#!/usr/bin/env python3
"""
ğŸ”¬ Advanced Hypothesis System - Ù†Ø¸Ø§Ù… Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
ğŸ“Š ÙŠÙˆÙ„Ø¯ ÙˆÙŠØ®ØªØ¨Ø± ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ø³ÙˆÙ‚
ğŸ¯ ÙŠØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ù†Ø¬Ø§Ø­Ø§Øª ÙˆØ§Ù„ÙØ´Ù„
"""

import os
import sys
import json
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import logging
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, field, asdict
import uuid
from scipy import stats
import asyncio
from concurrent.futures import ThreadPoolExecutor

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MarketHypothesis:
    """ÙØ±Ø¶ÙŠØ© Ø§Ù„Ø³ÙˆÙ‚"""
    hypothesis_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    name: str = ""
    description: str = ""
    category: str = ""  # trend, reversal, breakout, range, volatility
    conditions: Dict[str, Any] = field(default_factory=dict)
    indicators: List[str] = field(default_factory=list)
    timeframes: List[str] = field(default_factory=list)
    symbols: List[str] = field(default_factory=list)
    expected_outcome: Dict[str, Any] = field(default_factory=dict)
    entry_rules: Dict[str, Any] = field(default_factory=dict)
    exit_rules: Dict[str, Any] = field(default_factory=dict)
    risk_parameters: Dict[str, Any] = field(default_factory=dict)
    confidence: float = 0.5
    priority: int = 5
    test_results: List[Dict] = field(default_factory=list)
    backtest_results: Dict[str, Any] = field(default_factory=dict)
    live_results: Dict[str, Any] = field(default_factory=dict)
    validation_score: float = 0.0
    success_rate: float = 0.0
    profit_factor: float = 0.0
    sharpe_ratio: float = 0.0
    max_drawdown: float = 0.0
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)
    tested_count: int = 0
    successful_trades: int = 0
    failed_trades: int = 0
    is_active: bool = True
    is_validated: bool = False
    parent_hypothesis_id: Optional[str] = None
    child_hypotheses: List[str] = field(default_factory=list)
    meta_data: Dict[str, Any] = field(default_factory=dict)

class HypothesisGenerator:
    """Ù…ÙˆÙ„Ø¯ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª"""
    
    def __init__(self):
        self.hypothesis_templates = self._load_hypothesis_templates()
        self.market_patterns = self._load_market_patterns()
        self.successful_patterns = []
        self.failed_patterns = []
        
    def _load_hypothesis_templates(self) -> List[Dict]:
        """ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª"""
        return [
            # ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ø§ØªØ¬Ø§Ù‡
            {
                'category': 'trend',
                'template': 'trend_following',
                'conditions': {
                    'ma_alignment': 'bullish',  # MA50 > MA100 > MA200
                    'momentum': 'positive',
                    'volume': 'increasing'
                },
                'expected_outcome': {
                    'direction': 'up',
                    'duration': '4-8 hours',
                    'target': '1.5% - 3%'
                }
            },
            {
                'category': 'trend',
                'template': 'trend_reversal',
                'conditions': {
                    'divergence': True,
                    'support_resistance': 'at_level',
                    'candlestick_pattern': 'reversal'
                },
                'expected_outcome': {
                    'direction': 'reverse',
                    'duration': '2-4 hours',
                    'target': '1% - 2%'
                }
            },
            # ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚
            {
                'category': 'breakout',
                'template': 'range_breakout',
                'conditions': {
                    'price_action': 'consolidation',
                    'volatility': 'contracting',
                    'volume': 'decreasing'
                },
                'expected_outcome': {
                    'direction': 'breakout',
                    'duration': '1-2 hours',
                    'target': 'range_height * 1.5'
                }
            },
            {
                'category': 'breakout',
                'template': 'triangle_breakout',
                'conditions': {
                    'pattern': 'triangle',
                    'volume': 'decreasing',
                    'time_in_pattern': '>20 candles'
                },
                'expected_outcome': {
                    'direction': 'breakout_direction',
                    'duration': '2-3 hours',
                    'target': 'pattern_height'
                }
            },
            # ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„ØªØ°Ø¨Ø°Ø¨
            {
                'category': 'volatility',
                'template': 'volatility_expansion',
                'conditions': {
                    'bollinger_squeeze': True,
                    'atr': 'low',
                    'news_event': 'upcoming'
                },
                'expected_outcome': {
                    'volatility': 'increase',
                    'duration': '30-60 minutes',
                    'range': '2x_atr'
                }
            },
            # ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ù†Ø·Ø§Ù‚
            {
                'category': 'range',
                'template': 'range_trading',
                'conditions': {
                    'market_structure': 'ranging',
                    'support_resistance': 'defined',
                    'oscillator': 'oversold/overbought'
                },
                'expected_outcome': {
                    'direction': 'mean_reversion',
                    'duration': '2-4 hours',
                    'target': 'opposite_boundary'
                }
            },
            # ÙØ±Ø¶ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
            {
                'category': 'complex',
                'template': 'multi_timeframe_confluence',
                'conditions': {
                    'h4_trend': 'up',
                    'h1_pullback': True,
                    'm15_reversal_signal': True
                },
                'expected_outcome': {
                    'direction': 'up',
                    'duration': '4-8 hours',
                    'target': '2% - 4%'
                }
            }
        ]
    
    def _load_market_patterns(self) -> List[Dict]:
        """ØªØ­Ù…ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø³ÙˆÙ‚"""
        return [
            {'name': 'double_top', 'type': 'reversal', 'reliability': 0.75},
            {'name': 'double_bottom', 'type': 'reversal', 'reliability': 0.75},
            {'name': 'head_shoulders', 'type': 'reversal', 'reliability': 0.80},
            {'name': 'triangle', 'type': 'continuation', 'reliability': 0.70},
            {'name': 'flag', 'type': 'continuation', 'reliability': 0.72},
            {'name': 'wedge', 'type': 'reversal', 'reliability': 0.68},
            {'name': 'channel', 'type': 'continuation', 'reliability': 0.65}
        ]
    
    async def generate_hypotheses(self, market_data: Dict, 
                                historical_performance: Dict) -> List[MarketHypothesis]:
        """ØªÙˆÙ„ÙŠØ¯ ÙØ±Ø¶ÙŠØ§Øª Ø¬Ø¯ÙŠØ¯Ø©"""
        hypotheses = []
        
        # 1. ØªÙˆÙ„ÙŠØ¯ Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨
        template_hypotheses = await self._generate_from_templates(market_data)
        hypotheses.extend(template_hypotheses)
        
        # 2. ØªÙˆÙ„ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù†Ø§Ø¬Ø­Ø©
        pattern_hypotheses = await self._generate_from_successful_patterns(
            market_data, historical_performance
        )
        hypotheses.extend(pattern_hypotheses)
        
        # 3. ØªÙˆÙ„ÙŠØ¯ ÙØ±Ø¶ÙŠØ§Øª Ù…ØªÙƒÙŠÙØ©
        adaptive_hypotheses = await self._generate_adaptive_hypotheses(
            market_data, historical_performance
        )
        hypotheses.extend(adaptive_hypotheses)
        
        # 4. ØªÙˆÙ„ÙŠØ¯ ÙØ±Ø¶ÙŠØ§Øª Ù…Ø±ÙƒØ¨Ø©
        composite_hypotheses = await self._generate_composite_hypotheses(
            hypotheses[:10]  # Ø£ÙØ¶Ù„ 10 ÙØ±Ø¶ÙŠØ§Øª
        )
        hypotheses.extend(composite_hypotheses)
        
        # 5. ØªÙ‚ÙŠÙŠÙ… ÙˆØªØ±ØªÙŠØ¨ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª
        scored_hypotheses = await self._score_hypotheses(hypotheses, market_data)
        
        # Ø¥Ø±Ø¬Ø§Ø¹ Ø£ÙØ¶Ù„ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª
        return sorted(scored_hypotheses, key=lambda h: h.confidence, reverse=True)[:50]
    
    async def _generate_from_templates(self, market_data: Dict) -> List[MarketHypothesis]:
        """ØªÙˆÙ„ÙŠØ¯ ÙØ±Ø¶ÙŠØ§Øª Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨"""
        hypotheses = []
        
        for template in self.hypothesis_templates:
            # ØªØ®ØµÙŠØµ Ø§Ù„Ù‚Ø§Ù„Ø¨ Ù„Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø­Ø§Ù„ÙŠ
            hypothesis = MarketHypothesis(
                name=f"{template['template']}_{datetime.now().strftime('%Y%m%d_%H%M')}",
                description=f"Hypothesis based on {template['template']} pattern",
                category=template['category'],
                conditions=template['conditions'],
                expected_outcome=template['expected_outcome'],
                confidence=0.5  # Ø«Ù‚Ø© Ø£ÙˆÙ„ÙŠØ©
            )
            
            # ØªØ®ØµÙŠØµ Ù„Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
            suitable_symbols = await self._find_suitable_symbols(
                template, market_data
            )
            hypothesis.symbols = suitable_symbols[:10]
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
            hypothesis.timeframes = self._determine_timeframes(template)
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            hypothesis.indicators = self._extract_required_indicators(template)
            
            # ØªØ­Ø¯ÙŠØ¯ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØ§Ù„Ø®Ø±ÙˆØ¬
            hypothesis.entry_rules = self._generate_entry_rules(template)
            hypothesis.exit_rules = self._generate_exit_rules(template)
            
            # ØªØ­Ø¯ÙŠØ¯ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©
            hypothesis.risk_parameters = self._generate_risk_parameters(template)
            
            hypotheses.append(hypothesis)
        
        return hypotheses
    
    async def _generate_adaptive_hypotheses(self, market_data: Dict,
                                          historical_performance: Dict) -> List[MarketHypothesis]:
        """ØªÙˆÙ„ÙŠØ¯ ÙØ±Ø¶ÙŠØ§Øª Ù…ØªÙƒÙŠÙØ©"""
        hypotheses = []
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ
        performance_patterns = self._analyze_performance_patterns(historical_performance)
        
        for pattern in performance_patterns:
            if pattern['success_rate'] > 0.6:
                # Ø¥Ù†Ø´Ø§Ø¡ ÙØ±Ø¶ÙŠØ© Ù…Ø­Ø³Ù†Ø©
                hypothesis = MarketHypothesis(
                    name=f"adaptive_{pattern['name']}_{datetime.now().strftime('%Y%m%d')}",
                    description=f"Adaptive hypothesis based on successful {pattern['name']}",
                    category='adaptive',
                    conditions=self._enhance_conditions(pattern['conditions']),
                    expected_outcome=pattern['expected_outcome'],
                    confidence=pattern['success_rate']
                )
                
                # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù„Ù…
                hypothesis.entry_rules = self._optimize_entry_rules(
                    pattern['entry_rules'], 
                    pattern['successful_trades']
                )
                
                hypothesis.exit_rules = self._optimize_exit_rules(
                    pattern['exit_rules'],
                    pattern['successful_trades']
                )
                
                hypotheses.append(hypothesis)
        
        return hypotheses
    
    async def _generate_composite_hypotheses(self, 
                                           base_hypotheses: List[MarketHypothesis]) -> List[MarketHypothesis]:
        """ØªÙˆÙ„ÙŠØ¯ ÙØ±Ø¶ÙŠØ§Øª Ù…Ø±ÙƒØ¨Ø©"""
        composite_hypotheses = []
        
        # Ø¯Ù…Ø¬ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø©
        for i, h1 in enumerate(base_hypotheses):
            for j, h2 in enumerate(base_hypotheses[i+1:], i+1):
                if self._are_compatible(h1, h2):
                    composite = self._create_composite_hypothesis(h1, h2)
                    composite_hypotheses.append(composite)
        
        return composite_hypotheses
    
    def _are_compatible(self, h1: MarketHypothesis, h2: MarketHypothesis) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆØ§ÙÙ‚ ÙØ±Ø¶ÙŠØªÙŠÙ†"""
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ù… Ø§Ù„ØªØ¹Ø§Ø±Ø¶ ÙÙŠ Ø§Ù„Ø§ØªØ¬Ø§Ù‡
        if h1.expected_outcome.get('direction') and h2.expected_outcome.get('direction'):
            if h1.expected_outcome['direction'] != h2.expected_outcome['direction']:
                return False
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆØ§ÙÙ‚ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©
        common_timeframes = set(h1.timeframes) & set(h2.timeframes)
        if not common_timeframes:
            return False
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆØ§ÙÙ‚ Ø§Ù„ÙØ¦Ø§Øª
        compatible_categories = {
            'trend': ['momentum', 'breakout'],
            'breakout': ['trend', 'volatility'],
            'range': ['volatility'],
            'volatility': ['breakout', 'range']
        }
        
        if h2.category not in compatible_categories.get(h1.category, []):
            return False
        
        return True
    
    def _create_composite_hypothesis(self, h1: MarketHypothesis, 
                                   h2: MarketHypothesis) -> MarketHypothesis:
        """Ø¥Ù†Ø´Ø§Ø¡ ÙØ±Ø¶ÙŠØ© Ù…Ø±ÙƒØ¨Ø©"""
        composite = MarketHypothesis(
            name=f"composite_{h1.name}_{h2.name}",
            description=f"Composite of {h1.description} and {h2.description}",
            category='composite',
            parent_hypothesis_id=h1.hypothesis_id,
            child_hypotheses=[h1.hypothesis_id, h2.hypothesis_id]
        )
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ø´Ø±ÙˆØ·
        composite.conditions = {**h1.conditions, **h2.conditions}
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
        composite.indicators = list(set(h1.indicators + h2.indicators))
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©
        composite.timeframes = list(set(h1.timeframes) & set(h2.timeframes))
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ø±Ù…ÙˆØ²
        composite.symbols = list(set(h1.symbols) & set(h2.symbols))
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ù…Ø±ÙƒØ¨Ø©
        composite.confidence = (h1.confidence + h2.confidence) / 2 * 1.1  # Ù…ÙƒØ§ÙØ£Ø© Ù„Ù„ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯
        
        return composite

class HypothesisTester:
    """Ù…Ø®ØªØ¨Ø± Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª"""
    
    def __init__(self):
        self.test_results = []
        self.validation_criteria = {
            'min_trades': 30,
            'min_success_rate': 0.55,
            'min_profit_factor': 1.2,
            'max_drawdown': 0.15,
            'min_sharpe_ratio': 1.0
        }
    
    async def test_hypothesis(self, hypothesis: MarketHypothesis, 
                            market_data: pd.DataFrame,
                            mode: str = 'backtest') -> Dict[str, Any]:
        """Ø§Ø®ØªØ¨Ø§Ø± ÙØ±Ø¶ÙŠØ©"""
        logger.info(f"Testing hypothesis: {hypothesis.name}")
        
        if mode == 'backtest':
            results = await self._backtest_hypothesis(hypothesis, market_data)
        elif mode == 'paper':
            results = await self._paper_trade_hypothesis(hypothesis, market_data)
        elif mode == 'live':
            results = await self._live_test_hypothesis(hypothesis, market_data)
        else:
            raise ValueError(f"Unknown test mode: {mode}")
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙØ±Ø¶ÙŠØ© Ø¨Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        hypothesis.test_results.append(results)
        hypothesis.tested_count += 1
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        self._update_hypothesis_metrics(hypothesis, results)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©
        hypothesis.is_validated = self._validate_hypothesis(hypothesis)
        
        return results
    
    async def _backtest_hypothesis(self, hypothesis: MarketHypothesis,
                                 market_data: pd.DataFrame) -> Dict[str, Any]:
        """Ø§Ø®ØªØ¨Ø§Ø± Ø±Ø¬Ø¹ÙŠ Ù„Ù„ÙØ±Ø¶ÙŠØ©"""
        trades = []
        
        for i in range(100, len(market_data)):
            window = market_data.iloc[i-100:i]
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø´Ø±ÙˆØ· Ø§Ù„Ø¯Ø®ÙˆÙ„
            if self._check_entry_conditions(hypothesis, window):
                entry_price = window.iloc[-1]['close']
                entry_time = window.iloc[-1].name
                
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù‚Ø·Ø© Ø§Ù„Ø®Ø±ÙˆØ¬
                exit_idx, exit_price, exit_reason = self._find_exit_point(
                    hypothesis, market_data[i:i+50], entry_price
                )
                
                if exit_idx is not None:
                    trade = {
                        'entry_time': entry_time,
                        'entry_price': entry_price,
                        'exit_time': market_data.index[i + exit_idx],
                        'exit_price': exit_price,
                        'exit_reason': exit_reason,
                        'profit': (exit_price - entry_price) / entry_price,
                        'duration': exit_idx
                    }
                    trades.append(trade)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        results = self._calculate_backtest_metrics(trades)
        results['trades'] = trades
        
        return results
    
    def _check_entry_conditions(self, hypothesis: MarketHypothesis,
                              window: pd.DataFrame) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø´Ø±ÙˆØ· Ø§Ù„Ø¯Ø®ÙˆÙ„"""
        # Ù‡Ù†Ø§ ÙŠØªÙ… ØªÙ†ÙÙŠØ° Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø´Ø±ÙˆØ·
        # Ù‡Ø°Ø§ Ù…Ø«Ø§Ù„ Ù…Ø¨Ø³Ø·
        for condition, value in hypothesis.entry_rules.items():
            if condition == 'ma_crossover':
                if not self._check_ma_crossover(window, value):
                    return False
            elif condition == 'rsi_level':
                if not self._check_rsi_level(window, value):
                    return False
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø´Ø±ÙˆØ· Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø©
        
        return True
    
    def _calculate_backtest_metrics(self, trades: List[Dict]) -> Dict[str, Any]:
        """Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø±Ø¬Ø¹ÙŠ"""
        if not trades:
            return {
                'total_trades': 0,
                'winning_trades': 0,
                'losing_trades': 0,
                'success_rate': 0,
                'profit_factor': 0,
                'sharpe_ratio': 0,
                'max_drawdown': 0,
                'avg_profit': 0,
                'avg_loss': 0,
                'avg_duration': 0
            }
        
        profits = [t['profit'] for t in trades]
        winning_trades = [t for t in trades if t['profit'] > 0]
        losing_trades = [t for t in trades if t['profit'] <= 0]
        
        total_profit = sum([t['profit'] for t in winning_trades])
        total_loss = abs(sum([t['profit'] for t in losing_trades]))
        
        return {
            'total_trades': len(trades),
            'winning_trades': len(winning_trades),
            'losing_trades': len(losing_trades),
            'success_rate': len(winning_trades) / len(trades) if trades else 0,
            'profit_factor': total_profit / total_loss if total_loss > 0 else float('inf'),
            'sharpe_ratio': self._calculate_sharpe_ratio(profits),
            'max_drawdown': self._calculate_max_drawdown(profits),
            'avg_profit': np.mean([t['profit'] for t in winning_trades]) if winning_trades else 0,
            'avg_loss': np.mean([t['profit'] for t in losing_trades]) if losing_trades else 0,
            'avg_duration': np.mean([t['duration'] for t in trades])
        }
    
    def _calculate_sharpe_ratio(self, returns: List[float], risk_free_rate: float = 0.02) -> float:
        """Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø´Ø§Ø±Ø¨"""
        if not returns or len(returns) < 2:
            return 0
        
        returns_array = np.array(returns)
        excess_returns = returns_array - risk_free_rate / 252  # ÙŠÙˆÙ…ÙŠ
        
        if np.std(excess_returns) == 0:
            return 0
        
        return np.sqrt(252) * np.mean(excess_returns) / np.std(excess_returns)
    
    def _calculate_max_drawdown(self, returns: List[float]) -> float:
        """Ø­Ø³Ø§Ø¨ Ø£Ù‚ØµÙ‰ Ø§Ù†Ø®ÙØ§Ø¶"""
        if not returns:
            return 0
        
        cumulative = np.cumprod(1 + np.array(returns))
        running_max = np.maximum.accumulate(cumulative)
        drawdown = (cumulative - running_max) / running_max
        
        return abs(np.min(drawdown))

class HypothesisManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª"""
    
    def __init__(self):
        self.generator = HypothesisGenerator()
        self.tester = HypothesisTester()
        self.active_hypotheses: List[MarketHypothesis] = []
        self.hypothesis_history: List[MarketHypothesis] = []
        self.performance_threshold = 0.6
        self.max_active_hypotheses = 20
        
    async def update_hypotheses(self, market_data: Dict,
                              performance_data: Dict) -> List[MarketHypothesis]:
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª"""
        logger.info("Updating market hypotheses...")
        
        # 1. ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        await self._evaluate_active_hypotheses(market_data)
        
        # 2. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ø¶Ø¹ÙŠÙØ©
        self._prune_weak_hypotheses()
        
        # 3. ØªÙˆÙ„ÙŠØ¯ ÙØ±Ø¶ÙŠØ§Øª Ø¬Ø¯ÙŠØ¯Ø©
        new_hypotheses = await self.generator.generate_hypotheses(
            market_data, performance_data
        )
        
        # 4. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        tested_hypotheses = await self._test_new_hypotheses(
            new_hypotheses[:10], market_data
        )
        
        # 5. Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„ÙˆØ§Ø¹Ø¯Ø©
        self._add_promising_hypotheses(tested_hypotheses)
        
        # 6. ØªØ·ÙˆØ± Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©
        evolved_hypotheses = await self._evolve_successful_hypotheses()
        self.active_hypotheses.extend(evolved_hypotheses)
        
        # 7. Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù…Ø«Ù„
        self._maintain_optimal_count()
        
        return self.active_hypotheses
    
    async def _evaluate_active_hypotheses(self, market_data: Dict):
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ù†Ø´Ø·Ø©"""
        for hypothesis in self.active_hypotheses:
            # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø³ØªÙ…Ø±
            recent_performance = await self._test_recent_performance(
                hypothesis, market_data
            )
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            hypothesis.validation_score = self._calculate_validation_score(
                hypothesis, recent_performance
            )
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø©
            if hypothesis.validation_score < 0.4:
                hypothesis.is_active = False
                logger.info(f"Deactivating hypothesis: {hypothesis.name}")
    
    def _prune_weak_hypotheses(self):
        """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ø¶Ø¹ÙŠÙØ©"""
        # Ù†Ù‚Ù„ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ø¶Ø¹ÙŠÙØ© Ù„Ù„ØªØ§Ø±ÙŠØ®
        weak_hypotheses = [h for h in self.active_hypotheses 
                          if not h.is_active or h.validation_score < 0.4]
        
        for hypothesis in weak_hypotheses:
            self.hypothesis_history.append(hypothesis)
            self.active_hypotheses.remove(hypothesis)
    
    async def _evolve_successful_hypotheses(self) -> List[MarketHypothesis]:
        """ØªØ·ÙˆÙŠØ± Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©"""
        evolved = []
        
        successful = [h for h in self.active_hypotheses 
                     if h.success_rate > 0.65 and h.tested_count > 50]
        
        for hypothesis in successful:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…ØªØºÙŠØ±Ø§Øª Ù…Ø­Ø³Ù†Ø©
            variations = await self._create_hypothesis_variations(hypothesis)
            
            for variation in variations[:3]:  # Ø£ÙØ¶Ù„ 3 Ù…ØªØºÙŠØ±Ø§Øª
                # Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹
                test_results = await self.tester.test_hypothesis(
                    variation, self._get_recent_market_data()
                )
                
                if test_results['success_rate'] > hypothesis.success_rate:
                    evolved.append(variation)
                    logger.info(f"Evolved hypothesis: {variation.name}")
        
        return evolved
    
    async def _create_hypothesis_variations(self, 
                                          base_hypothesis: MarketHypothesis) -> List[MarketHypothesis]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…ØªØºÙŠØ±Ø§Øª Ù…Ù† ÙØ±Ø¶ÙŠØ© Ù†Ø§Ø¬Ø­Ø©"""
        variations = []
        
        # ØªØºÙŠÙŠØ± Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©
        risk_variation = self._create_risk_variation(base_hypothesis)
        variations.append(risk_variation)
        
        # ØªØºÙŠÙŠØ± Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ
        timeframe_variation = self._create_timeframe_variation(base_hypothesis)
        variations.append(timeframe_variation)
        
        # ØªØºÙŠÙŠØ± Ø§Ù„Ø´Ø±ÙˆØ·
        condition_variation = self._create_condition_variation(base_hypothesis)
        variations.append(condition_variation)
        
        # Ø¯Ù…Ø¬ Ù…Ø¹ ÙØ±Ø¶ÙŠØ§Øª Ø£Ø®Ø±Ù‰ Ù†Ø§Ø¬Ø­Ø©
        hybrid_variations = await self._create_hybrid_variations(base_hypothesis)
        variations.extend(hybrid_variations)
        
        return variations
    
    def save_hypotheses(self, filepath: str):
        """Ø­ÙØ¸ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª"""
        data = {
            'active_hypotheses': [asdict(h) for h in self.active_hypotheses],
            'hypothesis_history': [asdict(h) for h in self.hypothesis_history[-100:]],
            'metadata': {
                'last_update': datetime.now().isoformat(),
                'total_generated': len(self.hypothesis_history) + len(self.active_hypotheses),
                'active_count': len(self.active_hypotheses)
            }
        }
        
        with open(filepath, 'w') as f:
            json.dump(data, f, indent=2, default=str)
        
        logger.info(f"Saved {len(self.active_hypotheses)} active hypotheses")
    
    def load_hypotheses(self, filepath: str):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª"""
        if os.path.exists(filepath):
            with open(filepath, 'r') as f:
                data = json.load(f)
            
            self.active_hypotheses = [
                MarketHypothesis(**h) for h in data['active_hypotheses']
            ]
            
            logger.info(f"Loaded {len(self.active_hypotheses)} active hypotheses")

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
async def main():
    """ØªØ´ØºÙŠÙ„ Ù†Ø¸Ø§Ù… Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª"""
    manager = HypothesisManager()
    
    # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    market_data = {
        'symbols': ['EUR/USD', 'GBP/USD', 'USD/JPY'],
        'current_prices': {'EUR/USD': 1.0850, 'GBP/USD': 1.2650, 'USD/JPY': 149.50},
        'volatility': {'EUR/USD': 0.08, 'GBP/USD': 0.10, 'USD/JPY': 0.12}
    }
    
    performance_data = {
        'total_trades': 1000,
        'winning_trades': 580,
        'success_rate': 0.58
    }
    
    # ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª
    hypotheses = await manager.update_hypotheses(market_data, performance_data)
    
    print(f"Generated {len(hypotheses)} active hypotheses")
    
    # Ø­ÙØ¸ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª
    manager.save_hypotheses('market_hypotheses.json')

if __name__ == "__main__":
    asyncio.run(main())