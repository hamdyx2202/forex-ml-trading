#!/usr/bin/env python3
"""
Automated Training System with SL/TP Support
Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¢Ù„ÙŠ Ù…Ø¹ Ø¯Ø¹Ù… ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù
"""

import schedule
import time
from datetime import datetime, timedelta
from pathlib import Path
import json
from loguru import logger
import threading
import sqlite3
import pandas as pd
import requests

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø±
import sys
sys.path.append(str(Path(__file__).parent))

from integrated_training_sltp import IntegratedTrainingSystemSLTP
from performance_tracker import PerformanceTracker
from instrument_manager import InstrumentManager

class AutomatedTrainingSLTP:
    """Ù†Ø¸Ø§Ù… ØªØ¯Ø±ÙŠØ¨ Ø¢Ù„ÙŠ ÙŠØ¹Ù…Ù„ 24/7 Ù…Ø¹ ØªØ­Ø³ÙŠÙ† SL/TP"""
    
    def __init__(self):
        self.training_system = IntegratedTrainingSystemSLTP()
        self.performance_tracker = PerformanceTracker()
        self.instrument_manager = InstrumentManager()
        
        self.config = {
            'training_schedule': {
                'daily_training_time': '03:00',  # ÙˆÙ‚Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙŠÙˆÙ…ÙŠ
                'weekly_full_training': 'sunday',  # ÙŠÙˆÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙƒØ§Ù…Ù„
                'performance_check_interval': 60,  # Ø¯Ù‚Ø§Ø¦Ù‚
                'emergency_retrain_threshold': 0.45,  # Ø­Ø¯ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø·Ø§Ø±Ø¦
            },
            'notification_settings': {
                'enable_notifications': True,
                'webhook_url': None,  # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© webhook
                'email_notifications': False,
            },
            'training_priorities': {
                'high_priority': ['EURUSD', 'GBPUSD', 'XAUUSD', 'US30'],
                'medium_priority': ['USDJPY', 'AUDUSD', 'NZDUSD', 'EURJPY'],
                'low_priority': []  # Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬
            },
            'resource_management': {
                'max_concurrent_training': 3,
                'cpu_usage_limit': 80,  # Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ©
                'memory_usage_limit': 70,  # Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ©
            }
        }
        
        self.training_history = []
        self.is_running = False
        
    def start(self):
        """Ø¨Ø¯Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¢Ù„ÙŠ"""
        logger.info("ğŸ¤– Starting Automated Training System with SL/TP optimization...")
        
        self.is_running = True
        
        # Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ù…Ù‡Ø§Ù…
        self.schedule_tasks()
        
        # Ø¨Ø¯Ø¡ Ø®ÙŠØ· Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡
        performance_thread = threading.Thread(target=self.performance_monitor_loop, daemon=True)
        performance_thread.start()
        
        # Ø¨Ø¯Ø¡ Ø®ÙŠØ· Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©
        schedule_thread = threading.Thread(target=self.schedule_loop, daemon=True)
        schedule_thread.start()
        
        logger.info("âœ… Automated training system is running!")
        
    def schedule_tasks(self):
        """Ø¬Ø¯ÙˆÙ„Ø© Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        # ØªØ¯Ø±ÙŠØ¨ ÙŠÙˆÙ…ÙŠ
        schedule.every().day.at(self.config['training_schedule']['daily_training_time']).do(
            self.daily_training_task
        )
        
        # ØªØ¯Ø±ÙŠØ¨ Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ø´Ø§Ù…Ù„
        getattr(schedule.every(), self.config['training_schedule']['weekly_full_training']).at("02:00").do(
            self.weekly_full_training_task
        )
        
        # ØªÙ†Ø¸ÙŠÙ ÙŠÙˆÙ…ÙŠ
        schedule.every().day.at("23:00").do(self.cleanup_old_models)
        
        # ØªÙ‚Ø±ÙŠØ± ÙŠÙˆÙ…ÙŠ
        schedule.every().day.at("08:00").do(self.generate_daily_report)
        
    def schedule_loop(self):
        """Ø­Ù„Ù‚Ø© ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„Ø©"""
        while self.is_running:
            schedule.run_pending()
            time.sleep(60)  # ÙØ­Øµ ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚Ø©
            
    def performance_monitor_loop(self):
        """Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…Ø³ØªÙ…Ø±Ø© Ù„Ù„Ø£Ø¯Ø§Ø¡"""
        while self.is_running:
            try:
                self.check_model_performance()
                time.sleep(self.config['training_schedule']['performance_check_interval'] * 60)
            except Exception as e:
                logger.error(f"Error in performance monitoring: {str(e)}")
                time.sleep(300)  # Ø§Ù†ØªØ¸Ø§Ø± 5 Ø¯Ù‚Ø§Ø¦Ù‚ Ø¹Ù†Ø¯ Ø§Ù„Ø®Ø·Ø£
                
    def daily_training_task(self):
        """Ù…Ù‡Ù…Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙŠÙˆÙ…ÙŠØ©"""
        logger.info("ğŸ“… Starting daily training task...")
        
        try:
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ ØªØ¯Ø±ÙŠØ¨
            pairs_to_train = self.identify_pairs_needing_training()
            
            if pairs_to_train:
                # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
                prioritized_pairs = self.prioritize_pairs(pairs_to_train)
                
                # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬
                results = self.train_pairs_batch(prioritized_pairs)
                
                # Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„
                self.log_training_session(results, 'daily')
                
                # Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø±
                self.send_notification(f"Daily training completed: {len(results)} models updated")
            else:
                logger.info("No models need training today")
                
        except Exception as e:
            logger.error(f"Error in daily training: {str(e)}")
            self.send_notification(f"Daily training failed: {str(e)}", level='error')
            
    def weekly_full_training_task(self):
        """ØªØ¯Ø±ÙŠØ¨ Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ø´Ø§Ù…Ù„"""
        logger.info("ğŸ“… Starting weekly full training...")
        
        try:
            # ØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
            instrument_types = ['forex_major', 'metals', 'indices']
            
            results = self.training_system.train_all_instruments(
                instrument_types=instrument_types,
                force_retrain=True
            )
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            success_rate = len([r for r in results if r.get('success', False)]) / len(results)
            
            self.log_training_session(results, 'weekly_full')
            
            self.send_notification(
                f"Weekly training completed: {len(results)} models, "
                f"Success rate: {success_rate:.1%}"
            )
            
        except Exception as e:
            logger.error(f"Error in weekly training: {str(e)}")
            self.send_notification(f"Weekly training failed: {str(e)}", level='error')
            
    def check_model_performance(self):
        """ÙØ­Øµ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        logger.info("ğŸ” Checking model performance...")
        
        poor_performing = []
        
        # ÙØ­Øµ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù†Ø´Ø·Ø©
        models_dir = Path("models/unified_sltp")
        
        for model_file in models_dir.glob("*.pkl"):
            try:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                parts = model_file.stem.split('_')
                if len(parts) >= 2:
                    symbol = parts[0]
                    timeframe = parts[1]
                    
                    # ÙØ­Øµ Ø§Ù„Ø£Ø¯Ø§Ø¡
                    performance = self.performance_tracker.get_pair_performance(
                        symbol, timeframe
                    )
                    
                    if performance and performance.get('win_rate', 0) < self.config['training_schedule']['emergency_retrain_threshold']:
                        poor_performing.append({
                            'symbol': symbol,
                            'timeframe': timeframe,
                            'win_rate': performance.get('win_rate', 0),
                            'reason': 'low_win_rate'
                        })
                        
            except Exception as e:
                logger.error(f"Error checking {model_file}: {str(e)}")
                
        # ØªØ¯Ø±ÙŠØ¨ Ø·Ø§Ø±Ø¦ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¶Ø¹ÙŠÙØ© Ø§Ù„Ø£Ø¯Ø§Ø¡
        if poor_performing:
            logger.warning(f"Found {len(poor_performing)} poor performing models")
            self.emergency_retrain(poor_performing)
            
    def emergency_retrain(self, poor_models):
        """Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ Ø·Ø§Ø±Ø¦Ø© Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¶Ø¹ÙŠÙØ© Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        logger.warning("ğŸš¨ Starting emergency retraining...")
        
        # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
        max_models = min(len(poor_models), self.config['resource_management']['max_concurrent_training'])
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø³ÙˆØ£ Ø£Ø¯Ø§Ø¡Ù‹
        worst_models = sorted(poor_models, key=lambda x: x['win_rate'])[:max_models]
        
        for model in worst_models:
            try:
                logger.info(f"Retraining {model['symbol']} {model['timeframe']} (Win rate: {model['win_rate']:.1%})")
                
                success = self.training_system.train_single_model(
                    model['symbol'],
                    model['timeframe'],
                    self.instrument_manager.get_instrument_type(model['symbol'])
                )
                
                if success:
                    logger.info(f"âœ… Successfully retrained {model['symbol']} {model['timeframe']}")
                    
            except Exception as e:
                logger.error(f"Failed to retrain {model['symbol']}: {str(e)}")
                
        self.send_notification(
            f"Emergency retraining completed for {len(worst_models)} models",
            level='warning'
        )
        
    def identify_pairs_needing_training(self):
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ ØªØ¯Ø±ÙŠØ¨"""
        pairs_to_train = []
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ù†Ø´Ø·Ø©
        active_instruments = self.instrument_manager.get_all_instruments()
        
        for instrument in active_instruments:
            for timeframe in ['M5', 'M15', 'H1', 'H4']:
                if self.needs_training(instrument['symbol'], timeframe):
                    pairs_to_train.append({
                        'symbol': instrument['symbol'],
                        'timeframe': timeframe,
                        'type': instrument['type'],
                        'priority': self.get_pair_priority(instrument['symbol'])
                    })
                    
        return pairs_to_train
        
    def needs_training(self, symbol, timeframe):
        """ÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø²ÙˆØ¬ ÙŠØ­ØªØ§Ø¬ ØªØ¯Ø±ÙŠØ¨"""
        model_path = Path(f"models/unified_sltp/{symbol}_{timeframe}_unified.pkl")
        
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬
        if not model_path.exists():
            return True
            
        # ÙØ­Øµ Ø¹Ù…Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        model_age = time.time() - model_path.stat().st_mtime
        max_age = 7 * 24 * 3600  # 7 Ø£ÙŠØ§Ù…
        
        if model_age > max_age:
            return True
            
        # ÙØ­Øµ Ø§Ù„Ø£Ø¯Ø§Ø¡
        performance = self.performance_tracker.get_pair_performance(symbol, timeframe)
        if performance and performance.get('win_rate', 0) < 0.5:
            return True
            
        return False
        
    def get_pair_priority(self, symbol):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ø²ÙˆØ¬"""
        if symbol in self.config['training_priorities']['high_priority']:
            return 1
        elif symbol in self.config['training_priorities']['medium_priority']:
            return 2
        else:
            return 3
            
    def prioritize_pairs(self, pairs):
        """ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©"""
        return sorted(pairs, key=lambda x: (x['priority'], x['symbol']))
        
    def train_pairs_batch(self, pairs):
        """ØªØ¯Ø±ÙŠØ¨ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ø²ÙˆØ§Ø¬"""
        results = []
        
        # ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ù„Ø¯ÙØ¹Ø§Øª
        batch_size = self.config['resource_management']['max_concurrent_training']
        
        for i in range(0, len(pairs), batch_size):
            batch = pairs[i:i+batch_size]
            
            for pair in batch:
                try:
                    result = self.training_system.train_single_model(
                        pair['symbol'],
                        pair['timeframe'],
                        pair['type']
                    )
                    results.append(result)
                    
                except Exception as e:
                    logger.error(f"Error training {pair['symbol']} {pair['timeframe']}: {str(e)}")
                    results.append({
                        'pair': pair['symbol'],
                        'timeframe': pair['timeframe'],
                        'success': False,
                        'error': str(e)
                    })
                    
        return results
        
    def cleanup_old_models(self):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        logger.info("ğŸ§¹ Cleaning up old models...")
        
        models_dir = Path("models/unified_sltp")
        backup_dir = Path("models/backup")
        backup_dir.mkdir(exist_ok=True)
        
        # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± 3 Ù†Ø³Ø® Ù…Ù† ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬
        model_versions = {}
        
        for model_file in models_dir.glob("*.pkl"):
            base_name = '_'.join(model_file.stem.split('_')[:2])
            
            if base_name not in model_versions:
                model_versions[base_name] = []
                
            model_versions[base_name].append(model_file)
            
        # ØªØ±ØªÙŠØ¨ ÙˆÙ†Ù‚Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        cleaned = 0
        for base_name, files in model_versions.items():
            if len(files) > 3:
                # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ®
                files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
                
                # Ù†Ù‚Ù„ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ù„Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ
                for old_file in files[3:]:
                    old_file.rename(backup_dir / old_file.name)
                    cleaned += 1
                    
        logger.info(f"âœ… Moved {cleaned} old models to backup")
        
    def generate_daily_report(self):
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± ÙŠÙˆÙ…ÙŠ"""
        logger.info("ğŸ“Š Generating daily report...")
        
        report = {
            'date': datetime.now().strftime('%Y-%m-%d'),
            'models_count': 0,
            'average_performance': {},
            'training_sessions': len(self.training_history),
            'top_performers': [],
            'worst_performers': [],
            'sltp_optimization_stats': {}
        }
        
        # Ø¬Ù…Ø¹ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        models_dir = Path("models/unified_sltp")
        performances = []
        
        for model_file in models_dir.glob("*.pkl"):
            try:
                parts = model_file.stem.split('_')
                if len(parts) >= 2:
                    symbol = parts[0]
                    timeframe = parts[1]
                    
                    perf = self.performance_tracker.get_pair_performance(symbol, timeframe)
                    if perf:
                        performances.append({
                            'symbol': symbol,
                            'timeframe': timeframe,
                            'win_rate': perf.get('win_rate', 0),
                            'sharpe': perf.get('sharpe_ratio', 0),
                            'avg_sl': perf.get('avg_sl_pips', 0),
                            'avg_tp': perf.get('avg_tp_pips', 0),
                            'avg_rr': perf.get('avg_risk_reward', 0)
                        })
                        
            except:
                pass
                
        if performances:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª
            report['models_count'] = len(performances)
            report['average_performance'] = {
                'win_rate': sum(p['win_rate'] for p in performances) / len(performances),
                'sharpe_ratio': sum(p['sharpe'] for p in performances) / len(performances),
                'avg_sl_pips': sum(p['avg_sl'] for p in performances) / len(performances),
                'avg_tp_pips': sum(p['avg_tp'] for p in performances) / len(performances),
                'avg_risk_reward': sum(p['avg_rr'] for p in performances) / len(performances)
            }
            
            # Ø£ÙØ¶Ù„ ÙˆØ£Ø³ÙˆØ£ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            sorted_perfs = sorted(performances, key=lambda x: x['win_rate'], reverse=True)
            report['top_performers'] = sorted_perfs[:5]
            report['worst_performers'] = sorted_perfs[-5:]
            
        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        reports_dir = Path("reports")
        reports_dir.mkdir(exist_ok=True)
        
        report_path = reports_dir / f"daily_report_{report['date']}.json"
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
            
        # Ø¥Ø±Ø³Ø§Ù„ Ù…Ù„Ø®Øµ
        summary = f"""
ğŸ“Š Daily Report - {report['date']}
Models: {report['models_count']}
Avg Win Rate: {report['average_performance'].get('win_rate', 0):.1%}
Avg Sharpe: {report['average_performance'].get('sharpe_ratio', 0):.2f}
Avg SL: {report['average_performance'].get('avg_sl_pips', 0):.1f} pips
Avg TP: {report['average_performance'].get('avg_tp_pips', 0):.1f} pips
Avg R:R: {report['average_performance'].get('avg_risk_reward', 0):.2f}
"""
        
        self.send_notification(summary)
        logger.info(f"âœ… Report saved to {report_path}")
        
    def log_training_session(self, results, session_type):
        """ØªØ³Ø¬ÙŠÙ„ Ø¬Ù„Ø³Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        session = {
            'timestamp': datetime.now().isoformat(),
            'type': session_type,
            'results': results,
            'summary': {
                'total': len(results),
                'successful': len([r for r in results if r.get('success', False)]),
                'failed': len([r for r in results if not r.get('success', False)])
            }
        }
        
        self.training_history.append(session)
        
        # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± 100 Ø¬Ù„Ø³Ø©
        if len(self.training_history) > 100:
            self.training_history = self.training_history[-100:]
            
    def send_notification(self, message, level='info'):
        """Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø±"""
        if not self.config['notification_settings']['enable_notifications']:
            return
            
        # Ø·Ø¨Ø§Ø¹Ø© ÙÙŠ Ø§Ù„Ø³Ø¬Ù„
        if level == 'error':
            logger.error(f"ğŸš¨ {message}")
        elif level == 'warning':
            logger.warning(f"âš ï¸ {message}")
        else:
            logger.info(f"ğŸ“¢ {message}")
            
        # Ø¥Ø±Ø³Ø§Ù„ webhook Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
        if self.config['notification_settings']['webhook_url']:
            try:
                requests.post(
                    self.config['notification_settings']['webhook_url'],
                    json={
                        'text': message,
                        'level': level,
                        'timestamp': datetime.now().isoformat()
                    },
                    timeout=5
                )
            except:
                pass
                
    def stop(self):
        """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù†Ø¸Ø§Ù…"""
        logger.info("Stopping automated training system...")
        self.is_running = False
        
    def get_status(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
        return {
            'is_running': self.is_running,
            'next_daily_training': schedule.jobs[0].next_run if schedule.jobs else None,
            'training_history_count': len(self.training_history),
            'last_training': self.training_history[-1] if self.training_history else None
        }


if __name__ == "__main__":
    # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…
    auto_trainer = AutomatedTrainingSLTP()
    
    # Ø¨Ø¯Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…
    auto_trainer.start()
    
    # Ø§Ù„Ø¨Ù‚Ø§Ø¡ Ù†Ø´Ø·Ø§Ù‹
    logger.info("âœ… Automated training system is running... Press Ctrl+C to stop")
    
    try:
        while True:
            time.sleep(60)
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ø­Ø§Ù„Ø© ÙƒÙ„ 30 Ø¯Ù‚ÙŠÙ‚Ø©
            if datetime.now().minute % 30 == 0:
                status = auto_trainer.get_status()
                logger.info(f"Status: Running={status['is_running']}, "
                          f"History={status['training_history_count']} sessions")
                
    except KeyboardInterrupt:
        logger.info("\nğŸ‘‹ Stopping automated training...")
        auto_trainer.stop()