#!/usr/bin/env python3
"""
ğŸ”„ Ø¯Ù…Ø¬ Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ù…Ù†ÙØµÙ„Ø© ÙÙŠ Ø¬Ø¯ÙˆÙ„ Ù…ÙˆØ­Ø¯
ğŸ“Š ÙŠÙ†Ø´Ø¦ Ø¬Ø¯ÙˆÙ„ price_data Ù…Ù† Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
"""

import sqlite3
import pandas as pd
import logging
from datetime import datetime

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)

def merge_tables_to_price_data():
    """Ø¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ ÙÙŠ Ø¬Ø¯ÙˆÙ„ Ù…ÙˆØ­Ø¯"""
    db_path = './data/forex_ml.db'
    
    logger.info("="*60)
    logger.info("ğŸ”„ Merging Separate Tables into Unified price_data")
    logger.info("="*60)
    
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # 1. Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ price_data Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        logger.info("\nğŸ“Š Creating unified price_data table...")
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS price_data (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT NOT NULL,
            timeframe TEXT NOT NULL,
            time TEXT NOT NULL,
            open REAL NOT NULL,
            high REAL NOT NULL,
            low REAL NOT NULL,
            close REAL NOT NULL,
            volume INTEGER DEFAULT 0,
            spread REAL DEFAULT 0,
            UNIQUE(symbol, timeframe, time)
        )
        """)
        
        # 2. Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        cursor.execute("""
        SELECT name FROM sqlite_master 
        WHERE type='table' AND name LIKE '%_processed'
        """)
        processed_tables = cursor.fetchall()
        
        logger.info(f"\nğŸ“ Found {len(processed_tables)} processed tables")
        
        total_records = 0
        
        # 3. Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø¬Ø¯ÙˆÙ„
        for table_tuple in processed_tables:
            table_name = table_tuple[0]
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ø²ÙˆØ¬
            symbol = table_name.replace('_processed', '')
            
            logger.info(f"\nğŸ”„ Processing {symbol}...")
            
            # Ø¬Ù„Ø¨ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns_info = cursor.fetchall()
            column_names = [col[1] for col in columns_info]
            
            # ØªØ­Ø¯ÙŠØ¯ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©
            timeframe_mapping = {
                'PERIOD_M5': 'M5',
                'PERIOD_M15': 'M15',
                'PERIOD_M30': 'M30',
                'PERIOD_H1': 'H1',
                'PERIOD_H4': 'H4',
                'PERIOD_D1': 'D1'
            }
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø¥Ø·Ø§Ø± Ø²Ù…Ù†ÙŠ
            records_added = 0
            for period_col, tf in timeframe_mapping.items():
                if period_col in column_names:
                    try:
                        # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                        query = f"""
                        SELECT time, {period_col} 
                        FROM {table_name} 
                        WHERE {period_col} IS NOT NULL
                        """
                        cursor.execute(query)
                        rows = cursor.fetchall()
                        
                        if rows:
                            logger.info(f"   {tf}: {len(rows)} records found")
                            
                            # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø³Ø¬Ù„
                            for row in rows:
                                time_val = row[0]
                                price_data = row[1]
                                
                                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø©
                                try:
                                    if isinstance(time_val, (int, float)):
                                        time_str = datetime.fromtimestamp(time_val).strftime('%Y-%m-%d %H:%M:%S')
                                    else:
                                        time_str = str(time_val)
                                except:
                                    time_str = str(time_val)
                                
                                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ OHLC Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                                # Ø§ÙØªØ±Ø§Ø¶ Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø®Ø²Ù†Ø© ÙƒÙ€ "open,high,low,close,volume"
                                try:
                                    if isinstance(price_data, str):
                                        parts = price_data.split(',')
                                        if len(parts) >= 4:
                                            open_price = float(parts[0])
                                            high_price = float(parts[1])
                                            low_price = float(parts[2])
                                            close_price = float(parts[3])
                                            volume = int(parts[4]) if len(parts) > 4 else 0
                                            
                                            # Ø¥Ø¯Ø±Ø§Ø¬ ÙÙŠ Ø¬Ø¯ÙˆÙ„ price_data
                                            cursor.execute("""
                                            INSERT OR REPLACE INTO price_data 
                                            (symbol, timeframe, time, open, high, low, close, volume)
                                            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                                            """, (symbol, tf, time_str, open_price, high_price, 
                                                  low_price, close_price, volume))
                                            records_added += 1
                                except Exception as e:
                                    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù„ÙŠÙ„ Ù…Ø®ØªÙ„ÙØ©
                                    continue
                            
                    except Exception as e:
                        logger.error(f"   Error processing {tf}: {e}")
            
            if records_added > 0:
                logger.info(f"   âœ… Added {records_added} records")
                total_records += records_added
                conn.commit()
        
        # 4. Ø¥Ù†Ø´Ø§Ø¡ ÙÙ‡Ø§Ø±Ø³ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
        logger.info("\nğŸ”§ Creating indexes...")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_symbol_timeframe ON price_data(symbol, timeframe)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_time ON price_data(time)")
        
        # 5. Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù†Ù‡Ø§Ø¦ÙŠØ©
        cursor.execute("SELECT COUNT(*) FROM price_data")
        final_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT symbol) FROM price_data")
        unique_symbols = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT timeframe) FROM price_data")
        unique_timeframes = cursor.fetchone()[0]
        
        logger.info("\n" + "="*60)
        logger.info("âœ… Data Merge Complete!")
        logger.info(f"ğŸ“Š Total records in price_data: {final_count:,}")
        logger.info(f"ğŸ’¹ Unique symbols: {unique_symbols}")
        logger.info(f"â° Unique timeframes: {unique_timeframes}")
        
        # Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨
        logger.info("\nğŸ¯ Training-ready pairs (M15 with >2000 candles):")
        query = """
        SELECT symbol, COUNT(*) as count 
        FROM price_data 
        WHERE timeframe = 'M15'
        GROUP BY symbol 
        HAVING count > 2000
        ORDER BY count DESC
        """
        df = pd.read_sql_query(query, conn)
        
        if not df.empty:
            for _, row in df.iterrows():
                logger.info(f"   âœ… {row['symbol']}: {row['count']:,} candles")
        else:
            logger.info("   âš ï¸ No pairs with sufficient M15 data yet")
        
        conn.close()
        
    except Exception as e:
        logger.error(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()

def check_table_structure():
    """ÙØ­Øµ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"""
    db_path = './data/forex_ml.db'
    
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # ÙØ­Øµ Ø¬Ø¯ÙˆÙ„ ÙˆØ§Ø­Ø¯ ÙƒÙ…Ø«Ø§Ù„
        cursor.execute("""
        SELECT name FROM sqlite_master 
        WHERE type='table' AND name LIKE '%_processed'
        LIMIT 1
        """)
        
        table = cursor.fetchone()
        if table:
            table_name = table[0]
            logger.info(f"\nğŸ” Examining table structure: {table_name}")
            
            # Ø¹Ø±Ø¶ Ø¨Ø¹Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            cursor.execute(f"SELECT * FROM {table_name} LIMIT 5")
            rows = cursor.fetchall()
            
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns = cursor.fetchall()
            
            logger.info("\nColumns:")
            for col in columns:
                logger.info(f"   - {col[1]} ({col[2]})")
            
            logger.info("\nSample data:")
            for i, row in enumerate(rows):
                logger.info(f"   Row {i+1}: {row[:3]}...")  # Ø£ÙˆÙ„ 3 Ø£Ø¹Ù…Ø¯Ø© ÙÙ‚Ø·
        
        conn.close()
        
    except Exception as e:
        logger.error(f"Error checking structure: {e}")

if __name__ == "__main__":
    # ÙØ­Øµ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø£ÙˆÙ„Ø§Ù‹
    check_table_structure()
    
    # Ø«Ù… Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    merge_tables_to_price_data()