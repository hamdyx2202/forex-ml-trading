#!/usr/bin/env python3
"""
ğŸš€ ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
ğŸ“Š ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù†Øª Ø£Ù‚Ù„ Ù…Ù† 2000 Ø´Ù…Ø¹Ø©
"""

import os
import sys
import sqlite3
import pandas as pd
import logging

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± Ø§Ù„Ø³ÙŠØ±ÙØ±
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from enhanced_ml_server import EnhancedMLTradingSystem

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)

def get_all_available_pairs(min_candles=500):  # Ø®ÙØ¶Ù†Ø§ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰
    """Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    db_path = './data/forex_ml.db'
    
    if not os.path.exists(db_path):
        logger.error(f"âŒ Database not found at: {db_path}")
        return pd.DataFrame()
    
    try:
        conn = sqlite3.connect(db_path)
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ø¯ÙˆÙ„ price_data Ø£ÙˆÙ„Ø§Ù‹
        cursor = conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='price_data'")
        
        if cursor.fetchone():
            # Ø¬Ø¯ÙˆÙ„ price_data Ù…ÙˆØ¬ÙˆØ¯
            query = f"""
            SELECT symbol, COUNT(*) as count 
            FROM price_data 
            WHERE timeframe = 'M15'
            GROUP BY symbol 
            HAVING count > {min_candles}
            ORDER BY count DESC
            """
            pairs = pd.read_sql_query(query, conn)
            
            if not pairs.empty:
                logger.info(f"âœ… Found {len(pairs)} pairs in price_data with >{min_candles} M15 candles")
                conn.close()
                return pairs
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
        logger.info("ğŸ“Š Checking processed tables directly...")
        
        cursor.execute("""
        SELECT name FROM sqlite_master 
        WHERE type='table' AND name LIKE '%_processed'
        """)
        tables = cursor.fetchall()
        
        pairs_data = []
        
        for table_tuple in tables:
            table_name = table_tuple[0]
            symbol = table_name.replace('_processed', '')
            
            # Ø¹Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª M15
            try:
                query = f"""
                SELECT COUNT(*) as count
                FROM {table_name}
                WHERE timeframe = 'PERIOD_M15'
                """
                cursor.execute(query)
                count = cursor.fetchone()[0]
                
                if count > min_candles:
                    pairs_data.append({
                        'symbol': symbol,
                        'count': count,
                        'table': table_name
                    })
                    logger.info(f"   âœ… {symbol}: {count:,} M15 candles")
                
            except Exception as e:
                continue
        
        conn.close()
        
        if pairs_data:
            return pd.DataFrame(pairs_data)
        else:
            logger.warning(f"âš ï¸ No pairs found with >{min_candles} M15 candles")
            return pd.DataFrame()
        
    except Exception as e:
        logger.error(f"âŒ Database error: {e}")
        return pd.DataFrame()

def train_from_processed_tables(system, symbol, timeframe, table_name):
    """ØªØ¯Ø±ÙŠØ¨ Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"""
    try:
        logger.info(f"ğŸ¤– Training {symbol} {timeframe} from {table_name}...")
        
        conn = sqlite3.connect('./data/forex_ml.db')
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ
        tf_map = {
            'M15': 'PERIOD_M15',
            'M30': 'PERIOD_M30',
            'H1': 'PERIOD_H1'
        }
        period_tf = tf_map.get(timeframe, f'PERIOD_{timeframe}')
        
        # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        query = f"""
        SELECT time, open, high, low, close, volume
        FROM {table_name}
        WHERE timeframe = '{period_tf}'
        ORDER BY time DESC
        LIMIT 10000
        """
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        if len(df) < 500:
            logger.warning(f"Not enough data: {len(df)} records")
            return False
        
        # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        df['time'] = pd.to_datetime(df['time'], unit='s')
        df.set_index('time', inplace=True)
        df = df.sort_index()
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ù…Ø² Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…
        clean_symbol = symbol.replace('m', '').replace('.ecn', '').upper()
        
        # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        return system.train_enhanced_models(clean_symbol, timeframe)
        
    except Exception as e:
        logger.error(f"âŒ Training error: {e}")
        return False

def main():
    logger.info("\n" + "="*80)
    logger.info("ğŸš€ Training with Available Data")
    logger.info("ğŸ“Š Using reduced minimum requirements")
    logger.info("="*80)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…
    logger.info("\nğŸ”§ Initializing Enhanced Trading System...")
    system = EnhancedMLTradingSystem()
    
    # Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø© Ø¨Ø­Ø¯ Ø£Ø¯Ù†Ù‰ Ø£Ù‚Ù„
    pairs_df = get_all_available_pairs(min_candles=500)
    
    if pairs_df.empty:
        logger.error("\nâŒ No pairs available even with reduced requirements!")
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø£Ø®ÙŠØ±Ø© - Ø¹Ø±Ø¶ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
        conn = sqlite3.connect('./data/forex_ml.db')
        cursor = conn.cursor()
        
        cursor.execute("""
        SELECT name FROM sqlite_master 
        WHERE type='table' AND name LIKE '%_processed'
        """)
        tables = cursor.fetchall()
        
        if tables:
            logger.info("\nğŸ“Š All available data:")
            for table_tuple in tables:
                table_name = table_tuple[0]
                cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                count = cursor.fetchone()[0]
                logger.info(f"   - {table_name}: {count:,} total records")
        
        conn.close()
        return
    
    logger.info(f"\nğŸ“Š Found {len(pairs_df)} pairs for training")
    
    # Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©
    timeframes = ['M15']  # Ù†Ø¨Ø¯Ø£ Ø¨Ù€ M15 ÙÙ‚Ø·
    
    total_models = 0
    failed_models = 0
    
    # ØªØ¯Ø±ÙŠØ¨ ÙƒÙ„ Ø²ÙˆØ¬
    for idx, row in pairs_df.iterrows():
        symbol = row['symbol']
        count = row['count']
        table_name = row.get('table', f"{symbol}_processed")
        
        logger.info(f"\n{'='*60}")
        logger.info(f"[{idx+1}/{len(pairs_df)}] Training {symbol} ({count:,} M15 candles)")
        
        for timeframe in timeframes:
            try:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† Ø¬Ø¯ÙˆÙ„ price_data Ø£ÙˆÙ„Ø§Ù‹
                success = False
                
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ù…Ø²
                clean_symbol = symbol.replace('m', '').replace('.ecn', '').upper()
                
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¹Ø§Ø¯ÙŠ
                try:
                    success = system.train_enhanced_models(clean_symbol, timeframe)
                except:
                    # Ø¥Ø°Ø§ ÙØ´Ù„ØŒ Ø¬Ø±Ø¨ Ù…Ù† Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø©
                    logger.info("   ğŸ”„ Trying direct table training...")
                    success = train_from_processed_tables(system, symbol, timeframe, table_name)
                
                if success:
                    logger.info(f"   âœ… {timeframe} training completed")
                    total_models += 1
                else:
                    logger.warning(f"   âš ï¸ {timeframe} training failed")
                    failed_models += 1
                    
            except Exception as e:
                logger.error(f"   âŒ Error: {e}")
                failed_models += 1
        
        # ØªÙˆÙ‚Ù Ø¨Ø¹Ø¯ 5 Ø£Ø²ÙˆØ§Ø¬ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
        if idx >= 4:
            logger.info("\nğŸ“Š Stopping after 5 pairs for testing...")
            break
    
    # Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    logger.info("\n" + "="*80)
    logger.info("ğŸ Training Report")
    logger.info("="*80)
    logger.info(f"âœ… Models trained: {total_models}")
    logger.info(f"âŒ Failed: {failed_models}")
    
    if total_models > 0:
        logger.info(f"\nâœ… Successfully trained {total_models} models!")
        logger.info("ğŸš€ System is ready for trading with available models")
    else:
        logger.info("\nâš ï¸ No models were trained successfully")
        logger.info("ğŸ’¡ Try running: python3 direct_data_merger.py first")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.info("\nâš ï¸ Training interrupted by user")
    except Exception as e:
        logger.error(f"\nâŒ Fatal error: {e}")
        import traceback
        traceback.print_exc()