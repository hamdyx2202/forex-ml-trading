#!/usr/bin/env python3
"""
Fix Model Names Mismatch
Ø¥ØµÙ„Ø§Ø­ Ø¹Ø¯Ù… ØªØ·Ø§Ø¨Ù‚ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
"""

import os
import shutil
from pathlib import Path
import glob

print("ğŸ”§ Fixing model names mismatch...")
print("=" * 60)

print("\nğŸ“Š Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:")
print("Ø§Ù„Ø®Ø§Ø¯Ù… ÙŠØ¨Ø­Ø« Ø¹Ù†: models/advanced/EURJPYm_PERIOD_H1.pkl")
print("Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙØ¹Ù„ÙŠØ§Ù‹: models/advanced/EURJPYm_PERIOD_H1_ensemble_20250814_152901.pkl")

# Ø§Ù„Ø­Ù„ 1: Ø¥Ù†Ø´Ø§Ø¡ Ø±ÙˆØ§Ø¨Ø· Ø±Ù…Ø²ÙŠØ©
print("\nğŸ”— Solution 1: Creating symbolic links...")

models_dir = Path("models/advanced")
if models_dir.exists():
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¹ timestamps
    model_files = list(models_dir.glob("*_ensemble_*.pkl"))
    
    print(f"Found {len(model_files)} models with timestamps")
    
    for model_file in model_files:
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        filename = model_file.stem  # e.g., EURJPYm_PERIOD_H1_ensemble_20250814_152901
        
        if '_ensemble_' in filename:
            base_name = filename.split('_ensemble_')[0]  # EURJPYm_PERIOD_H1
            simple_name = base_name + '.pkl'
            simple_path = models_dir / simple_name
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ø±Ù…Ø²ÙŠ Ø£Ùˆ Ù†Ø³Ø®Ø©
            if not simple_path.exists():
                try:
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ø±Ù…Ø²ÙŠ (ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Linux)
                    os.symlink(model_file.name, simple_path)
                    print(f"âœ… Created symlink: {simple_name} -> {model_file.name}")
                except:
                    # Ø¥Ø°Ø§ ÙØ´Ù„ØŒ Ø§Ù†Ø³Ø® Ø§Ù„Ù…Ù„Ù
                    shutil.copy2(model_file, simple_path)
                    print(f"âœ… Copied: {model_file.name} -> {simple_name}")

# Ø§Ù„Ø­Ù„ 2: ØªØ­Ø¯ÙŠØ« advanced_predictor_95.py Ù„Ø¥Ø¸Ù‡Ø§Ø± debugging
print("\nğŸ“ Solution 2: Adding debug info to predictor...")

predictor_file = "src/advanced_predictor_95.py"
if os.path.exists(predictor_file):
    with open(predictor_file, 'r') as f:
        content = f.read()
    
    # Ø¥Ø¶Ø§ÙØ© debugging
    if 'def load_latest_models(self):' in content and 'print(f"Available models: {list(self.models.keys())}")' not in content:
        # Ø¥Ø¶Ø§ÙØ© Ø³Ø·Ø± debugging
        lines = content.split('\n')
        new_lines = []
        
        for i, line in enumerate(lines):
            new_lines.append(line)
            if 'print(f"âœ… Loaded {loaded_count} advanced models")' in line:
                indent = len(line) - len(line.lstrip())
                new_lines.append(' ' * indent + 'print(f"Available models: {list(self.models.keys())}")')
        
        content = '\n'.join(new_lines)
        
        with open(predictor_file + '.backup', 'w') as f:
            f.write(content)
        
        with open(predictor_file, 'w') as f:
            f.write(content)
        
        print("âœ… Added debug info to predictor")

# Ø§Ù„Ø­Ù„ 3: Ø¥Ù†Ø´Ø§Ø¡ wrapper Ù…Ø­Ø¯Ø« Ù„Ù„Ø®Ø§Ø¯Ù…
print("\nğŸ”§ Solution 3: Creating updated server wrapper...")

server_wrapper = '''#!/usr/bin/env python3
"""
Fixed Model Loading Server
Ø®Ø§Ø¯Ù… Ù…Ø­Ø¯Ø« Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
"""

import sys
import os
from pathlib import Path
from datetime import datetime
import pandas as pd
import numpy as np
from loguru import logger
import glob
import joblib

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

# ØªØ­Ø¯ÙŠØ« advanced_predictor Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø£Ø³Ù…Ø§Ø¡ Ù…Ø®ØªÙ„ÙØ©
from src.advanced_predictor_95 import AdvancedPredictor

# ØªØ¹Ø¯ÙŠÙ„ Ø¯Ø§Ù„Ø© load_latest_models
original_load = AdvancedPredictor.load_latest_models

def new_load_latest_models(self):
    """ØªØ­Ù…ÙŠÙ„ Ø£Ø­Ø¯Ø« Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© - Ù…Ø­Ø¯Ø«"""
    model_dir = Path("models/advanced")
    if not model_dir.exists():
        print("âš ï¸ No advanced models found")
        return
        
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    model_files = list(model_dir.glob("*.pkl"))
    if not model_files:
        print("âš ï¸ No models found")
        return
    
    print(f"\\nğŸ“ Found {len(model_files)} model files")
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ù…Ù„Ù
    loaded_count = 0
    for model_file in model_files:
        try:
            filename = model_file.stem
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙØªØ§Ø­ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
            if '_ensemble_' in filename:
                # Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ timestamp
                key = filename.split('_ensemble_')[0]
            elif filename.count('_') >= 2:
                # Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø³ÙŠØ· (Ù…Ø«Ù„ EURJPYm_PERIOD_H1)
                key = filename
            else:
                # ØªØ®Ø·ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª ØºÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
                continue
            
            print(f"ğŸ” Loading {filename} as key: {key}")
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model_data = joblib.load(model_file)
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            self.models[key] = model_data['model']
            self.scalers[key] = model_data['scaler']
            self.metrics[key] = model_data.get('metrics', {})
            
            # Ø¥Ø¶Ø§ÙØ© Ù†Ø³Ø® Ø¨Ø¯ÙŠÙ„Ø© Ù„Ù„Ù…ÙØªØ§Ø­ Ù„Ù„ØªÙˆØ§ÙÙ‚
            if '_PERIOD_' in key:
                # Ø¥Ø¶Ø§ÙØ© Ù†Ø³Ø®Ø© Ø¨Ø¯ÙˆÙ† PERIOD_
                alt_key = key.replace('_PERIOD_', '_')
                self.models[alt_key] = model_data['model']
                self.scalers[alt_key] = model_data['scaler']
                self.metrics[alt_key] = model_data.get('metrics', {})
                print(f"  â• Also added as: {alt_key}")
            
            loaded_count += 1
            print(f"  âœ… Loaded successfully")
                
        except Exception as e:
            print(f"  âŒ Error loading {model_file}: {e}")
    
    print(f"\\nâœ… Loaded {loaded_count} models")
    print(f"ğŸ“Š Available model keys: {list(self.models.keys())}")

# Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø¯Ø§Ù„Ø©
AdvancedPredictor.load_latest_models = new_load_latest_models

# Ø§Ù„Ø¢Ù† Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù…
print("ğŸš€ Starting server with fixed model loading...")
from src.mt5_bridge_server_advanced import app

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=5000, debug=False)
'''

with open('server_fixed_models.py', 'w') as f:
    f.write(server_wrapper)

print("âœ… Created server_fixed_models.py")

# Ø§Ù„Ø­Ù„ 4: ÙØ­Øµ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
print("\nğŸ” Checking existing models...")

if models_dir.exists():
    all_models = list(models_dir.glob("*.pkl"))
    print(f"\nAll .pkl files in models/advanced/:")
    for model in sorted(all_models):
        print(f"  â€¢ {model.name}")
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©
    print("\nğŸ“‹ Expected model names by server:")
    symbols = ['EURUSDm', 'GBPUSDm', 'USDJPYm', 'USDCHFm', 'AUDUSDm', 'USDCADm', 'NZDUSDm', 'EURJPYm']
    timeframes = ['PERIOD_M5', 'PERIOD_M15', 'PERIOD_H1', 'PERIOD_H4']
    
    for symbol in symbols:
        for timeframe in timeframes:
            expected_name = f"{symbol}_{timeframe}.pkl"
            expected_path = models_dir / expected_name
            if expected_path.exists():
                print(f"  âœ… {expected_name}")
            else:
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ timestamp
                pattern = f"{symbol}_{timeframe}_*.pkl"
                matches = list(models_dir.glob(pattern))
                if matches:
                    print(f"  âš ï¸ {expected_name} -> Found: {matches[0].name}")
                else:
                    print(f"  âŒ {expected_name} - Not found")

print("\n" + "="*60)
print("âœ… Solutions created!")
print("\nğŸš€ Try one of these:")
print("1. python server_fixed_models.py  (Recommended)")
print("2. Restart server to use symlinks/copies")
print("3. Check debug output to see loaded model names")