#!/usr/bin/env python3
"""
ğŸš€ Enhanced ML Server - Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ (Ù…Ø­Ø¯Ø«)
ğŸ“Š ÙŠØ³ØªØ®Ø¯Ù… Profit-based metrics Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Accuracy
ğŸ’° Ù†Ø¸Ø§Ù… Ù‚Ø§Ø¯Ø± Ø¹Ù„Ù‰ ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ù…Ø³ØªØ¯Ø§Ù… Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ù…Ø®Ø§Ø·Ø± Ù…ØªÙ‚Ø¯Ù…Ø©
"""

import os
import sys
import json
import logging
import threading
import sqlite3
import joblib
import numpy as np
import pandas as pd
import warnings
import time
from datetime import datetime, timedelta
from flask import Flask, request, jsonify
from flask_cors import CORS

# Ø¥Ø®ÙØ§Ø¡ ØªØ­Ø°ÙŠØ±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)
warnings.filterwarnings('ignore', message='DataFrame is highly fragmented')

# ML Libraries
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.feature_selection import SelectKBest, f_classif

# Import our custom systems
from market_analysis_engine import MarketAnalysisEngine
from risk_management_system import RiskManagementSystem

# Optional libraries
try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except:
    LIGHTGBM_AVAILABLE = False

try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except:
    XGBOOST_AVAILABLE = False

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('enhanced_ml_server.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Flask app
app = Flask(__name__)
CORS(app)

class EnhancedMLTradingSystem:
    """Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ Ù„Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ø°ÙƒÙŠ - Ù…Ø­Ø¯Ø« Ø¨Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø±Ø¨Ø­ÙŠØ©"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.feature_selectors = {}  # Ù„Ø­ÙØ¸ feature selectors
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
        self.db_path = './data/forex_ml.db'
        self.models_dir = './trained_models'
        
        os.makedirs(self.models_dir, exist_ok=True)
        
        # Initialize subsystems
        self.market_analyzer = MarketAnalysisEngine(self.db_path)
        self.risk_manager = RiskManagementSystem(initial_balance=10000)
        
        # Trading parameters - Ù…Ø­Ø¯Ø«Ø©
        self.min_confidence = 0.70  # Ø±ÙØ¹ Ù…Ù† 0.55 Ø¥Ù„Ù‰ 0.70
        self.min_market_score = 40  # Ø±ÙØ¹ Ù…Ù† 20 Ø¥Ù„Ù‰ 40
        self.max_daily_trades = 10
        self.trade_cooldown = {}
        
        # Performance tracking
        self.performance_tracker = {
            'predictions': [],
            'trades': [],
            'daily_stats': {},
            'model_performance': {},  # Ø£Ø¯Ø§Ø¡ ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬
            'model_weights': {}  # Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ù„ØªØµÙˆÙŠØª
        }
        
        # Position management
        self.open_positions = {}
        self.trailing_stop_levels = {}
        
        # Load existing models
        self.load_existing_models()
        
        logger.info(f"âœ… Enhanced ML Trading System initialized (Profit-based)")
        logger.info(f"   ğŸ“Š Min Confidence: {self.min_confidence}")
        logger.info(f"   ğŸ“Š Min Market Score: {self.min_market_score}")
    
    def calculate_trading_metrics(self, y_true, y_pred, prices, lot_sizes=None):
        """Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† accuracy"""
        if lot_sizes is None:
            lot_sizes = np.ones(len(y_true))
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹ÙˆØ§Ø¦Ø¯
        returns = []
        wins = []
        losses = []
        
        for i in range(len(y_true) - 1):
            if y_pred[i] == 1:  # Buy signal
                ret = prices[i+1] - prices[i]
            else:  # Sell signal  
                ret = prices[i] - prices[i+1]
            
            returns.append(ret * lot_sizes[i])
            if ret > 0:
                wins.append(ret * lot_sizes[i])
            elif ret < 0:
                losses.append(abs(ret * lot_sizes[i]))
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        total_return = sum(returns) if returns else 0
        num_trades = len(returns)
        num_wins = len(wins)
        num_losses = len(losses)
        
        # Profit Factor
        profit_factor = sum(wins) / sum(losses) if losses and sum(losses) > 0 else float('inf') if wins else 0
        
        # Win Rate
        win_rate = num_wins / num_trades if num_trades > 0 else 0
        
        # Expected Return
        expected_return = total_return / num_trades if num_trades > 0 else 0
        
        # Risk-Reward Ratio
        avg_win = sum(wins) / len(wins) if wins else 0
        avg_loss = sum(losses) / len(losses) if losses else 0
        risk_reward = avg_win / avg_loss if avg_loss > 0 else float('inf')
        
        # Maximum Drawdown
        if returns:
            cumulative = np.cumsum(returns)
            running_max = np.maximum.accumulate(cumulative)
            drawdown = np.where(running_max > 0, (cumulative - running_max) / running_max, 0)
            max_drawdown = abs(np.min(drawdown))
        else:
            max_drawdown = 0
        
        return {
            'total_return': total_return,
            'profit_factor': profit_factor,
            'win_rate': win_rate,
            'expected_return': expected_return,
            'risk_reward_ratio': risk_reward,
            'max_drawdown': max_drawdown,
            'num_trades': num_trades
        }
    
    def calculate_kelly_position(self, symbol, confidence=0.7):
        """Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„ØµÙÙ‚Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ø¯Ù„Ø© Kelly Ù…Ø­Ø³Ù†Ø©"""
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù‡Ø°Ø§ Ø§Ù„Ø±Ù…Ø²
        key = f"{symbol}_performance"
        if key in self.performance_tracker['model_performance']:
            perf = self.performance_tracker['model_performance'][key]
            win_rate = perf.get('win_rate', 0.5)
            avg_win = perf.get('avg_win', 1)
            avg_loss = perf.get('avg_loss', 1)
        else:
            # Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…Ø­Ø§ÙØ¸Ø©
            win_rate = 0.5
            avg_win = 1
            avg_loss = 1
        
        if avg_win <= 0 or win_rate <= 0:
            return 0.005  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ 0.5%
        
        # Kelly formula
        loss_rate = 1 - win_rate
        kelly_percentage = (win_rate * avg_win - loss_rate * avg_loss) / avg_win
        
        # Ø¶Ø¨Ø· Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø«Ù‚Ø©
        kelly_percentage *= confidence
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ø¯ÙˆØ¯ (0.5% - 2%)
        kelly_percentage = max(0.005, min(0.02, kelly_percentage))
        
        return kelly_percentage
    
    def update_trailing_stop(self, symbol, current_price, entry_price, current_sl, direction):
        """Ù†Ø¸Ø§Ù… Trailing Stop Loss Ù…Ø­Ø¯Ø«"""
        profit_pct = 0
        
        if direction == 'BUY':
            profit_pct = (current_price - entry_price) / entry_price
            
            # Trailing rules for BUY
            if profit_pct > 0.03:  # Ø±Ø¨Ø­ > 3%
                new_sl = entry_price * 1.02  # SL Ø¹Ù†Ø¯ +2%
            elif profit_pct > 0.02:  # Ø±Ø¨Ø­ > 2%
                new_sl = entry_price * 1.01  # SL Ø¹Ù†Ø¯ +1%
            elif profit_pct > 0.01:  # Ø±Ø¨Ø­ > 1%
                new_sl = entry_price  # SL Ø¹Ù†Ø¯ Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„
            else:
                return current_sl  # Ù„Ø§ ØªØºÙŠÙŠØ±
            
            # ØªØ­Ø¯ÙŠØ« ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† SL Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø£ÙØ¶Ù„
            if new_sl > current_sl:
                logger.info(f"ğŸ“ˆ Trailing SL for {symbol}: {current_sl:.5f} â†’ {new_sl:.5f} (Profit: {profit_pct:.1%})")
                return new_sl
                
        else:  # SELL
            profit_pct = (entry_price - current_price) / entry_price
            
            # Trailing rules for SELL
            if profit_pct > 0.03:  # Ø±Ø¨Ø­ > 3%
                new_sl = entry_price * 0.98  # SL Ø¹Ù†Ø¯ -2%
            elif profit_pct > 0.02:  # Ø±Ø¨Ø­ > 2%
                new_sl = entry_price * 0.99  # SL Ø¹Ù†Ø¯ -1%
            elif profit_pct > 0.01:  # Ø±Ø¨Ø­ > 1%
                new_sl = entry_price  # SL Ø¹Ù†Ø¯ Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„
            else:
                return current_sl  # Ù„Ø§ ØªØºÙŠÙŠØ±
            
            # ØªØ­Ø¯ÙŠØ« ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† SL Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø£ÙØ¶Ù„
            if new_sl < current_sl:
                logger.info(f"ğŸ“ˆ Trailing SL for {symbol}: {current_sl:.5f} â†’ {new_sl:.5f} (Profit: {profit_pct:.1%})")
                return new_sl
        
        return current_sl
    
    def check_entry_conditions(self, market_context, prediction_confidence):
        """ÙØ­Øµ Ø´Ø±ÙˆØ· Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ø­Ø³Ù†Ø© - ÙŠØ¬Ø¨ ØªØ­Ù‚Ù‚ 3 Ù…Ù† 4 Ø´Ø±ÙˆØ·"""
        conditions_met = 0
        conditions_details = []
        
        # 1. Volume Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø§Ù„Ù…ØªÙˆØ³Ø· Ø¨Ù€ 50%
        volume_ratio = market_context.get('volume', {}).get('volume_ratio', 1)
        if volume_ratio > 1.5:
            conditions_met += 1
            conditions_details.append("High volume")
        
        # 2. RSI Ø¨ÙŠÙ† 30-70
        rsi = market_context.get('momentum', {}).get('rsi', 50)
        if 30 <= rsi <= 70:
            conditions_met += 1
            conditions_details.append("Good RSI")
        
        # 3. Trend alignment
        trend_alignment = market_context.get('trend', {}).get('alignment', False)
        if trend_alignment:
            conditions_met += 1
            conditions_details.append("Trend aligned")
        
        # 4. No news time
        is_news_time = market_context.get('session', {}).get('is_news_time', False)
        if not is_news_time:
            conditions_met += 1
            conditions_details.append("No news")
        
        # ÙŠØ¬Ø¨ ØªØ­Ù‚Ù‚ 3 Ù…Ù† 4 Ø´Ø±ÙˆØ· Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„
        if conditions_met >= 3:
            logger.info(f"   âœ… Entry conditions met ({conditions_met}/4): {', '.join(conditions_details)}")
            return True
        else:
            logger.info(f"   âŒ Entry conditions not met ({conditions_met}/4)")
            return False
    
    def calculate_model_weights(self):
        """Ø­Ø³Ø§Ø¨ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        for key, performances in self.performance_tracker['model_performance'].items():
            if isinstance(performances, list) and len(performances) > 0:
                # Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬
                model_scores = {}
                
                for perf in performances[-100:]:  # Ø¢Ø®Ø± 100 ØµÙÙ‚Ø©
                    model = perf['model']
                    profit = perf['profit']
                    
                    if model not in model_scores:
                        model_scores[model] = []
                    model_scores[model].append(profit)
                
                # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆØ²Ù† Ù„ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬
                weights = {}
                for model, profits in model_scores.items():
                    avg_profit = np.mean(profits)
                    # Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø®Ø§Ø³Ø± ÙˆØ²Ù†Ù‡ 0.5ØŒ Ø§Ù„Ø±Ø§Ø¨Ø­ 1.5
                    weight = 1.5 if avg_profit > 0 else 0.5
                    weights[model] = weight
                
                self.model_weights[key] = weights
    
    def train_enhanced_models(self, symbol, timeframe):
        """ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¹ Time Series Split ÙˆÙ…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø±Ø¨Ø­ÙŠØ©"""
        try:
            logger.info(f"ğŸ¤– Training enhanced models for {symbol} {timeframe}...")
            
            # Load data
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Try different symbol formats
            possible_symbols = [symbol, f"{symbol}m", f"{symbol}.ecn", symbol.lower()]
            
            df = None
            for sym in possible_symbols:
                cursor.execute("""
                    SELECT * FROM price_data 
                    WHERE symbol = ? OR symbol LIKE ?
                    ORDER BY time ASC
                    LIMIT 50000
                """, (sym, f"{sym}%"))
                
                data = cursor.fetchall()
                if data:
                    columns = [desc[0] for desc in cursor.description]
                    df = pd.DataFrame(data, columns=columns)
                    logger.info(f"Found {len(df)} records with symbol: {sym}")
                    break
            
            conn.close()
            
            if df is None or len(df) < 5000:
                logger.warning(f"Not enough data for {symbol}")
                return False
            
            # Prepare data
            df['time'] = pd.to_datetime(df['time'])
            df.set_index('time', inplace=True)
            df = df.sort_index()
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ø£Ø±Ù‚Ø§Ù…
            for col in ['open', 'high', 'low', 'close', 'tick_volume']:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            df = df.dropna()
            
            # Create features with market context
            logger.info("   ğŸ“Š Creating features with market context...")
            
            X_list = []
            y_list = []
            prices_list = []
            
            # Process data
            window_size = 200
            skip_size = 20  # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ 20 Ø´Ù…Ø¹Ø© Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            
            for i in range(window_size, len(df) - 1, skip_size):
                window_data = df.iloc[i-window_size:i]
                
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙˆÙ‚
                market_context = self.market_analyzer.analyze_complete_market_context(
                    symbol, window_data.reset_index().to_dict('records'), timeframe
                )
                
                if market_context and abs(market_context['score']) > 20:
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª
                    features = self.calculate_enhanced_features(window_data, market_context)
                    
                    if not features.empty:
                        X_list.append(features.iloc[-1].values)
                        
                        # Ø§Ù„ØªÙ†Ø¨Ø¤: Ù‡Ù„ Ø§Ù„Ø³Ø¹Ø± Ø³ÙŠØ±ØªÙØ¹ØŸ
                        future_return = df['close'].iloc[i] - df['close'].iloc[i-1]
                        y_list.append(1 if future_return > 0 else 0)
                        
                        # Ø§Ù„Ø³Ø¹Ø± Ù„Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
                        prices_list.append(df['close'].iloc[i-1])
            
            if len(X_list) < 1000:
                logger.warning(f"Not enough quality samples: {len(X_list)}")
                return False
            
            # Convert to arrays
            X = np.array(X_list)
            y = np.array(y_list)
            prices = np.array(prices_list)
            
            logger.info(f"   ğŸ“Š Created {len(X)} training samples")
            
            # Feature Selection - Ø£ÙØ¶Ù„ 50 Ù…ÙŠØ²Ø©
            selector = SelectKBest(f_classif, k=min(50, X.shape[1]))
            X_selected = selector.fit_transform(X, y)
            
            # Ø­ÙØ¸ selector
            key = f"{symbol}_{timeframe}"
            self.feature_selectors[key] = selector
            
            # Time Series Split
            tscv = TimeSeriesSplit(n_splits=5)
            best_models = {}
            
            logger.info("   ğŸ”„ Training with Time Series Cross-Validation...")
            
            for fold, (train_idx, test_idx) in enumerate(tscv.split(X_selected)):
                logger.info(f"   ğŸ“Š Fold {fold+1}/5...")
                
                X_train = X_selected[train_idx]
                X_test = X_selected[test_idx]
                y_train = y[train_idx]
                y_test = y[test_idx]
                prices_test = prices[test_idx]
                
                # Scale
                scaler = RobustScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)
                
                # Ø­ÙØ¸ Ø¢Ø®Ø± scaler
                if fold == 4:
                    self.scalers[key] = scaler
                
                # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
                fold_models = {}
                
                # 1. Random Forest
                try:
                    rf = RandomForestClassifier(
                        n_estimators=200, max_depth=15, min_samples_split=5,
                        random_state=42, n_jobs=-1
                    )
                    rf.fit(X_train_scaled, y_train)
                    y_pred = rf.predict(X_test_scaled)
                    
                    metrics = self.calculate_trading_metrics(y_test, y_pred, prices_test)
                    
                    if metrics['profit_factor'] > 1.2 and metrics['total_return'] > 0:
                        fold_models['random_forest'] = {
                            'model': rf,
                            'metrics': metrics
                        }
                        logger.info(f"      âœ… RF: PF={metrics['profit_factor']:.2f}, Return={metrics['total_return']:.2f}")
                except Exception as e:
                    logger.error(f"      âŒ RF: {e}")
                
                # 2. Gradient Boosting
                try:
                    gb = GradientBoostingClassifier(
                        n_estimators=150, learning_rate=0.05, max_depth=6,
                        random_state=42
                    )
                    gb.fit(X_train_scaled, y_train)
                    y_pred = gb.predict(X_test_scaled)
                    
                    metrics = self.calculate_trading_metrics(y_test, y_pred, prices_test)
                    
                    if metrics['profit_factor'] > 1.2 and metrics['total_return'] > 0:
                        fold_models['gradient_boosting'] = {
                            'model': gb,
                            'metrics': metrics
                        }
                        logger.info(f"      âœ… GB: PF={metrics['profit_factor']:.2f}, Return={metrics['total_return']:.2f}")
                except Exception as e:
                    logger.error(f"      âŒ GB: {e}")
                
                # 3. Extra Trees
                try:
                    et = ExtraTreesClassifier(
                        n_estimators=200, max_depth=15, min_samples_split=5,
                        random_state=42, n_jobs=-1
                    )
                    et.fit(X_train_scaled, y_train)
                    y_pred = et.predict(X_test_scaled)
                    
                    metrics = self.calculate_trading_metrics(y_test, y_pred, prices_test)
                    
                    if metrics['profit_factor'] > 1.2 and metrics['total_return'] > 0:
                        fold_models['extra_trees'] = {
                            'model': et,
                            'metrics': metrics
                        }
                        logger.info(f"      âœ… ET: PF={metrics['profit_factor']:.2f}, Return={metrics['total_return']:.2f}")
                except Exception as e:
                    logger.error(f"      âŒ ET: {e}")
                
                # 4. Neural Network
                try:
                    nn = MLPClassifier(
                        hidden_layer_sizes=(100, 50, 25),
                        activation='relu', solver='adam',
                        max_iter=500, random_state=42
                    )
                    nn.fit(X_train_scaled, y_train)
                    y_pred = nn.predict(X_test_scaled)
                    
                    metrics = self.calculate_trading_metrics(y_test, y_pred, prices_test)
                    
                    if metrics['profit_factor'] > 1.2 and metrics['total_return'] > 0:
                        fold_models['neural_network'] = {
                            'model': nn,
                            'metrics': metrics
                        }
                        logger.info(f"      âœ… NN: PF={metrics['profit_factor']:.2f}, Return={metrics['total_return']:.2f}")
                except Exception as e:
                    logger.error(f"      âŒ NN: {e}")
                
                # 5. LightGBM
                if LIGHTGBM_AVAILABLE:
                    try:
                        lgbm = lgb.LGBMClassifier(
                            n_estimators=200, num_leaves=50, learning_rate=0.05,
                            random_state=42, verbosity=-1
                        )
                        lgbm.fit(X_train_scaled, y_train)
                        y_pred = lgbm.predict(X_test_scaled)
                        
                        metrics = self.calculate_trading_metrics(y_test, y_pred, prices_test)
                        
                        if metrics['profit_factor'] > 1.2 and metrics['total_return'] > 0:
                            fold_models['lightgbm'] = {
                                'model': lgbm,
                                'metrics': metrics
                            }
                            logger.info(f"      âœ… LGBM: PF={metrics['profit_factor']:.2f}, Return={metrics['total_return']:.2f}")
                    except Exception as e:
                        logger.error(f"      âŒ LGBM: {e}")
                
                # 6. XGBoost
                if XGBOOST_AVAILABLE:
                    try:
                        xgb_model = xgb.XGBClassifier(
                            n_estimators=200, max_depth=6, learning_rate=0.05,
                            random_state=42, use_label_encoder=False
                        )
                        xgb_model.fit(X_train_scaled, y_train)
                        y_pred = xgb_model.predict(X_test_scaled)
                        
                        metrics = self.calculate_trading_metrics(y_test, y_pred, prices_test)
                        
                        if metrics['profit_factor'] > 1.2 and metrics['total_return'] > 0:
                            fold_models['xgboost'] = {
                                'model': xgb_model,
                                'metrics': metrics
                            }
                            logger.info(f"      âœ… XGB: PF={metrics['profit_factor']:.2f}, Return={metrics['total_return']:.2f}")
                    except Exception as e:
                        logger.error(f"      âŒ XGB: {e}")
                
                # ØªØ­Ø¯ÙŠØ« Ø£ÙØ¶Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
                for model_name, model_data in fold_models.items():
                    if model_name not in best_models or \
                       model_data['metrics']['profit_factor'] > best_models[model_name]['metrics']['profit_factor']:
                        best_models[model_name] = model_data
            
            # Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            if best_models:
                self.models[key] = {}
                
                logger.info(f"   ğŸ’¾ Saving best models...")
                for model_name, model_data in best_models.items():
                    self.models[key][model_name] = model_data['model']
                    
                    # Ø­ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø±Øµ
                    model_path = os.path.join(self.models_dir, f"{symbol}_{timeframe}_{model_name}_enhanced.pkl")
                    joblib.dump(model_data['model'], model_path)
                    
                    logger.info(f"      âœ… {model_name}: PF={model_data['metrics']['profit_factor']:.2f}")
                
                # Ø­ÙØ¸ scaler Ùˆ selector
                scaler_path = os.path.join(self.models_dir, f"{symbol}_{timeframe}_scaler_enhanced.pkl")
                joblib.dump(self.scalers[key], scaler_path)
                
                selector_path = os.path.join(self.models_dir, f"{symbol}_{timeframe}_selector_enhanced.pkl")
                joblib.dump(self.feature_selectors[key], selector_path)
                
                logger.info(f"âœ… Successfully trained {len(best_models)} profitable models for {symbol} {timeframe}!")
                return True
            else:
                logger.warning(f"âŒ No profitable models found for {symbol} {timeframe}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Training error: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def calculate_enhanced_features(self, df, market_context=None):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ù…Ø¹ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³ÙˆÙ‚"""
        features = pd.DataFrame(index=[df.index[-1]])
        
        # Basic price features
        features['returns'] = df['close'].pct_change().iloc[-1]
        features['log_returns'] = np.log(df['close'] / df['close'].shift(1)).iloc[-1]
        
        # Moving averages
        for period in [5, 10, 20, 50]:
            features[f'sma_{period}'] = df['close'].rolling(period).mean().iloc[-1]
            features[f'sma_{period}_ratio'] = df['close'].iloc[-1] / features[f'sma_{period}']
        
        # RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain.iloc[-1] / loss.iloc[-1] if loss.iloc[-1] != 0 else 0
        features['rsi'] = 100 - (100 / (1 + rs))
        
        # Bollinger Bands
        sma20 = df['close'].rolling(20).mean().iloc[-1]
        std20 = df['close'].rolling(20).std().iloc[-1]
        features['bb_upper'] = sma20 + 2 * std20
        features['bb_lower'] = sma20 - 2 * std20
        features['bb_position'] = (df['close'].iloc[-1] - features['bb_lower']) / (features['bb_upper'] - features['bb_lower'])
        
        # Volume features
        features['volume_ratio'] = df['tick_volume'].iloc[-1] / df['tick_volume'].rolling(20).mean().iloc[-1]
        
        # Market context features
        if market_context:
            features['market_score'] = market_context.get('score', 0)
            features['trend_strength'] = market_context.get('trend', {}).get('strength', 0)
            features['support_distance'] = market_context.get('support_resistance', {}).get('distance_to_support', 0)
            features['resistance_distance'] = market_context.get('support_resistance', {}).get('distance_to_resistance', 0)
            features['volume_signal'] = 1 if market_context.get('volume', {}).get('volume_signal') == 'BULLISH_CONFIRMATION' else -1
            features['is_news_time'] = 1 if market_context.get('session', {}).get('is_news_time') else 0
        
        return features
    
    def predict_with_weighted_ensemble(self, symbol, timeframe, df):
        """Ø§Ù„ØªÙ†Ø¨Ø¤ Ù…Ø¹ ØªØµÙˆÙŠØª Ù…Ø±Ø¬Ø­ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        try:
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙˆÙ‚
            market_context = self.market_analyzer.analyze_complete_market_context(
                symbol, df.reset_index().to_dict('records'), timeframe
            )
            
            if not market_context:
                logger.warning("Failed to analyze market context")
                return self._simple_fallback_prediction(df)
            
            # ÙØ­Øµ Ø´Ø±ÙˆØ· Ø§Ù„Ø³ÙˆÙ‚
            market_score = market_context['score']
            
            logger.info(f"   ğŸ“Š Market Score: {market_score}")
            
            # Ø±ÙØ¶ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø¶Ø¹ÙŠÙØ©
            if abs(market_score) < self.min_market_score:
                logger.info(f"   âŒ Weak market score: {market_score} < {self.min_market_score}")
                return {
                    'action': 2,
                    'direction': 'HOLD',
                    'confidence': 0.0,
                    'reason': 'Weak market conditions'
                }
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª
            features = self.calculate_enhanced_features(df, market_context)
            
            if features.empty:
                return self._simple_fallback_prediction(df)
            
            # ØªØ·Ø¨ÙŠÙ‚ feature selection Ùˆ scaling
            key = f"{symbol}_{timeframe}"
            
            if key not in self.models or key not in self.feature_selectors:
                logger.warning(f"No models or selectors for {key}")
                return self._simple_fallback_prediction(df)
            
            # Feature selection
            X = features.values.reshape(1, -1)
            X_selected = self.feature_selectors[key].transform(X)
            
            # Scaling
            X_scaled = self.scalers[key].transform(X_selected)
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤ Ù…Ù† ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬
            predictions = []
            weights = []
            model_names = []
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            model_weights = self.model_weights.get(key, {})
            
            for model_name, model in self.models[key].items():
                try:
                    pred = model.predict(X_scaled)[0]
                    prob = model.predict_proba(X_scaled)[0]
                    
                    predictions.append(pred)
                    
                    # Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ 1ØŒ Ø£Ùˆ Ù…Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø§Ø¨Ù‚
                    weight = model_weights.get(model_name, 1.0)
                    weights.append(weight)
                    
                    model_names.append(model_name)
                    
                    logger.info(f"      {model_name}: {'BUY' if pred == 1 else 'SELL'} ({max(prob):.2%}) - Weight: {weight:.2f}")
                    
                except Exception as e:
                    logger.error(f"      âŒ {model_name}: {e}")
            
            if not predictions:
                return self._simple_fallback_prediction(df)
            
            # ØªØµÙˆÙŠØª Ù…Ø±Ø¬Ø­
            weighted_sum = sum(p * w for p, w in zip(predictions, weights))
            total_weight = sum(weights)
            weighted_avg = weighted_sum / total_weight
            
            # Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
            if weighted_avg > 0.5:
                direction = 'BUY'
                action = 0
            else:
                direction = 'SELL'
                action = 1
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø©
            confidence = abs(weighted_avg - 0.5) * 2  # ØªØ­ÙˆÙŠÙ„ Ù„Ù†Ø³Ø¨Ø© 0-1
            
            # ÙØ­Øµ Ø´Ø±ÙˆØ· Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©
            if confidence >= self.min_confidence:
                if self.check_entry_conditions(market_context, confidence):
                    logger.info(f"   âœ… Signal: {direction} with {confidence:.1%} confidence")
                    
                    return {
                        'action': action,
                        'direction': direction,
                        'confidence': confidence,
                        'market_context': market_context,
                        'models_used': model_names,
                        'weighted_score': weighted_avg
                    }
                else:
                    return {
                        'action': 2,
                        'direction': 'HOLD',
                        'confidence': confidence,
                        'reason': 'Entry conditions not met'
                    }
            else:
                logger.info(f"   âŒ Low confidence: {confidence:.1%} < {self.min_confidence:.1%}")
                return {
                    'action': 2,
                    'direction': 'HOLD',
                    'confidence': confidence,
                    'reason': 'Low confidence'
                }
                
        except Exception as e:
            logger.error(f"Prediction error: {str(e)}")
            import traceback
            traceback.print_exc()
            return self._simple_fallback_prediction(df)
    
    def _simple_fallback_prediction(self, df):
        """Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¨Ø³ÙŠØ·Ø©"""
        try:
            if len(df) < 20:
                return {
                    'action': 2,
                    'direction': 'HOLD',
                    'confidence': 0.0,
                    'reason': 'Insufficient data'
                }
            
            # Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø¨Ø³ÙŠØ·Ø©
            sma10 = df['close'].rolling(10).mean().iloc[-1]
            sma20 = df['close'].rolling(20).mean().iloc[-1]
            current_price = df['close'].iloc[-1]
            
            # RSI
            delta = df['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain.iloc[-1] / loss.iloc[-1] if loss.iloc[-1] != 0 else 0
            rsi = 100 - (100 / (1 + rs))
            
            # Ù‚Ø±Ø§Ø± Ø¨Ø³ÙŠØ·
            if sma10 > sma20 and current_price > sma10 and 30 < rsi < 70:
                return {
                    'action': 0,
                    'direction': 'BUY',
                    'confidence': 0.6,
                    'reason': 'Simple strategy'
                }
            elif sma10 < sma20 and current_price < sma10 and 30 < rsi < 70:
                return {
                    'action': 1,
                    'direction': 'SELL',
                    'confidence': 0.6,
                    'reason': 'Simple strategy'
                }
            else:
                return {
                    'action': 2,
                    'direction': 'HOLD',
                    'confidence': 0.0,
                    'reason': 'No clear signal'
                }
                
        except Exception as e:
            logger.error(f"Fallback prediction error: {e}")
            return {
                'action': 2,
                'direction': 'HOLD',
                'confidence': 0.0,
                'reason': 'Error in prediction'
            }
    
    def calculate_dynamic_sl_tp_with_partial(self, symbol, direction, entry_price, market_context):
        """Ø­Ø³Ø§Ø¨ SL/TP Ù…Ø¹ Ø¥Ø¶Ø§ÙØ© TP0 Ù„Ù„Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø¬Ø²Ø¦ÙŠ"""
        pip_value = 0.01 if 'JPY' in symbol else 0.0001
        
        # Handle None market_context
        if market_context is None:
            logger.warning(f"No market context for {symbol}, using default SL/TP")
            sl_percentage = 0.002  # 0.2%
            tp0_percentage = 0.0015  # 0.15% - Ù†ØµÙ TP1
            tp1_percentage = 0.003  # 0.3%
            tp2_percentage = 0.005  # 0.5%
            
            if direction == 'BUY':
                return {
                    'sl_price': entry_price * (1 - sl_percentage),
                    'tp0_price': entry_price * (1 + tp0_percentage),  # Ø¥ØºÙ„Ø§Ù‚ 50%
                    'tp1_price': entry_price * (1 + tp1_percentage),
                    'tp2_price': entry_price * (1 + tp2_percentage),
                    'partial_close_at_tp0': 0.5  # Ø¥ØºÙ„Ø§Ù‚ 50% Ø¹Ù†Ø¯ TP0
                }
            else:
                return {
                    'sl_price': entry_price * (1 + sl_percentage),
                    'tp0_price': entry_price * (1 - tp0_percentage),
                    'tp1_price': entry_price * (1 - tp1_percentage),
                    'tp2_price': entry_price * (1 - tp2_percentage),
                    'partial_close_at_tp0': 0.5
                }
        
        # Ø­Ø³Ø§Ø¨ Ù…ØªÙ‚Ø¯Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙˆÙ‚
        atr = market_context['volatility']['atr']
        volatility_level = market_context['volatility']['volatility_level']
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø¶Ø§Ø¹ÙØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‚Ù„Ø¨
        if volatility_level == 'VERY_HIGH':
            sl_multiplier = 3.0
            tp_multiplier = 4.0
        elif volatility_level == 'HIGH':
            sl_multiplier = 2.5
            tp_multiplier = 3.5
        else:
            sl_multiplier = 2.0
            tp_multiplier = 3.0
        
        sl_distance = atr * sl_multiplier
        
        # Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
        sr_levels = market_context.get('support_resistance', {})
        
        if direction == 'BUY':
            # Ø¶Ø¨Ø· SL Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ø¹Ù…
            if sr_levels.get('nearest_support'):
                support_price = sr_levels['nearest_support']['price']
                support_distance = entry_price - support_price
                
                if 0.5 * sl_distance < support_distance < 2 * sl_distance:
                    sl_distance = support_distance + (5 * pip_value)
            
            sl_price = entry_price - sl_distance
            
            # Ø­Ø³Ø§Ø¨ TPs
            tp0_price = entry_price + (sl_distance * 0.75)  # TP0 Ø¹Ù†Ø¯ 75% Ù…Ù† Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©
            tp1_price = entry_price + (sl_distance * 1.5)   # TP1 Ø¹Ù†Ø¯ 1.5x
            tp2_price = entry_price + (sl_distance * 2.5)   # TP2 Ø¹Ù†Ø¯ 2.5x
            
        else:  # SELL
            # Ø¶Ø¨Ø· SL Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
            if sr_levels.get('nearest_resistance'):
                resistance_price = sr_levels['nearest_resistance']['price']
                resistance_distance = resistance_price - entry_price
                
                if 0.5 * sl_distance < resistance_distance < 2 * sl_distance:
                    sl_distance = resistance_distance + (5 * pip_value)
            
            sl_price = entry_price + sl_distance
            
            # Ø­Ø³Ø§Ø¨ TPs
            tp0_price = entry_price - (sl_distance * 0.75)
            tp1_price = entry_price - (sl_distance * 1.5)
            tp2_price = entry_price - (sl_distance * 2.5)
        
        return {
            'sl_price': float(sl_price),
            'tp0_price': float(tp0_price),
            'tp1_price': float(tp1_price),
            'tp2_price': float(tp2_price),
            'sl_pips': float(sl_distance / pip_value),
            'tp0_pips': float(abs(tp0_price - entry_price) / pip_value),
            'tp1_pips': float(abs(tp1_price - entry_price) / pip_value),
            'tp2_pips': float(abs(tp2_price - entry_price) / pip_value),
            'risk_reward_ratio': 1.5,
            'partial_close_at_tp0': 0.5
        }
    
    def load_existing_models(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©"""
        if not os.path.exists(self.models_dir):
            return
        
        loaded_count = 0
        for file in os.listdir(self.models_dir):
            if file.endswith('_enhanced.pkl') and 'scaler' not in file and 'selector' not in file:
                try:
                    parts = file.replace('_enhanced.pkl', '').split('_')
                    if len(parts) >= 3:
                        symbol = parts[0]
                        timeframe = parts[1]
                        model_type = '_'.join(parts[2:])
                        
                        key = f"{symbol}_{timeframe}"
                        if key not in self.models:
                            self.models[key] = {}
                        
                        model_path = os.path.join(self.models_dir, file)
                        self.models[key][model_type] = joblib.load(model_path)
                        
                        # ØªØ­Ù…ÙŠÙ„ scaler
                        scaler_file = f"{symbol}_{timeframe}_scaler_enhanced.pkl"
                        scaler_path = os.path.join(self.models_dir, scaler_file)
                        if os.path.exists(scaler_path):
                            self.scalers[key] = joblib.load(scaler_path)
                        
                        # ØªØ­Ù…ÙŠÙ„ selector
                        selector_file = f"{symbol}_{timeframe}_selector_enhanced.pkl"
                        selector_path = os.path.join(self.models_dir, selector_file)
                        if os.path.exists(selector_path):
                            self.feature_selectors[key] = joblib.load(selector_path)
                        
                        loaded_count += 1
                        
                except Exception as e:
                    logger.error(f"Failed to load {file}: {e}")
        
        logger.info(f"   ğŸ“‚ Loaded {loaded_count} existing models")
        
        # Ø­Ø³Ø§Ø¨ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
        self.calculate_model_weights()
    
    def log_trade(self, symbol, action, entry_price, sl, tp, confidence, market_context, entry_reason):
        """ØªØ³Ø¬ÙŠÙ„ ØªÙØ§ØµÙŠÙ„ ÙƒÙ„ ØµÙÙ‚Ø©"""
        trade_log = {
            'timestamp': datetime.now().isoformat(),
            'symbol': symbol,
            'action': action,
            'entry_price': entry_price,
            'stop_loss': sl,
            'take_profit': tp,
            'confidence': confidence,
            'entry_reason': entry_reason,
            'market_conditions': {
                'score': market_context.get('score', 0) if market_context else 0,
                'volatility': market_context.get('volatility', {}).get('volatility_level', 'UNKNOWN') if market_context else 'UNKNOWN',
                'trend': market_context.get('trend', {}).get('direction', 'UNKNOWN') if market_context else 'UNKNOWN',
                'session': market_context.get('session', {}).get('name', 'UNKNOWN') if market_context else 'UNKNOWN'
            }
        }
        
        self.performance_tracker['trades'].append(trade_log)
        
        # Ø­ÙØ¸ ÙÙŠ Ù…Ù„Ù
        with open('trade_log.json', 'a') as f:
            f.write(json.dumps(trade_log) + '\n')
        
        logger.info(f"   ğŸ“ Trade logged: {symbol} {action} @ {entry_price:.5f}")
    
    def backtest(self, symbol, timeframe, start_date, end_date):
        """Ù†Ø¸Ø§Ù… Backtesting Ù„Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©"""
        try:
            logger.info(f"ğŸ”„ Running backtest for {symbol} {timeframe} from {start_date} to {end_date}")
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            conn = sqlite3.connect(self.db_path)
            query = """
                SELECT * FROM price_data 
                WHERE symbol = ? AND time >= ? AND time <= ?
                ORDER BY time ASC
            """
            
            df = pd.read_sql_query(query, conn, params=(symbol, start_date, end_date))
            conn.close()
            
            if df.empty or len(df) < 1000:
                return {
                    'error': 'Insufficient data for backtesting'
                }
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            df['time'] = pd.to_datetime(df['time'])
            df.set_index('time', inplace=True)
            
            # Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„backtest
            initial_balance = 10000
            balance = initial_balance
            trades = []
            equity_curve = [initial_balance]
            
            # Ø§Ù„Ù…Ø±ÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            window_size = 200
            for i in range(window_size, len(df) - 1):
                window_data = df.iloc[i-window_size:i+1]
                
                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø´Ø§Ø±Ø©
                prediction = self.predict_with_weighted_ensemble(symbol, timeframe, window_data)
                
                if prediction['action'] != 2:  # Ù„ÙŠØ³ HOLD
                    # Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„ØµÙÙ‚Ø©
                    risk_pct = self.calculate_kelly_position(symbol, prediction['confidence'])
                    position_size = balance * risk_pct
                    
                    # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ØµÙÙ‚Ø©
                    entry_price = df['close'].iloc[i]
                    
                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†ØªÙŠØ¬Ø© Ø§Ù„ØµÙÙ‚Ø©
                    if prediction['action'] == 0:  # BUY
                        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙˆÙ„ Ø³Ø¹Ø± ÙŠØ­Ù‚Ù‚ TP Ø£Ùˆ SL
                        for j in range(i+1, min(i+100, len(df))):
                            high = df['high'].iloc[j]
                            low = df['low'].iloc[j]
                            
                            # Ø§ÙØªØ±Ø§Ø¶ SL Ø¹Ù†Ø¯ -1% Ùˆ TP Ø¹Ù†Ø¯ +1.5%
                            sl_price = entry_price * 0.99
                            tp_price = entry_price * 1.015
                            
                            if low <= sl_price:
                                # Ø®Ø³Ø§Ø±Ø©
                                loss = position_size * 0.01
                                balance -= loss
                                trades.append({
                                    'entry_time': df.index[i],
                                    'exit_time': df.index[j],
                                    'type': 'BUY',
                                    'result': 'LOSS',
                                    'pnl': -loss
                                })
                                break
                            elif high >= tp_price:
                                # Ø±Ø¨Ø­
                                profit = position_size * 0.015
                                balance += profit
                                trades.append({
                                    'entry_time': df.index[i],
                                    'exit_time': df.index[j],
                                    'type': 'BUY',
                                    'result': 'WIN',
                                    'pnl': profit
                                })
                                break
                    
                    else:  # SELL
                        for j in range(i+1, min(i+100, len(df))):
                            high = df['high'].iloc[j]
                            low = df['low'].iloc[j]
                            
                            sl_price = entry_price * 1.01
                            tp_price = entry_price * 0.985
                            
                            if high >= sl_price:
                                # Ø®Ø³Ø§Ø±Ø©
                                loss = position_size * 0.01
                                balance -= loss
                                trades.append({
                                    'entry_time': df.index[i],
                                    'exit_time': df.index[j],
                                    'type': 'SELL',
                                    'result': 'LOSS',
                                    'pnl': -loss
                                })
                                break
                            elif low <= tp_price:
                                # Ø±Ø¨Ø­
                                profit = position_size * 0.015
                                balance += profit
                                trades.append({
                                    'entry_time': df.index[i],
                                    'exit_time': df.index[j],
                                    'type': 'SELL',
                                    'result': 'WIN',
                                    'pnl': profit
                                })
                                break
                
                equity_curve.append(balance)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            total_trades = len(trades)
            winning_trades = len([t for t in trades if t['result'] == 'WIN'])
            losing_trades = total_trades - winning_trades
            
            total_profit = sum([t['pnl'] for t in trades if t['pnl'] > 0])
            total_loss = abs(sum([t['pnl'] for t in trades if t['pnl'] < 0]))
            
            # Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            results = {
                'initial_balance': initial_balance,
                'final_balance': balance,
                'total_return': (balance - initial_balance) / initial_balance * 100,
                'total_trades': total_trades,
                'winning_trades': winning_trades,
                'losing_trades': losing_trades,
                'win_rate': winning_trades / total_trades * 100 if total_trades > 0 else 0,
                'profit_factor': total_profit / total_loss if total_loss > 0 else float('inf'),
                'max_drawdown': self._calculate_max_drawdown(equity_curve),
                'trades': trades[-20:]  # Ø¢Ø®Ø± 20 ØµÙÙ‚Ø©
            }
            
            logger.info(f"âœ… Backtest completed:")
            logger.info(f"   Return: {results['total_return']:.2f}%")
            logger.info(f"   Win Rate: {results['win_rate']:.1f}%")
            logger.info(f"   Profit Factor: {results['profit_factor']:.2f}")
            logger.info(f"   Max Drawdown: {results['max_drawdown']:.2f}%")
            
            return results
            
        except Exception as e:
            logger.error(f"Backtest error: {str(e)}")
            import traceback
            traceback.print_exc()
            return {'error': str(e)}
    
    def _calculate_max_drawdown(self, equity_curve):
        """Ø­Ø³Ø§Ø¨ Ø£Ù‚ØµÙ‰ Ø§Ù†Ø®ÙØ§Ø¶"""
        peak = equity_curve[0]
        max_dd = 0
        
        for value in equity_curve:
            if value > peak:
                peak = value
            else:
                dd = (peak - value) / peak * 100
                if dd > max_dd:
                    max_dd = dd
        
        return max_dd


# Global system instance
system = EnhancedMLTradingSystem()

@app.route('/status', methods=['GET'])
def status():
    """ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙŠØ±ÙØ±"""
    return jsonify({
        'status': 'running',
        'version': '3.0',
        'type': 'enhanced_profit_based',
        'models_loaded': sum(len(models) for models in system.models.values()),
        'min_confidence': system.min_confidence,
        'min_market_score': system.min_market_score
    })

@app.route('/predict', methods=['POST'])
def predict():
    """Ø§Ù„ØªÙ†Ø¨Ø¤ Ù…Ø¹ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†"""
    try:
        data = request.json
        symbol = data.get('symbol', '').replace('m', '').upper()
        clean_symbol = data.get('clean_symbol', symbol)
        timeframe = data.get('timeframe', 'M15')
        candles = data.get('candles', [])
        
        if not candles or len(candles) < 50:
            return jsonify({
                'action': 2,
                'direction': 'NONE',
                'confidence': 0.0,
                'error': 'Insufficient data'
            })
        
        # ØªØ­ÙˆÙŠÙ„ Ù„Ù„DataFrame
        df = pd.DataFrame(candles)
        df['time'] = pd.to_datetime(df['time'])
        df.set_index('time', inplace=True)
        
        for col in ['open', 'high', 'low', 'close']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤
        logger.info(f"\nğŸ“Š Request: {symbol} ({clean_symbol}) {timeframe} - {len(candles)} candles")
        
        prediction_result = system.predict_with_weighted_ensemble(clean_symbol, timeframe, df)
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©
        action = prediction_result.get('direction', 'HOLD')
        confidence = prediction_result.get('confidence', 0)
        market_context = prediction_result.get('market_context')
        
        logger.info(f"   ğŸ“Š Prediction: {action} with {confidence:.1%} confidence")
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¥Ø´Ø§Ø±Ø© Ù‚ÙˆÙŠØ©
        if action != 'HOLD' and confidence >= system.min_confidence:
            current_price = float(df['close'].iloc[-1])
            
            # Ø­Ø³Ø§Ø¨ SL/TP Ù…Ø¹ Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø¬Ø²Ø¦ÙŠ
            sl_tp_info = system.calculate_dynamic_sl_tp_with_partial(
                clean_symbol, action, current_price, market_context
            )
            
            # Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„ØµÙÙ‚Ø© Ø¨Kelly
            kelly_pct = system.calculate_kelly_position(clean_symbol, confidence)
            lot_size = system.risk_manager.calculate_position_size(
                clean_symbol,
                current_price,
                sl_tp_info['sl_price'],
                market_context,
                confidence
            )[0]
            
            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙÙ‚Ø©
            entry_reason = f"Market score: {market_context['score'] if market_context else 'N/A'}, Models agree"
            system.log_trade(
                clean_symbol, action, current_price,
                sl_tp_info['sl_price'], sl_tp_info['tp1_price'],
                confidence, market_context, entry_reason
            )
            
            logger.info(f"   âœ… Signal: {action} @ {current_price:.5f}")
            logger.info(f"   ğŸ¯ SL: {sl_tp_info['sl_pips']:.0f} pips, TP0: {sl_tp_info['tp0_pips']:.0f} pips (50%), TP1: {sl_tp_info['tp1_pips']:.0f} pips")
            logger.info(f"   ğŸ’° Position size: {kelly_pct:.1%} of capital")
            
            return jsonify({
                'action': 0 if action == 'BUY' else 1,
                'direction': action,
                'confidence': float(confidence),
                'sl_price': float(sl_tp_info['sl_price']),
                'tp0_price': float(sl_tp_info['tp0_price']),
                'tp1_price': float(sl_tp_info['tp1_price']),
                'tp2_price': float(sl_tp_info['tp2_price']),
                'partial_close': sl_tp_info['partial_close_at_tp0'],
                'lot_size': float(lot_size),
                'position_size_pct': float(kelly_pct),
                'market_score': market_context['score'] if market_context else 0,
                'entry_reason': entry_reason
            })
        else:
            reason = prediction_result.get('reason', 'Low confidence or weak signal')
            logger.info(f"   â¸ï¸ HOLD: {reason}")
            
            return jsonify({
                'action': 2,
                'direction': 'HOLD',
                'confidence': float(confidence),
                'reason': reason
            })
            
    except Exception as e:
        logger.error(f"Error in prediction: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return jsonify({
            'action': 2,
            'direction': 'NONE',
            'confidence': 0.0,
            'error': str(e)
        })

@app.route('/update_position', methods=['POST'])
def update_position():
    """ØªØ­Ø¯ÙŠØ« trailing stop Ù„Ù„ØµÙÙ‚Ø© Ø§Ù„Ù…ÙØªÙˆØ­Ø©"""
    try:
        data = request.json
        symbol = data.get('symbol', '').replace('m', '').upper()
        current_price = float(data.get('current_price', 0))
        entry_price = float(data.get('entry_price', 0))
        current_sl = float(data.get('stop_loss', 0))
        direction = data.get('direction', 'BUY')
        
        # Ø­Ø³Ø§Ø¨ trailing stop Ø¬Ø¯ÙŠØ¯
        new_sl = system.update_trailing_stop(symbol, current_price, entry_price, current_sl, direction)
        
        return jsonify({
            'new_stop_loss': float(new_sl),
            'updated': new_sl != current_sl
        })
        
    except Exception as e:
        logger.error(f"Error updating position: {str(e)}")
        return jsonify({'error': str(e)}), 500

@app.route('/backtest', methods=['POST'])
def backtest():
    """ØªØ´ØºÙŠÙ„ backtest Ø¹Ù„Ù‰ ÙØªØ±Ø© Ù…Ø­Ø¯Ø¯Ø©"""
    try:
        data = request.json
        symbol = data.get('symbol', 'EURUSD')
        timeframe = data.get('timeframe', 'M15')
        start_date = data.get('start_date', '2024-01-01')
        end_date = data.get('end_date', '2024-12-31')
        
        results = system.backtest(symbol, timeframe, start_date, end_date)
        
        return jsonify(results)
        
    except Exception as e:
        logger.error(f"Backtest error: {str(e)}")
        return jsonify({'error': str(e)}), 500

@app.route('/train', methods=['POST'])
def train():
    """ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ø²ÙˆØ¬ Ù…Ø¹ÙŠÙ†"""
    try:
        data = request.json
        symbol = data.get('symbol', 'EURUSD')
        timeframe = data.get('timeframe', 'M15')
        
        success = system.train_enhanced_models(symbol, timeframe)
        
        if success:
            return jsonify({
                'status': 'success',
                'message': f'Models trained successfully for {symbol} {timeframe}'
            })
        else:
            return jsonify({
                'status': 'failed',
                'message': f'Failed to train models for {symbol} {timeframe}'
            })
            
    except Exception as e:
        logger.error(f"Training error: {str(e)}")
        return jsonify({'error': str(e)}), 500

@app.route('/performance', methods=['GET'])
def get_performance():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡"""
    try:
        # Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
        trades = system.performance_tracker['trades']
        
        if not trades:
            return jsonify({
                'message': 'No trades yet',
                'total_trades': 0
            })
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙÙ‚Ø§Øª
        total_trades = len(trades)
        recent_trades = trades[-20:]  # Ø¢Ø®Ø± 20 ØµÙÙ‚Ø©
        
        return jsonify({
            'total_trades': total_trades,
            'recent_trades': recent_trades,
            'models_performance': system.performance_tracker.get('model_performance', {}),
            'model_weights': system.model_weights
        })
        
    except Exception as e:
        logger.error(f"Performance error: {str(e)}")
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    logger.info("ğŸš€ Starting Enhanced ML Server (Profit-based)...")
    app.run(host='0.0.0.0', port=5000, debug=False)