#!/usr/bin/env python3
"""
ğŸ§  Ultimate Continuous Learning System - Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
ğŸ“ˆ ÙŠØªØ¹Ù„Ù… Ù…Ù† ÙƒÙ„ ØµÙÙ‚Ø© ÙˆÙŠØ­Ø³Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
ğŸ”„ ÙŠØ¯Ø¹Ù… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„Ø§Øª ÙˆØ§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import sqlite3
from loguru import logger
import schedule
import time
from typing import Dict, List, Optional, Tuple
import os
from pathlib import Path
import joblib
from sklearn.preprocessing import RobustScaler
import threading
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

# Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.ensemble import IsolationForest
from sklearn.cluster import DBSCAN
import talib

class UltimateContinuousLearner:
    """Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù… - ÙŠØªØ¹Ù„Ù… ÙˆÙŠØªØ­Ø³Ù† Ø¨Ø§Ø³ØªÙ…Ø±Ø§Ø±"""
    
    def __init__(self, config_path: str = "config/config.json"):
        """ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±"""
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                self.config = json.load(f)
        else:
            self.config = self._get_default_config()
        
        self.db_path = self.config.get("database", {}).get("path", "data/forex_data.db")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        logger.add("logs/continuous_learning_ultimate.log", rotation="1 day", retention="30 days")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self._init_learning_database()
        
        # Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        self.learning_memory = {
            'pattern_performance': defaultdict(lambda: {'success': 0, 'fail': 0, 'confidence': 0.5}),
            'market_conditions': defaultdict(list),
            'time_patterns': defaultdict(lambda: {'success': 0, 'total': 0}),
            'strategy_performance': defaultdict(lambda: {'trades': 0, 'wins': 0, 'total_pips': 0}),
            'symbol_characteristics': defaultdict(dict),
            'adaptive_parameters': defaultdict(dict),
            'hypothesis_tracker': defaultdict(list),
            'risk_adjustments': defaultdict(float)
        }
        
        # Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªØ¹Ù„Ù…
        self.learning_rate = 0.01
        self.adaptation_threshold = 0.1
        self.memory_size = 10000
        self.update_frequency = 100  # ÙƒÙ„ 100 ØµÙÙ‚Ø©
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        self._load_learning_memory()
        
        # Ø¨Ø¯Ø¡ Ø®ÙŠØ· Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±
        self.learning_thread = threading.Thread(target=self._continuous_learning_loop, daemon=True)
        self.learning_thread.start()
        
        logger.info("âœ… ØªÙ… ØªØ´ØºÙŠÙ„ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")

    def _get_default_config(self):
        """Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©"""
        return {
            "database": {"path": "data/forex_data.db"},
            "learning": {
                "min_trades_for_update": 50,
                "confidence_decay": 0.995,
                "max_memory_days": 90
            }
        }

    def _init_learning_database(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØµÙÙ‚Ø§Øª
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS continuous_learning (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                trade_id TEXT UNIQUE,
                symbol TEXT NOT NULL,
                timeframe TEXT NOT NULL,
                strategy TEXT NOT NULL,
                
                -- ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØµÙÙ‚Ø©
                entry_time TIMESTAMP,
                exit_time TIMESTAMP,
                entry_price REAL,
                exit_price REAL,
                direction TEXT,
                lot_size REAL,
                
                -- Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                result TEXT,
                pnl_pips REAL,
                pnl_money REAL,
                
                -- Ø§Ù„ØªØ­Ù„ÙŠÙ„
                pattern_detected TEXT,
                indicators_snapshot TEXT,
                market_context TEXT,
                confidence_before REAL,
                confidence_after REAL,
                
                -- Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ù…Ø³ØªÙØ§Ø¯Ø©
                lessons_learned TEXT,
                improvements_suggested TEXT,
                hypothesis_tested TEXT,
                hypothesis_result TEXT,
                
                -- Ø§Ù„Ù…Ø®Ø§Ø·Ø±
                risk_score REAL,
                max_drawdown REAL,
                recovery_time INTEGER,
                
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # Ø¬Ø¯ÙˆÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS pattern_performance (
                pattern_key TEXT PRIMARY KEY,
                symbol TEXT,
                timeframe TEXT,
                
                -- Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                total_occurrences INTEGER DEFAULT 0,
                successful_trades INTEGER DEFAULT 0,
                failed_trades INTEGER DEFAULT 0,
                
                -- Ø§Ù„Ø£Ø¯Ø§Ø¡
                total_pips REAL DEFAULT 0,
                avg_pips_per_trade REAL DEFAULT 0,
                max_win_pips REAL DEFAULT 0,
                max_loss_pips REAL DEFAULT 0,
                
                -- Ø§Ù„Ø«Ù‚Ø© ÙˆØ§Ù„Ø¬ÙˆØ¯Ø©
                success_rate REAL DEFAULT 0,
                confidence_score REAL DEFAULT 0.5,
                quality_score REAL DEFAULT 0.5,
                
                -- Ø§Ù„ØªÙˆÙ‚ÙŠØª
                best_hours TEXT,
                best_days TEXT,
                best_sessions TEXT,
                
                last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # Ø¬Ø¯ÙˆÙ„ ØªÙƒÙŠÙ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS strategy_adaptations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol TEXT NOT NULL,
                timeframe TEXT NOT NULL,
                strategy TEXT NOT NULL,
                
                -- Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª
                parameter_name TEXT,
                old_value REAL,
                new_value REAL,
                reason TEXT,
                
                -- Ø§Ù„Ø£Ø¯Ø§Ø¡
                performance_before REAL,
                performance_after REAL,
                improvement REAL,
                
                -- Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
                applied BOOLEAN DEFAULT FALSE,
                applied_date TIMESTAMP,
                rollback_date TIMESTAMP,
                
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS hypothesis_tracking (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                hypothesis_id TEXT UNIQUE,
                symbol TEXT,
                timeframe TEXT,
                
                -- Ø§Ù„ÙØ±Ø¶ÙŠØ©
                hypothesis_text TEXT,
                hypothesis_type TEXT,
                confidence_level REAL,
                
                -- Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
                tests_conducted INTEGER DEFAULT 0,
                tests_successful INTEGER DEFAULT 0,
                tests_failed INTEGER DEFAULT 0,
                
                -- Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                avg_performance REAL,
                statistical_significance REAL,
                conclusion TEXT,
                
                -- Ø§Ù„Ø­Ø§Ù„Ø©
                status TEXT DEFAULT 'testing',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                concluded_at TIMESTAMP
            )
        """)
        
        # Ø¬Ø¯ÙˆÙ„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙˆÙ‚
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS market_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol TEXT NOT NULL,
                timeframe TEXT NOT NULL,
                analysis_time TIMESTAMP,
                
                -- Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚
                market_phase TEXT,
                trend_strength REAL,
                volatility_level REAL,
                volume_profile TEXT,
                
                -- Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª
                support_levels TEXT,
                resistance_levels TEXT,
                fibonacci_levels TEXT,
                pivot_points TEXT,
                
                -- Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
                predicted_direction TEXT,
                prediction_confidence REAL,
                target_levels TEXT,
                risk_levels TEXT,
                
                -- Ø§Ù„Ø£Ø­Ø¯Ø§Ø«
                upcoming_events TEXT,
                market_sentiment TEXT,
                
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        conn.commit()
        conn.close()

    def learn_from_trade(self, trade_result: Dict) -> Dict:
        """Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ù†ØªÙŠØ¬Ø© ØµÙÙ‚Ø© Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…"""
        try:
            symbol = trade_result.get('symbol', '')
            timeframe = trade_result.get('timeframe', '')
            strategy = trade_result.get('strategy', '')
            pnl_pips = trade_result.get('pnl_pips', 0)
            
            logger.info(f"ğŸ“š Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† ØµÙÙ‚Ø©: {symbol} - {strategy} - {pnl_pips:.1f} pips")
            
            # ØªØ­Ù„ÙŠÙ„ Ù†Ø¬Ø§Ø­ Ø£Ùˆ ÙØ´Ù„ Ø§Ù„ØµÙÙ‚Ø©
            success = pnl_pips > 0
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù†Ù…Ø§Ø· ÙˆØ§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
            patterns = self._extract_patterns(trade_result)
            market_context = self._analyze_market_context(trade_result)
            time_analysis = self._analyze_time_patterns(trade_result)
            
            # ØªØ­Ø¯ÙŠØ« Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ¹Ù„Ù…
            self._update_pattern_performance(patterns, success, pnl_pips)
            self._update_strategy_performance(strategy, symbol, success, pnl_pips)
            self._update_time_patterns(time_analysis, success)
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª
            hypothesis_results = self._test_hypothesis(trade_result)
            
            # Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†
            improvements = self._generate_improvements(trade_result, patterns, market_context)
            
            # Ø­Ø³Ø§Ø¨ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø©
            confidence_adjustment = self._calculate_confidence_adjustment(
                success, pnl_pips, patterns, market_context
            )
            
            # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            self._save_learning_record(
                trade_result, patterns, market_context, 
                improvements, hypothesis_results, confidence_adjustment
            )
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø§Ø¬Ø© Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            if self._should_update_models(symbol, strategy):
                self._trigger_model_update(symbol, timeframe, strategy)
            
            # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„ØªÙˆØµÙŠØ§Øª
            return {
                'learned': True,
                'confidence_adjustment': confidence_adjustment,
                'improvements': improvements,
                'hypothesis_results': hypothesis_results,
                'next_trade_suggestions': self._get_next_trade_suggestions(symbol, strategy)
            }
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØµÙÙ‚Ø©: {e}")
            return {'learned': False, 'error': str(e)}

    def _extract_patterns(self, trade_result: Dict) -> Dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙÙ‚Ø©"""
        patterns = {
            'technical_patterns': [],
            'candlestick_patterns': [],
            'indicator_signals': {},
            'price_action': {}
        }
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©
        indicators = trade_result.get('indicators', {})
        
        # ØªØ­Ù„ÙŠÙ„ RSI
        rsi = indicators.get('rsi', 50)
        if rsi < 30:
            patterns['indicator_signals']['rsi'] = 'oversold'
        elif rsi > 70:
            patterns['indicator_signals']['rsi'] = 'overbought'
        else:
            patterns['indicator_signals']['rsi'] = 'neutral'
        
        # ØªØ­Ù„ÙŠÙ„ MACD
        macd_hist = indicators.get('macd_hist', 0)
        patterns['indicator_signals']['macd'] = 'bullish' if macd_hist > 0 else 'bearish'
        
        # ØªØ­Ù„ÙŠÙ„ Moving Averages
        ma_analysis = self._analyze_moving_averages(indicators)
        patterns['indicator_signals']['ma_trend'] = ma_analysis
        
        # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø´Ù…ÙˆØ¹
        candle_patterns = trade_result.get('candle_patterns', [])
        patterns['candlestick_patterns'] = candle_patterns
        
        # Price Action
        patterns['price_action'] = {
            'trend': self._identify_trend(trade_result),
            'support_resistance': self._find_sr_levels(trade_result),
            'volatility': indicators.get('atr', 0)
        }
        
        return patterns

    def _analyze_market_context(self, trade_result: Dict) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³ÙˆÙ‚"""
        context = {
            'market_phase': 'unknown',
            'volatility': 'normal',
            'volume': 'average',
            'session': 'unknown',
            'trend_strength': 0
        }
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚ÙŠØ©
        indicators = trade_result.get('indicators', {})
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ù„Ø¨
        atr = indicators.get('atr', 0)
        atr_avg = indicators.get('atr_avg', 1)
        if atr > atr_avg * 1.5:
            context['volatility'] = 'high'
        elif atr < atr_avg * 0.5:
            context['volatility'] = 'low'
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù…
        volume = trade_result.get('volume', 0)
        volume_avg = trade_result.get('volume_avg', 1)
        if volume > volume_avg * 1.5:
            context['volume'] = 'high'
        elif volume < volume_avg * 0.5:
            context['volume'] = 'low'
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¬Ù„Ø³Ø©
        hour = trade_result.get('hour', 0)
        context['session'] = self._get_trading_session(hour)
        
        # Ù‚ÙˆØ© Ø§Ù„Ø§ØªØ¬Ø§Ù‡
        adx = indicators.get('adx', 0)
        if adx > 40:
            context['trend_strength'] = 'strong'
        elif adx > 25:
            context['trend_strength'] = 'moderate'
        else:
            context['trend_strength'] = 'weak'
        
        return context

    def _analyze_time_patterns(self, trade_result: Dict) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
        entry_time = pd.to_datetime(trade_result.get('entry_time'))
        
        return {
            'hour': entry_time.hour,
            'day_of_week': entry_time.dayofweek,
            'day_of_month': entry_time.day,
            'month': entry_time.month,
            'session': self._get_trading_session(entry_time.hour),
            'is_news_time': self._is_news_time(entry_time),
            'is_market_open': self._is_major_market_open(entry_time)
        }

    def _update_pattern_performance(self, patterns: Dict, success: bool, pnl_pips: float):
        """ØªØ­Ø¯ÙŠØ« Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ù†Ù…Ø§Ø·"""
        # ØªØ­Ø¯ÙŠØ« Ø£Ø¯Ø§Ø¡ ÙƒÙ„ Ù†Ù…Ø·
        for pattern_type, pattern_data in patterns.items():
            if isinstance(pattern_data, dict):
                for key, value in pattern_data.items():
                    pattern_key = f"{pattern_type}_{key}_{value}"
                    
                    if success:
                        self.learning_memory['pattern_performance'][pattern_key]['success'] += 1
                    else:
                        self.learning_memory['pattern_performance'][pattern_key]['fail'] += 1
                    
                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø«Ù‚Ø©
                    total = (self.learning_memory['pattern_performance'][pattern_key]['success'] + 
                            self.learning_memory['pattern_performance'][pattern_key]['fail'])
                    
                    if total > 0:
                        success_rate = self.learning_memory['pattern_performance'][pattern_key]['success'] / total
                        self.learning_memory['pattern_performance'][pattern_key]['confidence'] = success_rate

    def _update_strategy_performance(self, strategy: str, symbol: str, success: bool, pnl_pips: float):
        """ØªØ­Ø¯ÙŠØ« Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©"""
        key = f"{symbol}_{strategy}"
        
        self.learning_memory['strategy_performance'][key]['trades'] += 1
        if success:
            self.learning_memory['strategy_performance'][key]['wins'] += 1
        self.learning_memory['strategy_performance'][key]['total_pips'] += pnl_pips

    def _update_time_patterns(self, time_analysis: Dict, success: bool):
        """ØªØ­Ø¯ÙŠØ« Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªÙˆÙ‚ÙŠØª"""
        hour = time_analysis['hour']
        day = time_analysis['day_of_week']
        session = time_analysis['session']
        
        # ØªØ­Ø¯ÙŠØ« Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø§Ø¹Ø§Øª
        hour_key = f"hour_{hour}"
        self.learning_memory['time_patterns'][hour_key]['total'] += 1
        if success:
            self.learning_memory['time_patterns'][hour_key]['success'] += 1
        
        # ØªØ­Ø¯ÙŠØ« Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£ÙŠØ§Ù…
        day_key = f"day_{day}"
        self.learning_memory['time_patterns'][day_key]['total'] += 1
        if success:
            self.learning_memory['time_patterns'][day_key]['success'] += 1
        
        # ØªØ­Ø¯ÙŠØ« Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø§Øª
        session_key = f"session_{session}"
        self.learning_memory['time_patterns'][session_key]['total'] += 1
        if success:
            self.learning_memory['time_patterns'][session_key]['success'] += 1

    def _test_hypothesis(self, trade_result: Dict) -> Dict:
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª"""
        hypothesis_results = {}
        
        # Ø§Ø®ØªØ¨Ø§Ø± ÙØ±Ø¶ÙŠØ§Øª Ù…Ø­Ø¯Ø¯Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹
        active_hypotheses = self._get_active_hypotheses(
            trade_result.get('symbol'),
            trade_result.get('strategy')
        )
        
        for hypothesis in active_hypotheses:
            result = self._evaluate_hypothesis(hypothesis, trade_result)
            hypothesis_results[hypothesis['id']] = result
            
            # ØªØ­Ø¯ÙŠØ« ØªØªØ¨Ø¹ Ø§Ù„ÙØ±Ø¶ÙŠØ©
            self._update_hypothesis_tracking(hypothesis['id'], result)
        
        return hypothesis_results

    def _generate_improvements(self, trade_result: Dict, patterns: Dict, market_context: Dict) -> List[Dict]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†"""
        improvements = []
        
        # ØªØ­Ù„ÙŠÙ„ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù
        if trade_result.get('pnl_pips', 0) < 0:
            # ØªØ­Ù„ÙŠÙ„ Ø³Ø¨Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
            loss_reasons = self._analyze_loss_reasons(trade_result, patterns, market_context)
            
            for reason in loss_reasons:
                improvement = {
                    'type': reason['type'],
                    'description': reason['description'],
                    'action': reason['suggested_action'],
                    'priority': reason['priority']
                }
                improvements.append(improvement)
        
        # Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø¹Ø§Ù…Ø© Ù„Ù„ØªØ­Ø³ÙŠÙ†
        general_improvements = self._get_general_improvements(patterns, market_context)
        improvements.extend(general_improvements)
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
        improvements.sort(key=lambda x: x['priority'], reverse=True)
        
        return improvements[:5]  # Ø£Ù‡Ù… 5 ØªØ­Ø³ÙŠÙ†Ø§Øª

    def _calculate_confidence_adjustment(self, success: bool, pnl_pips: float, 
                                       patterns: Dict, market_context: Dict) -> float:
        """Ø­Ø³Ø§Ø¨ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø©"""
        base_adjustment = 0.0
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø£Ø³Ø§Ø³ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªÙŠØ¬Ø©
        if success:
            base_adjustment = min(0.1, abs(pnl_pips) / 100)
        else:
            base_adjustment = -min(0.1, abs(pnl_pips) / 100)
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø·
        pattern_quality = self._evaluate_pattern_quality(patterns)
        base_adjustment *= pattern_quality
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³ÙˆÙ‚
        if market_context.get('volatility') == 'high':
            base_adjustment *= 0.7  # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„Ø£Ø³ÙˆØ§Ù‚ Ø§Ù„Ù…ØªÙ‚Ù„Ø¨Ø©
        
        return np.clip(base_adjustment, -0.2, 0.2)

    def _save_learning_record(self, trade_result: Dict, patterns: Dict, 
                            market_context: Dict, improvements: List, 
                            hypothesis_results: Dict, confidence_adjustment: float):
        """Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ¹Ù„Ù… ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT OR REPLACE INTO continuous_learning (
                    trade_id, symbol, timeframe, strategy,
                    entry_time, exit_time, entry_price, exit_price,
                    direction, lot_size, result, pnl_pips, pnl_money,
                    pattern_detected, indicators_snapshot, market_context,
                    confidence_before, confidence_after,
                    lessons_learned, improvements_suggested,
                    hypothesis_tested, hypothesis_result,
                    risk_score, max_drawdown, recovery_time
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                trade_result.get('trade_id'),
                trade_result.get('symbol'),
                trade_result.get('timeframe'),
                trade_result.get('strategy'),
                trade_result.get('entry_time'),
                trade_result.get('exit_time'),
                trade_result.get('entry_price'),
                trade_result.get('exit_price'),
                trade_result.get('direction'),
                trade_result.get('lot_size'),
                'win' if trade_result.get('pnl_pips', 0) > 0 else 'loss',
                trade_result.get('pnl_pips'),
                trade_result.get('pnl_money'),
                json.dumps(patterns),
                json.dumps(trade_result.get('indicators', {})),
                json.dumps(market_context),
                trade_result.get('confidence', 0.5),
                trade_result.get('confidence', 0.5) + confidence_adjustment,
                json.dumps(self._extract_lessons(trade_result, patterns)),
                json.dumps(improvements),
                json.dumps(list(hypothesis_results.keys())),
                json.dumps(hypothesis_results),
                trade_result.get('risk_score', 0),
                trade_result.get('max_drawdown', 0),
                trade_result.get('recovery_time', 0)
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ¹Ù„Ù…: {e}")

    def _should_update_models(self, symbol: str, strategy: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø§Ø¬Ø© Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        key = f"{symbol}_{strategy}"
        trades_count = self.learning_memory['strategy_performance'][key]['trades']
        
        # ØªØ­Ø¯ÙŠØ« ÙƒÙ„ 100 ØµÙÙ‚Ø© Ø£Ùˆ Ø¹Ù†Ø¯ Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„Ø£Ø¯Ø§Ø¡
        if trades_count % self.update_frequency == 0:
            return True
        
        # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„Ø£Ø¯Ø§Ø¡
        if trades_count > 20:
            win_rate = self.learning_memory['strategy_performance'][key]['wins'] / trades_count
            if win_rate < 0.45:  # Ø£Ù‚Ù„ Ù…Ù† 45% Ù†Ø¬Ø§Ø­
                return True
        
        return False

    def _trigger_model_update(self, symbol: str, timeframe: str, strategy: str):
        """ØªØ´ØºÙŠÙ„ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        logger.info(f"ğŸ”„ ØªØ´ØºÙŠÙ„ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {symbol} - {timeframe} - {strategy}")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ù…Ø© ØªØ­Ø¯ÙŠØ«
        update_task = {
            'symbol': symbol,
            'timeframe': timeframe,
            'strategy': strategy,
            'reason': 'continuous_learning',
            'timestamp': datetime.now()
        }
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª
        self._queue_model_update(update_task)

    def _get_next_trade_suggestions(self, symbol: str, strategy: str) -> Dict:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„ØµÙÙ‚Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©"""
        suggestions = {
            'best_hours': [],
            'avoid_hours': [],
            'recommended_patterns': [],
            'risk_adjustments': {},
            'confidence_modifiers': {}
        }
        
        # ØªØ­Ù„ÙŠÙ„ Ø£ÙØ¶Ù„ Ø§Ù„Ø£ÙˆÙ‚Ø§Øª
        time_performance = self._analyze_time_performance()
        suggestions['best_hours'] = time_performance['best_hours'][:3]
        suggestions['avoid_hours'] = time_performance['worst_hours'][:3]
        
        # Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§
        pattern_performance = self._analyze_pattern_performance(symbol)
        suggestions['recommended_patterns'] = pattern_performance['best_patterns'][:5]
        
        # ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±
        suggestions['risk_adjustments'] = self._calculate_risk_adjustments(symbol, strategy)
        
        return suggestions

    def _continuous_learning_loop(self):
        """Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©"""
        while True:
            try:
                # ØªØ­Ø¯ÙŠØ« Ø¯ÙˆØ±ÙŠ Ù„Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
                self._periodic_analysis()
                
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
                self._cleanup_old_memory()
                
                # Ø­ÙØ¸ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                self._save_learning_memory()
                
                # Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ§Ù„ÙŠ
                time.sleep(3600)  # ÙƒÙ„ Ø³Ø§Ø¹Ø©
                
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±: {e}")
                time.sleep(60)

    def _periodic_analysis(self):
        """ØªØ­Ù„ÙŠÙ„ Ø¯ÙˆØ±ÙŠ Ù„Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª"""
        logger.info("ğŸ”„ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯ÙˆØ±ÙŠ...")
        
        # ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª
        for key, performance in self.learning_memory['strategy_performance'].items():
            if performance['trades'] > 50:
                win_rate = performance['wins'] / performance['trades']
                avg_pips = performance['total_pips'] / performance['trades']
                
                logger.info(f"ğŸ“Š {key}: Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­ {win_rate:.2%}, Ù…ØªÙˆØ³Ø· Ø§Ù„Ù†Ù‚Ø§Ø· {avg_pips:.1f}")
                
                # ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª ØªØ­Ø³ÙŠÙ†
                if win_rate < 0.5:
                    self._generate_strategy_improvements(key, performance)

    def _cleanup_old_memory(self):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        max_age_days = self.config.get('learning', {}).get('max_memory_days', 90)
        cutoff_date = datetime.now() - timedelta(days=max_age_days)
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ø­Ø°Ù Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
            cursor.execute("""
                DELETE FROM continuous_learning 
                WHERE created_at < ?
            """, (cutoff_date,))
            
            deleted_count = cursor.rowcount
            
            conn.commit()
            conn.close()
            
            if deleted_count > 0:
                logger.info(f"ğŸ§¹ ØªÙ… Ø­Ø°Ù {deleted_count} Ø³Ø¬Ù„ Ù‚Ø¯ÙŠÙ…")
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {e}")

    def _save_learning_memory(self):
        """Ø­ÙØ¸ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ¹Ù„Ù…"""
        try:
            memory_path = Path("data/learning_memory.json")
            memory_path.parent.mkdir(exist_ok=True)
            
            # ØªØ­ÙˆÙŠÙ„ defaultdict Ø¥Ù„Ù‰ dict Ø¹Ø§Ø¯ÙŠ Ù„Ù„Ø­ÙØ¸
            memory_to_save = {
                key: dict(value) if isinstance(value, defaultdict) else value
                for key, value in self.learning_memory.items()
            }
            
            with open(memory_path, 'w') as f:
                json.dump(memory_to_save, f, indent=2, default=str)
                
            logger.info("ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ¹Ù„Ù…")
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {e}")

    def _load_learning_memory(self):
        """ØªØ­Ù…ÙŠÙ„ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©"""
        try:
            memory_path = Path("data/learning_memory.json")
            
            if memory_path.exists():
                with open(memory_path, 'r') as f:
                    loaded_memory = json.load(f)
                
                # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
                for key, value in loaded_memory.items():
                    if key in self.learning_memory:
                        if isinstance(self.learning_memory[key], defaultdict):
                            self.learning_memory[key].update(value)
                        else:
                            self.learning_memory[key] = value
                
                logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©")
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {e}")

    def generate_performance_report(self, symbol: Optional[str] = None, 
                                  strategy: Optional[str] = None) -> Dict:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø£Ø¯Ø§Ø¡ Ø´Ø§Ù…Ù„"""
        report = {
            'overall_performance': {},
            'pattern_analysis': {},
            'time_analysis': {},
            'improvements': [],
            'recommendations': []
        }
        
        try:
            conn = sqlite3.connect(self.db_path)
            
            # Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù…
            query = """
                SELECT 
                    COUNT(*) as total_trades,
                    SUM(CASE WHEN pnl_pips > 0 THEN 1 ELSE 0 END) as wins,
                    SUM(pnl_pips) as total_pips,
                    AVG(pnl_pips) as avg_pips,
                    MAX(pnl_pips) as max_win,
                    MIN(pnl_pips) as max_loss
                FROM continuous_learning
            """
            
            params = []
            if symbol:
                query += " WHERE symbol = ?"
                params.append(symbol)
            if strategy:
                query += " AND strategy = ?" if symbol else " WHERE strategy = ?"
                params.append(strategy)
            
            df = pd.read_sql_query(query, conn, params=params)
            
            if not df.empty:
                row = df.iloc[0]
                report['overall_performance'] = {
                    'total_trades': int(row['total_trades']),
                    'wins': int(row['wins']),
                    'win_rate': row['wins'] / row['total_trades'] if row['total_trades'] > 0 else 0,
                    'total_pips': float(row['total_pips']),
                    'avg_pips': float(row['avg_pips']),
                    'max_win': float(row['max_win']),
                    'max_loss': float(row['max_loss'])
                }
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
            report['pattern_analysis'] = self._generate_pattern_report()
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆÙ‚Øª
            report['time_analysis'] = self._generate_time_report()
            
            # Ø§Ù„ØªÙˆØµÙŠØ§Øª
            report['recommendations'] = self._generate_recommendations(report)
            
            conn.close()
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {e}")
        
        return report

    # ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø©
    def _get_trading_session(self, hour: int) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ø¬Ù„Ø³Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„"""
        if 0 <= hour < 8:
            return 'tokyo'
        elif 8 <= hour < 16:
            return 'london'
        elif 13 <= hour < 21:
            return 'newyork'
        else:
            return 'sydney'

    def _is_news_time(self, timestamp: pd.Timestamp) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆÙ‚Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø±"""
        # Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© (UTC)
        news_hours = [8, 10, 12, 14, 18, 20]
        return timestamp.hour in news_hours and timestamp.minute < 30

    def _is_major_market_open(self, timestamp: pd.Timestamp) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙØªØ­ Ø§Ù„Ø£Ø³ÙˆØ§Ù‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
        hour = timestamp.hour
        return 8 <= hour <= 21  # London to NY close

    def _identify_trend(self, trade_result: Dict) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡"""
        indicators = trade_result.get('indicators', {})
        
        sma_50 = indicators.get('sma_50', 0)
        sma_200 = indicators.get('sma_200', 0)
        
        if sma_50 > sma_200:
            return 'uptrend'
        elif sma_50 < sma_200:
            return 'downtrend'
        else:
            return 'sideways'

    def _find_sr_levels(self, trade_result: Dict) -> Dict:
        """Ø¥ÙŠØ¬Ø§Ø¯ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©"""
        # ØªÙ†ÙÙŠØ° Ù…Ø¨Ø³Ø·
        return {
            'support': trade_result.get('support_level', 0),
            'resistance': trade_result.get('resistance_level', 0)
        }

    def _analyze_loss_reasons(self, trade_result: Dict, patterns: Dict, 
                            market_context: Dict) -> List[Dict]:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©"""
        reasons = []
        
        # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø³ÙŠØ¡
        if market_context.get('volatility') == 'high':
            reasons.append({
                'type': 'high_volatility',
                'description': 'Ø¯Ø®ÙˆÙ„ ÙÙŠ Ø³ÙˆÙ‚ Ø¹Ø§Ù„ÙŠ Ø§Ù„ØªÙ‚Ù„Ø¨',
                'suggested_action': 'ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø¹Ù†Ø¯ Ø§Ø±ØªÙØ§Ø¹ ATR ÙÙˆÙ‚ Ø§Ù„Ù…ØªÙˆØ³Ø· Ø¨Ù€ 50%',
                'priority': 8
            })
        
        # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§ØªØ¬Ø§Ù‡ Ø®Ø§Ø·Ø¦
        if patterns.get('price_action', {}).get('trend') != trade_result.get('direction'):
            reasons.append({
                'type': 'against_trend',
                'description': 'ØªØ¯Ø§ÙˆÙ„ Ø¹ÙƒØ³ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…',
                'suggested_action': 'Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù…Ø¹ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ ÙÙ‚Ø· Ø¹Ù†Ø¯ Ù‚ÙˆØ© ADX > 25',
                'priority': 9
            })
        
        return reasons

    def _evaluate_pattern_quality(self, patterns: Dict) -> float:
        """ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø·"""
        quality_score = 0.5
        
        # ØªÙ‚ÙŠÙŠÙ… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø©
        confirming_indicators = 0
        total_indicators = 0
        
        for indicator, signal in patterns.get('indicator_signals', {}).items():
            total_indicators += 1
            if signal in ['bullish', 'oversold'] and patterns.get('direction') == 'buy':
                confirming_indicators += 1
            elif signal in ['bearish', 'overbought'] and patterns.get('direction') == 'sell':
                confirming_indicators += 1
        
        if total_indicators > 0:
            quality_score = confirming_indicators / total_indicators
        
        return quality_score

    def _extract_lessons(self, trade_result: Dict, patterns: Dict) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ù…Ø³ØªÙØ§Ø¯Ø©"""
        lessons = []
        
        if trade_result.get('pnl_pips', 0) > 0:
            lessons.append(f"Ù†Ø¬Ø­Øª Ø¹Ù†Ø¯ {patterns.get('price_action', {}).get('trend', 'unknown')} trend")
        else:
            lessons.append(f"ÙØ´Ù„Øª ÙÙŠ {trade_result.get('market_context', {}).get('session', 'unknown')} session")
        
        return lessons

    def _get_active_hypotheses(self, symbol: str, strategy: str) -> List[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ù†Ø´Ø·Ø©"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT * FROM hypothesis_tracking
                WHERE (symbol = ? OR symbol IS NULL)
                AND status = 'testing'
                ORDER BY confidence_level DESC
                LIMIT 5
            """, (symbol,))
            
            hypotheses = []
            for row in cursor.fetchall():
                hypotheses.append({
                    'id': row[1],
                    'text': row[4],
                    'type': row[5],
                    'confidence': row[6]
                })
            
            conn.close()
            return hypotheses
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª: {e}")
            return []

    def _evaluate_hypothesis(self, hypothesis: Dict, trade_result: Dict) -> Dict:
        """ØªÙ‚ÙŠÙŠÙ… ÙØ±Ø¶ÙŠØ©"""
        # ØªÙ†ÙÙŠØ° Ù…Ø¨Ø³Ø·
        return {
            'hypothesis_id': hypothesis['id'],
            'result': 'confirmed' if trade_result.get('pnl_pips', 0) > 0 else 'rejected',
            'confidence_change': 0.1 if trade_result.get('pnl_pips', 0) > 0 else -0.1
        }

    def _update_hypothesis_tracking(self, hypothesis_id: str, result: Dict):
        """ØªØ­Ø¯ÙŠØ« ØªØªØ¨Ø¹ Ø§Ù„ÙØ±Ø¶ÙŠØ©"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            if result['result'] == 'confirmed':
                cursor.execute("""
                    UPDATE hypothesis_tracking
                    SET tests_conducted = tests_conducted + 1,
                        tests_successful = tests_successful + 1,
                        confidence_level = confidence_level + ?
                    WHERE hypothesis_id = ?
                """, (result['confidence_change'], hypothesis_id))
            else:
                cursor.execute("""
                    UPDATE hypothesis_tracking
                    SET tests_conducted = tests_conducted + 1,
                        tests_failed = tests_failed + 1,
                        confidence_level = confidence_level + ?
                    WHERE hypothesis_id = ?
                """, (result['confidence_change'], hypothesis_id))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙØ±Ø¶ÙŠØ©: {e}")

    def _queue_model_update(self, update_task: Dict):
        """Ø¥Ø¶Ø§ÙØ© Ù…Ù‡Ù…Ø© ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±"""
        # Ø­ÙØ¸ ÙÙŠ Ù…Ù„Ù Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©
        tasks_file = Path("data/pending_model_updates.json")
        
        try:
            if tasks_file.exists():
                with open(tasks_file, 'r') as f:
                    tasks = json.load(f)
            else:
                tasks = []
            
            tasks.append(update_task)
            
            with open(tasks_file, 'w') as f:
                json.dump(tasks, f, indent=2, default=str)
                
            logger.info(f"ğŸ“ ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ù…Ù‡Ù…Ø© ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±")
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ù…Ù‡Ù…Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ«: {e}")

    def _analyze_time_performance(self) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£ÙˆÙ‚Ø§Øª"""
        performance = {'best_hours': [], 'worst_hours': []}
        
        # Ø­Ø³Ø§Ø¨ Ø£Ø¯Ø§Ø¡ ÙƒÙ„ Ø³Ø§Ø¹Ø©
        hour_performance = []
        for hour in range(24):
            hour_key = f"hour_{hour}"
            data = self.learning_memory['time_patterns'][hour_key]
            
            if data['total'] > 10:  # Ø¹ÙŠÙ†Ø© ÙƒØ§ÙÙŠØ©
                success_rate = data['success'] / data['total']
                hour_performance.append((hour, success_rate))
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø³Ø§Ø¹Ø§Øª
        hour_performance.sort(key=lambda x: x[1], reverse=True)
        
        performance['best_hours'] = [h[0] for h in hour_performance[:5]]
        performance['worst_hours'] = [h[0] for h in hour_performance[-5:]]
        
        return performance

    def _analyze_pattern_performance(self, symbol: str) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ù†Ù…Ø§Ø·"""
        performance = {'best_patterns': [], 'worst_patterns': []}
        
        # Ø­Ø³Ø§Ø¨ Ø£Ø¯Ø§Ø¡ ÙƒÙ„ Ù†Ù…Ø·
        pattern_scores = []
        for pattern_key, data in self.learning_memory['pattern_performance'].items():
            if symbol in pattern_key:
                total = data['success'] + data['fail']
                if total > 5:  # Ø¹ÙŠÙ†Ø© ÙƒØ§ÙÙŠØ©
                    success_rate = data['success'] / total
                    pattern_scores.append((pattern_key, success_rate, data['confidence']))
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
        pattern_scores.sort(key=lambda x: x[2], reverse=True)
        
        performance['best_patterns'] = [p[0] for p in pattern_scores[:10]]
        performance['worst_patterns'] = [p[0] for p in pattern_scores[-5:]]
        
        return performance

    def _calculate_risk_adjustments(self, symbol: str, strategy: str) -> Dict:
        """Ø­Ø³Ø§Ø¨ ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±"""
        key = f"{symbol}_{strategy}"
        performance = self.learning_memory['strategy_performance'][key]
        
        adjustments = {
            'lot_size_modifier': 1.0,
            'sl_modifier': 1.0,
            'tp_modifier': 1.0,
            'confidence_threshold': 0.85
        }
        
        if performance['trades'] > 50:
            win_rate = performance['wins'] / performance['trades']
            
            # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„ØµÙÙ‚Ø©
            if win_rate > 0.6:
                adjustments['lot_size_modifier'] = 1.2
            elif win_rate < 0.4:
                adjustments['lot_size_modifier'] = 0.8
            
            # ØªØ¹Ø¯ÙŠÙ„ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©
            if win_rate < 0.45:
                adjustments['sl_modifier'] = 0.8  # ÙˆÙ‚Ù Ø®Ø³Ø§Ø±Ø© Ø£Ù‚Ø±Ø¨
            
            # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù‡Ø¯Ù
            avg_pips = performance['total_pips'] / performance['trades']
            if avg_pips < 5:
                adjustments['tp_modifier'] = 1.2  # Ø£Ù‡Ø¯Ø§Ù Ø£Ø¨Ø¹Ø¯
        
        return adjustments

    def _get_general_improvements(self, patterns: Dict, market_context: Dict) -> List[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¹Ø§Ù…Ø©"""
        improvements = []
        
        # ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚
        if market_context.get('volume') == 'low':
            improvements.append({
                'type': 'volume_filter',
                'description': 'ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¯Ø§ÙˆÙ„ ÙÙŠ Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ù…Ù†Ø®ÙØ¶',
                'action': 'Ø¥Ø¶Ø§ÙØ© ÙÙ„ØªØ± Ø­Ø¬Ù… > Ø§Ù„Ù…ØªÙˆØ³Ø· Ã— 0.8',
                'priority': 6
            })
        
        return improvements

    def _generate_strategy_improvements(self, key: str, performance: Dict):
        """ØªÙˆÙ„ÙŠØ¯ ØªØ­Ø³ÙŠÙ†Ø§Øª Ù„Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©"""
        logger.info(f"ğŸ”§ ØªÙˆÙ„ÙŠØ¯ ØªØ­Ø³ÙŠÙ†Ø§Øª Ù„Ù€ {key}")
        
        # ØªØ­Ù„ÙŠÙ„ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù ÙˆØªÙˆÙ„ÙŠØ¯ Ø­Ù„ÙˆÙ„
        improvements = []
        
        win_rate = performance['wins'] / performance['trades']
        avg_pips = performance['total_pips'] / performance['trades']
        
        if win_rate < 0.5:
            improvements.append("Ø²ÙŠØ§Ø¯Ø© Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªØ£ÙƒÙŠØ¯ Ù‚Ø¨Ù„ Ø§Ù„Ø¯Ø®ÙˆÙ„")
            improvements.append("ØªØ­Ø³ÙŠÙ† ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ù„Ø³Ø§Øª")
        
        if avg_pips < 0:
            improvements.append("Ù…Ø±Ø§Ø¬Ø¹Ø© Ù…Ø³ØªÙˆÙŠØ§Øª ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©")
            improvements.append("ØªØ­Ø³ÙŠÙ† Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø© Ù„Ù„Ø¹Ø§Ø¦Ø¯")
        
        # Ø­ÙØ¸ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª
        self._save_strategy_improvements(key, improvements)

    def _save_strategy_improvements(self, key: str, improvements: List[str]):
        """Ø­ÙØ¸ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            parts = key.split('_')
            symbol = parts[0]
            strategy = '_'.join(parts[1:])
            
            for improvement in improvements:
                cursor.execute("""
                    INSERT INTO strategy_adaptations (
                        symbol, timeframe, strategy, parameter_name,
                        old_value, new_value, reason
                    ) VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (symbol, 'H1', strategy, 'improvement', 0, 0, improvement))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª: {e}")

    def _generate_pattern_report(self) -> Dict:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ù†Ù…Ø§Ø·"""
        report = {}
        
        # Ø£ÙØ¶Ù„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
        best_patterns = []
        for pattern_key, data in self.learning_memory['pattern_performance'].items():
            total = data['success'] + data['fail']
            if total > 10:
                success_rate = data['success'] / total
                best_patterns.append({
                    'pattern': pattern_key,
                    'success_rate': success_rate,
                    'confidence': data['confidence'],
                    'occurrences': total
                })
        
        best_patterns.sort(key=lambda x: x['confidence'], reverse=True)
        report['top_patterns'] = best_patterns[:10]
        
        return report

    def _generate_time_report(self) -> Dict:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙˆÙ‚Øª"""
        report = {
            'best_hours': [],
            'best_days': [],
            'best_sessions': []
        }
        
        # Ø£ÙØ¶Ù„ Ø§Ù„Ø³Ø§Ø¹Ø§Øª
        hour_data = []
        for hour in range(24):
            hour_key = f"hour_{hour}"
            data = self.learning_memory['time_patterns'][hour_key]
            if data['total'] > 10:
                success_rate = data['success'] / data['total']
                hour_data.append({'hour': hour, 'success_rate': success_rate})
        
        hour_data.sort(key=lambda x: x['success_rate'], reverse=True)
        report['best_hours'] = hour_data[:5]
        
        return report

    def _generate_recommendations(self, report: Dict) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©"""
        recommendations = []
        
        # ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡
        if report['overall_performance'].get('win_rate', 0) < 0.5:
            recommendations.append("ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø§ÙŠÙŠØ± Ø¯Ø®ÙˆÙ„ Ø§Ù„ØµÙÙ‚Ø§Øª Ù„Ø²ÙŠØ§Ø¯Ø© Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­")
        
        if report['overall_performance'].get('avg_pips', 0) < 5:
            recommendations.append("Ø²ÙŠØ§Ø¯Ø© Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø±Ø¨Ø­ Ø£Ùˆ ØªØ­Ø³ÙŠÙ† Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ø®ÙˆÙ„")
        
        # ØªÙˆØµÙŠØ§Øª Ø§Ù„ÙˆÙ‚Øª
        if report['time_analysis'].get('best_hours'):
            best_hour = report['time_analysis']['best_hours'][0]['hour']
            recommendations.append(f"Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„ØªØ¯Ø§ÙˆÙ„ ÙÙŠ Ø§Ù„Ø³Ø§Ø¹Ø© {best_hour}:00")
        
        return recommendations


# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == "__main__":
    # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±
    learner = UltimateContinuousLearner()
    
    # Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ ØµÙÙ‚Ø© Ù„Ù„ØªØ¹Ù„Ù… Ù…Ù†Ù‡Ø§
    sample_trade = {
        'trade_id': 'TRADE_001',
        'symbol': 'EURUSD',
        'timeframe': 'H1',
        'strategy': 'scalping',
        'entry_time': datetime.now() - timedelta(hours=2),
        'exit_time': datetime.now(),
        'entry_price': 1.0850,
        'exit_price': 1.0870,
        'direction': 'buy',
        'lot_size': 0.1,
        'pnl_pips': 20,
        'pnl_money': 200,
        'indicators': {
            'rsi': 65,
            'macd_hist': 0.0002,
            'atr': 0.0010,
            'adx': 35
        },
        'volume': 1500,
        'volume_avg': 1200,
        'hour': 14
    }
    
    # Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØµÙÙ‚Ø©
    result = learner.learn_from_trade(sample_trade)
    logger.info(f"Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ¹Ù„Ù…: {result}")
    
    # ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡
    report = learner.generate_performance_report('EURUSD', 'scalping')
    logger.info(f"ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡: {json.dumps(report, indent=2)}")