#!/usr/bin/env python3
"""
Advanced Predictor for 95% Accuracy
Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ø¯Ù‚Ø© 95%
"""

import joblib
import pandas as pd
import numpy as np
from datetime import datetime
import os
import json
from pathlib import Path
import glob

class AdvancedPredictor:
    """Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.metrics = {}
        self.load_latest_models()
        
    def load_latest_models(self):
        """ØªØ­Ù…ÙŠÙ„ Ø£Ø­Ø¯Ø« Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
        model_dir = Path("models/advanced")
        if not model_dir.exists():
            print("âš ï¸ No advanced models found. Please run train_advanced_95_percent.py first")
            return
            
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø­Ø¯Ø« Ù…Ù„Ù ØªØ¯Ø±ÙŠØ¨
        model_files = list(model_dir.glob("*_ensemble_*.pkl"))
        if not model_files:
            print("âš ï¸ No ensemble models found")
            return
            
        # ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬
        loaded_count = 0
        for model_file in model_files:
            try:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ø²ÙˆØ¬ ÙˆØ§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ
                filename = model_file.stem  # e.g., EURUSDm_PERIOD_M5_ensemble_20250812_142405
                
                # Extract model key by removing the ensemble timestamp part
                if '_ensemble_' in filename:
                    key = filename.split('_ensemble_')[0]  # EURUSDm_PERIOD_M5
                else:
                    # Fallback: take first 3 parts
                    parts = filename.split('_')
                    if len(parts) >= 3:
                        key = '_'.join(parts[:3])
                    else:
                        key = filename
                
                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                model_data = joblib.load(model_file)
                self.models[key] = model_data['model']
                self.scalers[key] = model_data['scaler']
                self.metrics[key] = model_data.get('metrics', {})
                
                loaded_count += 1
                print(f"âœ… Loaded model: {key}")
                    
            except Exception as e:
                print(f"âŒ Error loading {model_file}: {e}")
                
        print(f"âœ… Loaded {loaded_count} advanced models")
        
    def prepare_features(self, data):
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù…"""
        df = pd.DataFrame([data])
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¤Ø´Ø±Ø§Øª Ø¨Ø³ÙŠØ·Ø© (Ù†ÙØ³ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨)
        # Ù‡Ù†Ø§ ÙŠØ¬Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ FeatureEngineer
        # Ù„ÙƒÙ† Ù„Ù„Ø¨Ø³Ø§Ø·Ø© Ø³Ù†Ø¶ÙŠÙ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        
        features = {}
        
        # Ù†Ø³Ø¨ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±
        features['HL_ratio'] = data['high'] / data['low']
        features['CO_ratio'] = data['close'] / data['open']
        features['body_size'] = abs(data['close'] - data['open'])
        features['upper_shadow'] = data['high'] - max(data['open'], data['close'])
        features['lower_shadow'] = min(data['open'], data['close']) - data['low']
        
        # Ù…Ø¤Ø´Ø±Ø§Øª Ø¨Ø³ÙŠØ·Ø© (ØªØ­ØªØ§Ø¬ Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ©)
        # ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ ÙŠØ¬Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ feature_engineer_fixed.py
        
        return features
        
    def predict_with_confidence(self, symbol, timeframe, current_data, historical_data=None):
        """Ø§Ù„ØªÙ†Ø¨Ø¤ Ù…Ø¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©"""
        key = f"{symbol}_{timeframe}"
        
        if key not in self.models:
            return {
                'signal': 'NEUTRAL',
                'confidence': 0,
                'probability_up': 0.5,
                'probability_down': 0.5,
                'message': f'No model available for {symbol} {timeframe}'
            }
            
        try:
            # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª
            if historical_data is not None:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
                import sys
                sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
                from feature_engineer_fixed_v5 import FeatureEngineer
                engineer = FeatureEngineer()
                
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DataFrame
                df = pd.DataFrame(historical_data)
                df['datetime'] = pd.to_datetime(df['time'], unit='s')
                df.set_index('datetime', inplace=True)
                
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
                df_features = engineer.add_technical_indicators(df)
                df_features = engineer.add_price_features(df_features)
                df_features = engineer.add_pattern_features(df_features)
                df_features = engineer.add_time_features(df_features)
                df_features = engineer.add_market_structure(df_features)
                
                # Ø£Ø®Ø° Ø¢Ø®Ø± ØµÙ
                features = df_features.iloc[-1]
                
                # Ø§Ø®ØªÙŠØ§Ø± Ù†ÙØ³ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
                feature_cols = [col for col in df_features.columns 
                               if col not in ['target', 'target_binary', 'target_3class', 
                                             'future_return', 'time', 'open', 'high', 
                                             'low', 'close', 'volume', 'spread']]
                
                X = features[feature_cols].values.reshape(1, -1)
            else:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙŠØ²Ø§Øª Ø¨Ø³ÙŠØ·Ø©
                features = self.prepare_features(current_data)
                X = pd.DataFrame([features])
                
            # Ø§Ù„ØªØ­Ø¬ÙŠÙ…
            if self.scalers[key] is not None:
                X_scaled = self.scalers[key].transform(X)
            else:
                X_scaled = X
                
            # Ø§Ù„ØªÙ†Ø¨Ø¤
            model = self.models[key]
            prediction = model.predict(X_scaled)[0]
            probabilities = model.predict_proba(X_scaled)[0]
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø©
            confidence = max(probabilities)
            prob_up = probabilities[1] if len(probabilities) > 1 else 0.5
            prob_down = probabilities[0] if len(probabilities) > 1 else 0.5
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø«Ù‚Ø©
            if confidence < 0.6:
                signal = 'NEUTRAL'
                action = 'WAIT'
            elif prediction == 1 and confidence >= 0.7:
                signal = 'STRONG_BUY' if confidence >= 0.85 else 'BUY'
                action = 'BUY'
            elif prediction == 0 and confidence >= 0.7:
                signal = 'STRONG_SELL' if confidence >= 0.85 else 'SELL'
                action = 'SELL'
            else:
                signal = 'NEUTRAL'
                action = 'WAIT'
                
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model_metrics = self.metrics.get(key, {})
            
            result = {
                'signal': signal,
                'action': action,
                'confidence': float(confidence),
                'probability_up': float(prob_up),
                'probability_down': float(prob_down),
                'model_accuracy': model_metrics.get('accuracy', 0),
                'high_conf_accuracy': model_metrics.get('high_confidence_accuracy', 0),
                'timestamp': datetime.now().isoformat()
            }
            
            # Ø¥Ø¶Ø§ÙØ© ØªÙˆØµÙŠØ§Øª Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±
            if action in ['BUY', 'SELL']:
                result['risk_management'] = {
                    'position_size': 0.02 if confidence >= 0.85 else 0.01,  # 2% Ø£Ùˆ 1% Ù…Ù† Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„
                    'stop_loss_pips': 20 if confidence >= 0.85 else 30,
                    'take_profit_pips': 40 if confidence >= 0.85 else 30,
                    'trailing_stop': confidence >= 0.8
                }
                
            return result
            
        except Exception as e:
            return {
                'signal': 'ERROR',
                'confidence': 0,
                'message': f'Prediction error: {str(e)}'
            }
            
    def get_model_performance(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        performance = {}
        
        for key, metrics in self.metrics.items():
            performance[key] = {
                'accuracy': metrics.get('accuracy', 0),
                'precision': metrics.get('precision', 0),
                'recall': metrics.get('recall', 0),
                'f1_score': metrics.get('f1_score', 0),
                'high_confidence_accuracy': metrics.get('high_confidence_accuracy', 0),
                'high_confidence_trades': metrics.get('high_confidence_trades', 0)
            }
            
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª
        if performance:
            avg_accuracy = np.mean([p['accuracy'] for p in performance.values()])
            avg_high_conf = np.mean([p['high_confidence_accuracy'] for p in performance.values()])
            
            performance['overall'] = {
                'average_accuracy': avg_accuracy,
                'average_high_confidence_accuracy': avg_high_conf,
                'models_count': len(self.models)
            }
            
        return performance

# Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
def predict(symbol, timeframe, current_data, historical_data=None):
    """Ø¯Ø§Ù„Ø© Ø³Ø±ÙŠØ¹Ø© Ù„Ù„ØªÙ†Ø¨Ø¤"""
    predictor = AdvancedPredictor()
    return predictor.predict_with_confidence(symbol, timeframe, current_data, historical_data)

if __name__ == "__main__":
    # Ù…Ø«Ø§Ù„ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
    predictor = AdvancedPredictor()
    
    # Ø¹Ø±Ø¶ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    performance = predictor.get_model_performance()
    
    print("="*60)
    print("ðŸŽ¯ Advanced Models Performance")
    print("="*60)
    
    for key, metrics in performance.items():
        if key != 'overall':
            print(f"\n{key}:")
            print(f"  â€¢ Accuracy: {metrics['accuracy']:.2%}")
            print(f"  â€¢ High Confidence Accuracy: {metrics['high_confidence_accuracy']:.2%}")
            
    if 'overall' in performance:
        print(f"\nðŸ“Š Overall Performance:")
        print(f"  â€¢ Average Accuracy: {performance['overall']['average_accuracy']:.2%}")
        print(f"  â€¢ Average High-Conf Accuracy: {performance['overall']['average_high_confidence_accuracy']:.2%}")
        print(f"  â€¢ Total Models: {performance['overall']['models_count']}")