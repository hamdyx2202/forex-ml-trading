#!/usr/bin/env python3
"""
Advanced Predictor with Unified Features
Ø§Ù„Ù…ØªÙ†Ø¨Ø¦ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ÙˆØ­Ø¯Ø©
"""

import joblib
import pandas as pd
import numpy as np
from datetime import datetime
import os
import json
from pathlib import Path
import glob
from loguru import logger
import sys

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù…Ù„ÙØ§Øª
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from feature_engineering_unified import UnifiedFeatureEngineer

class UnifiedAdvancedPredictor:
    """Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø§Ù„Ù…ÙˆØ­Ø¯"""
    
    def __init__(self, models_dir: str = "models/unified"):
        self.models = {}
        self.scalers = {}
        self.metrics = {}
        self.feature_info = {}
        self.models_dir = models_dir
        self.feature_engineer = UnifiedFeatureEngineer()
        self.load_latest_models()
        
    def load_latest_models(self):
        """ØªØ­Ù…ÙŠÙ„ Ø£Ø­Ø¯Ø« Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙˆØ­Ø¯Ø©"""
        model_dir = Path(self.models_dir)
        if not model_dir.exists():
            logger.warning(f"Models directory not found: {self.models_dir}")
            # Try alternative paths
            alt_paths = [
                "models/advanced",
                "../models/unified",
                "../models/advanced"
            ]
            for alt_path in alt_paths:
                if Path(alt_path).exists():
                    model_dir = Path(alt_path)
                    logger.info(f"Using alternative model path: {alt_path}")
                    break
            else:
                logger.error("No models found in any location")
                return
            
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        model_files = list(model_dir.glob("*.pkl"))
        if not model_files:
            logger.warning("No model files found")
            return
            
        # ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬
        loaded_count = 0
        for model_file in model_files:
            try:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                filename = model_file.stem
                
                # ØªØ®Ø·ÙŠ Ù…Ù„ÙØ§Øª non-model
                if 'config' in filename or 'summary' in filename:
                    continue
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙØªØ§Ø­ (symbol_timeframe)
                # Ù…Ø«Ø§Ù„: EURJPYm_PERIOD_H1_unified_v2 -> EURJPYm_PERIOD_H1
                parts = filename.split('_')
                if len(parts) >= 3:
                    # Ø£Ø®Ø° Ø£ÙˆÙ„ 3 Ø£Ø¬Ø²Ø§Ø¡ (Symbol_PERIOD_Timeframe)
                    key = '_'.join(parts[:3])
                else:
                    key = filename
                
                logger.info(f"Loading model: {key} from {filename}")
                
                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                model_data = joblib.load(model_file)
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…ÙˆØ­Ø¯
                if model_data.get('training_metadata', {}).get('unified_features', False):
                    self.models[key] = model_data['model']
                    self.scalers[key] = model_data['scaler']
                    self.metrics[key] = model_data.get('metrics', {})
                    self.feature_info[key] = {
                        'feature_names': model_data.get('feature_names', []),
                        'n_features': model_data.get('n_features', 0),
                        'feature_version': model_data.get('feature_version', 'unknown')
                    }
                    loaded_count += 1
                    logger.info(f"âœ… Loaded {key}: {self.feature_info[key]['n_features']} features")
                else:
                    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ù…Ø¹ ØªØ­Ø°ÙŠØ±
                    self.models[key] = model_data.get('model', model_data)
                    self.scalers[key] = model_data.get('scaler')
                    self.metrics[key] = model_data.get('metrics', {})
                    loaded_count += 1
                    logger.warning(f"âš ï¸ Loaded legacy model: {key}")
                    
            except Exception as e:
                logger.error(f"Error loading {model_file}: {e}")
                
        logger.info(f"âœ… Loaded {loaded_count} models")
        
    def predict_with_confidence(self, symbol, timeframe, current_data, historical_data=None):
        """Ø§Ù„ØªÙ†Ø¨Ø¤ Ù…Ø¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©"""
        key = f"{symbol}_{timeframe}"
        
        if key not in self.models:
            logger.warning(f"No model found for {key}")
            logger.info(f"Available models: {list(self.models.keys())[:5]}...")
            return {
                'signal': 'NEUTRAL',
                'action': 'NO_TRADE',
                'confidence': 0,
                'probability_up': 0.5,
                'probability_down': 0.5,
                'message': f'No model available for {symbol} {timeframe}'
            }
            
        try:
            # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if historical_data is not None and len(historical_data) > 0:
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ø¥Ù„Ù‰ DataFrame
                df = pd.DataFrame(historical_data)
                
                # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
                required_cols = ['time', 'open', 'high', 'low', 'close', 'volume']
                for col in required_cols:
                    if col not in df.columns:
                        logger.error(f"Missing required column: {col}")
                        return self._error_response(f"Missing data: {col}")
                
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙˆÙ‚Øª Ø¥Ù„Ù‰ datetime index
                df['datetime'] = pd.to_datetime(df['time'], unit='s')
                df.set_index('datetime', inplace=True)
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ­Ø¯
                X, feature_names = self.feature_engineer.create_features(df)
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª
                expected_features = self.feature_info.get(key, {}).get('n_features', 0)
                if expected_features > 0 and X.shape[1] != expected_features:
                    logger.error(
                        f"Feature mismatch for {key}: "
                        f"created {X.shape[1]}, expected {expected_features}"
                    )
                    
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
                    if self.feature_info[key].get('feature_names'):
                        X = self._align_features(X, feature_names, key)
                    else:
                        return self._error_response(
                            f"Feature count mismatch: {X.shape[1]} vs {expected_features}"
                        )
                
                # Ø£Ø®Ø° Ø¢Ø®Ø± ØµÙ Ù„Ù„ØªÙ†Ø¨Ø¤
                X_current = X[-1:] if len(X) > 0 else X
                
            else:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙÙ‚Ø·
                return self._error_response("Historical data required for prediction")
            
            # Ø§Ù„ØªØ­Ø¬ÙŠÙ…
            if self.scalers[key] is not None:
                X_scaled = self.scalers[key].transform(X_current)
            else:
                X_scaled = X_current
                
            # Ø§Ù„ØªÙ†Ø¨Ø¤
            model = self.models[key]
            prediction = model.predict(X_scaled)[0]
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ§Øª
            if hasattr(model, 'predict_proba'):
                probabilities = model.predict_proba(X_scaled)[0]
                prob_down = float(probabilities[0])
                prob_up = float(probabilities[1]) if len(probabilities) > 1 else 1 - prob_down
                confidence = float(max(probabilities))
            else:
                # Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ Ù„Ø§ ØªØ¯Ø¹Ù… Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ§Øª
                prob_up = 1.0 if prediction == 1 else 0.0
                prob_down = 1.0 - prob_up
                confidence = 0.7  # Ø«Ù‚Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
                
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø«Ù‚Ø©
            if confidence < 0.6:
                signal = 'NEUTRAL'
                action = 'NO_TRADE'
            elif prediction == 1 and confidence >= 0.7:
                signal = 'STRONG_BUY' if confidence >= 0.85 else 'BUY'
                action = 'BUY'
            elif prediction == 0 and confidence >= 0.7:
                signal = 'STRONG_SELL' if confidence >= 0.85 else 'SELL'
                action = 'SELL'
            else:
                signal = 'NEUTRAL'
                action = 'NO_TRADE'
                
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model_metrics = self.metrics.get(key, {})
            
            result = {
                'signal': signal,
                'action': action,
                'confidence': confidence,
                'probability_up': prob_up,
                'probability_down': prob_down,
                'model_accuracy': model_metrics.get('accuracy', 0),
                'high_conf_accuracy': model_metrics.get('high_confidence_accuracy', 0),
                'feature_count': X.shape[1] if 'X' in locals() else 0,
                'timestamp': datetime.now().isoformat()
            }
            
            # Ø¥Ø¶Ø§ÙØ© ØªÙˆØµÙŠØ§Øª Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±
            if action in ['BUY', 'SELL']:
                result['risk_management'] = {
                    'position_size': 0.02 if confidence >= 0.85 else 0.01,
                    'stop_loss_pips': 20 if confidence >= 0.85 else 30,
                    'take_profit_pips': 40 if confidence >= 0.85 else 30,
                    'trailing_stop': confidence >= 0.8
                }
                
            return result
            
        except Exception as e:
            logger.error(f"Prediction error for {key}: {str(e)}")
            import traceback
            traceback.print_exc()
            return self._error_response(f"Prediction error: {str(e)}")
    
    def _align_features(self, X, current_names, model_key):
        """Ù…Ø­Ø§Ø°Ø§Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨"""
        expected_names = self.feature_info[model_key]['feature_names']
        
        # Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ù„Ù„Ù…Ø­Ø§Ø°Ø§Ø©
        df_current = pd.DataFrame(X, columns=current_names)
        aligned_data = []
        
        for feature in expected_names:
            if feature in df_current.columns:
                aligned_data.append(df_current[feature].values)
            else:
                # Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
                logger.warning(f"Missing feature: {feature}")
                aligned_data.append(np.zeros(X.shape[0]))
        
        return np.column_stack(aligned_data)
    
    def _error_response(self, message):
        """Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø®Ø·Ø£ Ù…ÙˆØ­Ø¯Ø©"""
        return {
            'signal': 'ERROR',
            'action': 'NO_TRADE',
            'confidence': 0,
            'probability_up': 0.5,
            'probability_down': 0.5,
            'message': message,
            'timestamp': datetime.now().isoformat()
        }
    
    def get_model_performance(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        performance = {}
        
        for key, metrics in self.metrics.items():
            performance[key] = {
                'accuracy': metrics.get('accuracy', 0),
                'precision': metrics.get('precision', 0),
                'recall': metrics.get('recall', 0),
                'f1_score': metrics.get('f1_score', 0),
                'high_confidence_accuracy': metrics.get('high_confidence_accuracy', 0),
                'high_confidence_trades': metrics.get('high_confidence_trades', 0),
                'feature_count': self.feature_info.get(key, {}).get('n_features', 0),
                'feature_version': self.feature_info.get(key, {}).get('feature_version', 'unknown')
            }
            
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª
        if performance:
            avg_accuracy = np.mean([p['accuracy'] for p in performance.values()])
            avg_high_conf = np.mean([p['high_confidence_accuracy'] for p in performance.values()])
            
            performance['overall'] = {
                'average_accuracy': avg_accuracy,
                'average_high_confidence_accuracy': avg_high_conf,
                'models_count': len(self.models),
                'unified_features': True
            }
            
        return performance

# Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
if __name__ == "__main__":
    # Ù…Ø«Ø§Ù„ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
    predictor = UnifiedAdvancedPredictor()
    
    # Ø¹Ø±Ø¶ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    performance = predictor.get_model_performance()
    
    print("="*60)
    print("ğŸ¯ Unified Models Performance")
    print("="*60)
    
    for key, metrics in performance.items():
        if key != 'overall':
            print(f"\n{key}:")
            print(f"  â€¢ Accuracy: {metrics['accuracy']:.2%}")
            print(f"  â€¢ High Confidence Accuracy: {metrics['high_confidence_accuracy']:.2%}")
            print(f"  â€¢ Feature Count: {metrics['feature_count']}")
            print(f"  â€¢ Feature Version: {metrics['feature_version']}")
            
    if 'overall' in performance:
        print(f"\nğŸ“Š Overall Performance:")
        print(f"  â€¢ Average Accuracy: {performance['overall']['average_accuracy']:.2%}")
        print(f"  â€¢ Average High-Conf Accuracy: {performance['overall']['average_high_confidence_accuracy']:.2%}")
        print(f"  â€¢ Total Models: {performance['overall']['models_count']}")
        print(f"  â€¢ Unified Features: {performance['overall']['unified_features']}")