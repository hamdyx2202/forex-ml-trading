#!/usr/bin/env python3
"""
Advanced MT5 Bridge Server - Uses Trained ML Models
Ø®Ø§Ø¯Ù… Ù…ØªÙ‚Ø¯Ù… ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import json
import numpy as np
import pandas as pd
from datetime import datetime
from pathlib import Path
import joblib
from loguru import logger
import sys
import warnings
warnings.filterwarnings('ignore')

# Setup logging
logger.remove()
logger.add(sys.stdout, format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>")
logger.add("logs/advanced_server.log", rotation="1 day", retention="30 days")

# Import advanced predictor
sys.path.append(str(Path(__file__).parent.parent))
from src.advanced_predictor_95 import AdvancedPredictor
from feature_engineer_adaptive import AdaptiveFeatureEngineer as FeatureEngineer

app = Flask(__name__)
CORS(app)

class AdvancedMLServer:
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø®Ø§Ø¯Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
        self.predictor = AdvancedPredictor()
        self.feature_engineer = FeatureEngineer(target_features=68)
        self.models_loaded = len(self.predictor.models) > 0
        
        logger.info(f"Advanced ML Server initialized")
        logger.info(f"Models loaded: {len(self.predictor.models)}")
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­Ù…Ù„Ø©
        for model_key in self.predictor.models.keys():
            metrics = self.predictor.metrics.get(model_key, {})
            logger.info(f"  â€¢ {model_key}: Accuracy={metrics.get('accuracy', 0):.2%}")
    
    def process_signal_request(self, data):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            if not data or 'symbol' not in data:
                return {
                    'action': 'ERROR',
                    'confidence': 0,
                    'reason': 'Missing symbol'
                }
            
            symbol = data.get('symbol', '')
            timeframe = data.get('timeframe', 'M5')
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            timeframe_map = {
                'M5': 'PERIOD_M5',
                'M15': 'PERIOD_M15',
                'H1': 'PERIOD_H1',
                'H4': 'PERIOD_H4'
            }
            model_timeframe = timeframe_map.get(timeframe, 'PERIOD_M5')
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ù…ÙˆØ¹
            if 'data' in data and isinstance(data['data'], list) and len(data['data']) > 0:
                # Ù„Ø¯ÙŠÙ†Ø§ Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ù…ÙˆØ¹ ÙƒØ§Ù…Ù„Ø©
                bars_data = data['data']
                
                if len(bars_data) < 50:
                    return {
                        'action': 'NO_TRADE',
                        'confidence': 0,
                        'reason': f'Not enough bars: {len(bars_data)}, need at least 50'
                    }
                
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DataFrame
                df = pd.DataFrame(bars_data)
                
                # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¨Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØµØ­ÙŠØ­Ø©
                if 'time' in df.columns:
                    df['datetime'] = pd.to_datetime(df['time'], unit='s')
                    df.set_index('datetime', inplace=True)
                
                # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª numeric
                for col in ['open', 'high', 'low', 'close', 'volume']:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors='coerce')
                
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©
                logger.info(f"Processing {len(df)} bars for {symbol} {timeframe}")
                
                try:
                    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙŠØ²Ø§Øª
                    df_features = self.feature_engineer.create_features(df.copy())
                    
                    if df_features.empty:
                        logger.warning("No features created")
                        return {
                            'action': 'NO_TRADE',
                            'confidence': 0,
                            'reason': 'Failed to create features'
                        }
                    
                    # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
                    model_key = f"{symbol}_{model_timeframe}"
                    logger.info(f"ðŸ” Model key: {model_key} (symbol={symbol}, timeframe={model_timeframe})")
                    
                    logger.info(f"ðŸ” Searching for model: {model_key}")
                    if model_key not in self.predictor.models:
                        logger.warning(f"No model found for {model_key}")
                        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙˆÙ† suffix
                        alt_key = f"{symbol}_{model_timeframe}"
                        if alt_key in self.predictor.models:
                            model_key = alt_key
                        else:
                            return {
                                'action': 'NO_TRADE',
                                'confidence': 0,
                                'reason': f'No model for {model_key}'
                            }
                    
                    # Ø§Ù„ØªÙ†Ø¨Ø¤
                    result = self.predictor.predict_with_confidence(
                        symbol=symbol,
                        timeframe=model_timeframe,
                        current_data=None,
                        historical_data=bars_data
                    )
                    
                    logger.info(f"Prediction for {symbol}: {result}")
                    
                    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø±Ø¯
                    response = {
                        'signal': result.get('signal', 'NO_TRADE'),
                        'action': result.get('action', 'NO_TRADE'),
                        'confidence': float(result.get('confidence', 0)),
                        'probability_up': float(result.get('probability_up', 0.5)),
                        'probability_down': float(result.get('probability_down', 0.5)),
                        'model_accuracy': float(result.get('model_accuracy', 0)),
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    # Ø¥Ø¶Ø§ÙØ© ØªÙˆØµÙŠØ§Øª Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±
                    if 'risk_management' in result:
                        response['risk_management'] = result['risk_management']
                    
                    return response
                    
                except Exception as e:
                    logger.error(f"Feature engineering error: {e}")
                    return {
                        'action': 'ERROR',
                        'confidence': 0,
                        'reason': f'Feature engineering failed: {str(e)}'
                    }
                    
            else:
                # Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ù…ÙˆØ¹
                return {
                    'action': 'NO_TRADE',
                    'confidence': 0,
                    'reason': 'No candle data provided'
                }
                
        except Exception as e:
            logger.error(f"Error processing signal: {e}")
            return {
                'action': 'ERROR',
                'confidence': 0,
                'reason': str(e)
            }

# Ø¥Ù†Ø´Ø§Ø¡ instance Ù…Ù† Ø§Ù„Ø®Ø§Ø¯Ù…
ml_server = AdvancedMLServer()

@app.route('/health', methods=['GET'])
def health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ø®Ø§Ø¯Ù…"""
    return jsonify({
        'status': 'healthy',
        'models_loaded': ml_server.models_loaded,
        'models_count': len(ml_server.predictor.models),
        'models': list(ml_server.predictor.models.keys()),
        'timestamp': datetime.now().isoformat()
    })

@app.route('/get_signal', methods=['POST'])
def get_signal():
    """Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø·Ù„Ø¨ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù…Ù† MT5"""
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        raw_data = request.get_data(as_text=True)
        logger.info(f"Received request from {request.remote_addr}")
        
        # ØªØ­Ù„ÙŠÙ„ JSON
        try:
            data = json.loads(raw_data.strip())
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {e}")
            return jsonify({
                'action': 'ERROR',
                'confidence': 0,
                'reason': 'Invalid JSON'
            }), 400
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨
        response = ml_server.process_signal_request(data)
        
        logger.info(f"Response: {response}")
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"Server error: {e}")
        return jsonify({
            'action': 'ERROR',
            'confidence': 0,
            'reason': str(e)
        }), 500

@app.route('/model_performance', methods=['GET'])
def model_performance():
    """Ø¹Ø±Ø¶ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
    try:
        performance = ml_server.predictor.get_model_performance()
        return jsonify(performance)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def run_server(host='0.0.0.0', port=5000):
    """ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù…"""
    logger.info("="*60)
    logger.info("ðŸš€ Starting Advanced ML Bridge Server")
    logger.info(f"ðŸ“¡ Listening on {host}:{port}")
    logger.info(f"ðŸ§  Models loaded: {len(ml_server.predictor.models)}")
    logger.info("="*60)
    
    if not ml_server.models_loaded:
        logger.warning("âš ï¸ No models loaded! Please run train_advanced_95_percent.py first")
    
    app.run(host=host, port=port, debug=False)

if __name__ == '__main__':
    run_server()