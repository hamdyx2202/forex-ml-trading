#!/usr/bin/env python3
"""
Integrated Training System with SL/TP Optimization
Ù†Ø¸Ø§Ù… ØªØ¯Ø±ÙŠØ¨ Ù…ØªÙƒØ§Ù…Ù„ Ù…Ø¹ ØªØ­Ø³ÙŠÙ† ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import joblib
from loguru import logger
import sqlite3
import json
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing as mp
import warnings
warnings.filterwarnings('ignore')

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø±
import sys
sys.path.append(str(Path(__file__).parent))

from advanced_learner_unified_sltp import AdvancedLearnerWithSLTP
from continuous_learner_unified_sltp import ContinuousLearnerWithSLTP
from feature_engineer_adaptive_75 import AdaptiveFeatureEngineer75
from instrument_manager import InstrumentManager
from performance_tracker import PerformanceTracker

class IntegratedTrainingSystemSLTP:
    """Ù†Ø¸Ø§Ù… ØªØ¯Ø±ÙŠØ¨ Ù…ØªÙƒØ§Ù…Ù„ ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù… ÙˆØ§Ù„Ù…Ø³ØªÙ…Ø± Ù…Ø¹ SL/TP"""
    
    def __init__(self):
        self.advanced_learner = AdvancedLearnerWithSLTP()
        self.continuous_learner = ContinuousLearnerWithSLTP()
        self.instrument_manager = InstrumentManager()
        self.performance_tracker = PerformanceTracker()
        
        self.models_dir = Path("models/unified_sltp")
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        self.training_config = {
            'min_data_points': 1000,
            'test_size': 0.2,
            'validation_size': 0.1,
            'max_workers': mp.cpu_count() - 1,
            'batch_size': 5,
            'timeframes': ['M5', 'M15', 'H1', 'H4'],
            'sl_tp_optimization': {
                'lookforward_candles': 100,
                'min_sl_pips': 10,
                'max_sl_pips': 200,
                'min_tp_pips': 10,
                'max_tp_pips': 500,
                'risk_reward_min': 1.0,
                'risk_reward_target': 2.0
            }
        }
        
    def train_all_instruments(self, instrument_types=None, force_retrain=False):
        """ØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©"""
        logger.info("ğŸš€ Starting integrated training system with SL/TP optimization...")
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø¯ÙˆØ§Øª
        if instrument_types:
            instruments = self.instrument_manager.get_instruments_by_types(instrument_types)
        else:
            instruments = self.instrument_manager.get_all_instruments()
            
        logger.info(f"ğŸ“Š Found {len(instruments)} instruments to train")
        
        # ØªØ¬Ù…ÙŠØ¹ Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        training_tasks = []
        for instrument in instruments:
            for timeframe in self.training_config['timeframes']:
                if force_retrain or self.needs_training(instrument['symbol'], timeframe):
                    training_tasks.append((instrument['symbol'], timeframe, instrument['type']))
                    
        logger.info(f"ğŸ“‹ Total training tasks: {len(training_tasks)}")
        
        # ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ
        results = self.parallel_training(training_tasks)
        
        # ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        self.summarize_results(results)
        
        # Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø± Ù„Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
        important_pairs = self.get_important_pairs(instruments)
        self.start_continuous_learning(important_pairs)
        
        return results
        
    def parallel_training(self, training_tasks):
        """ØªØ¯Ø±ÙŠØ¨ Ù…ØªÙˆØ§Ø²ÙŠ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬"""
        results = []
        
        with ProcessPoolExecutor(max_workers=self.training_config['max_workers']) as executor:
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ù‡Ø§Ù… Ø¥Ù„Ù‰ Ø¯ÙØ¹Ø§Øª
            batches = [training_tasks[i:i+self.training_config['batch_size']] 
                      for i in range(0, len(training_tasks), self.training_config['batch_size'])]
            
            future_to_task = {}
            
            for batch in batches:
                for task in batch:
                    future = executor.submit(self.train_single_model, *task)
                    future_to_task[future] = task
                    
                # Ø§Ù†ØªØ¸Ø§Ø± Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„Ø¯ÙØ¹Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
                for future in as_completed(future_to_task):
                    task = future_to_task[future]
                    try:
                        result = future.result()
                        results.append(result)
                        
                        if result['success']:
                            logger.info(f"âœ… {task[0]} {task[1]} - Accuracy: {result['accuracy']:.2%}, "
                                      f"SL MAE: {result['sl_mae']:.1f}, TP MAE: {result['tp_mae']:.1f}")
                        else:
                            logger.warning(f"âŒ {task[0]} {task[1]} - {result['error']}")
                            
                    except Exception as e:
                        logger.error(f"Error training {task[0]} {task[1]}: {str(e)}")
                        results.append({
                            'pair': task[0],
                            'timeframe': task[1],
                            'success': False,
                            'error': str(e)
                        })
                        
        return results
        
    def train_single_model(self, symbol, timeframe, instrument_type):
        """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ø­Ø¯ Ù…Ø¹ SL/TP Ù…Ø­Ø³Ù‘Ù†"""
        try:
            logger.info(f"ğŸ¯ Training {symbol} {timeframe} with enhanced SL/TP...")
            
            # Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            df = self.load_training_data(symbol, timeframe)
            if df is None or len(df) < self.training_config['min_data_points']:
                return {
                    'pair': symbol,
                    'timeframe': timeframe,
                    'success': False,
                    'error': 'Insufficient data'
                }
                
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
            feature_engineer = AdaptiveFeatureEngineer75(target_features=75)
            df_features = feature_engineer.engineer_features(df, symbol)
            
            # Ø­Ø³Ø§Ø¨ SL/TP Ø§Ù„Ø£Ù…Ø«Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø£Ø¯Ø§Ø©
            df_with_targets = self.calculate_optimal_targets_by_type(
                df_features, symbol, instrument_type
            )
            
            # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            success = self.advanced_learner.train_model_with_sltp(symbol, timeframe)
            
            if success:
                # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                evaluation = self.evaluate_model(symbol, timeframe, df_with_targets)
                
                return {
                    'pair': symbol,
                    'timeframe': timeframe,
                    'success': True,
                    'accuracy': evaluation['accuracy'],
                    'sl_mae': evaluation['sl_mae'],
                    'tp_mae': evaluation['tp_mae'],
                    'sharpe_ratio': evaluation['sharpe_ratio'],
                    'max_drawdown': evaluation['max_drawdown'],
                    'win_rate': evaluation['win_rate'],
                    'avg_rr': evaluation['avg_rr']
                }
            else:
                return {
                    'pair': symbol,
                    'timeframe': timeframe,
                    'success': False,
                    'error': 'Training failed'
                }
                
        except Exception as e:
            logger.error(f"Error in train_single_model: {str(e)}")
            return {
                'pair': symbol,
                'timeframe': timeframe,
                'success': False,
                'error': str(e)
            }
            
    def calculate_optimal_targets_by_type(self, df, symbol, instrument_type):
        """Ø­Ø³Ø§Ø¨ SL/TP Ø§Ù„Ø£Ù…Ø«Ù„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø£Ø¯Ø§Ø©"""
        logger.info(f"ğŸ’¡ Calculating optimal targets for {instrument_type} instrument...")
        
        df = df.copy()
        config = self.training_config['sl_tp_optimization']
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø®Ø§ØµØ© Ø¨Ù†ÙˆØ¹ Ø§Ù„Ø£Ø¯Ø§Ø©
        type_configs = {
            'forex_major': {
                'sl_multiplier': 1.0,
                'tp_multiplier': 2.0,
                'min_sl': 10,
                'typical_sl': 30,
                'typical_tp': 60
            },
            'forex_cross': {
                'sl_multiplier': 1.2,
                'tp_multiplier': 2.2,
                'min_sl': 15,
                'typical_sl': 40,
                'typical_tp': 80
            },
            'metals': {
                'sl_multiplier': 1.5,
                'tp_multiplier': 2.5,
                'min_sl': 30,
                'typical_sl': 100,
                'typical_tp': 200
            },
            'indices': {
                'sl_multiplier': 1.3,
                'tp_multiplier': 2.0,
                'min_sl': 20,
                'typical_sl': 50,
                'typical_tp': 100
            },
            'crypto': {
                'sl_multiplier': 2.0,
                'tp_multiplier': 3.0,
                'min_sl': 50,
                'typical_sl': 150,
                'typical_tp': 300
            },
            'energy': {
                'sl_multiplier': 1.8,
                'tp_multiplier': 2.5,
                'min_sl': 40,
                'typical_sl': 80,
                'typical_tp': 160
            }
        }
        
        type_config = type_configs.get(instrument_type, type_configs['forex_major'])
        
        # Ø­Ø³Ø§Ø¨ Ù‚ÙŠÙ…Ø© Ø§Ù„Ù†Ù‚Ø·Ø©
        pip_value = self._get_pip_value(symbol)
        
        # Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø©
        df['optimal_sl_pips'] = 0.0
        df['optimal_tp_pips'] = 0.0
        df['trade_quality'] = 'normal'
        df['confidence_level'] = 0.5
        
        lookforward = config['lookforward_candles']
        
        for i in range(len(df) - lookforward):
            current_price = df['close'].iloc[i]
            future_data = df.iloc[i+1:i+lookforward+1]
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙˆÙ‚
            volatility = df['ATR'].iloc[i] / current_price
            trend_strength = self._calculate_trend_strength(df.iloc[max(0, i-50):i+1])
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ÙˆØ§Ù„Ø«Ù‚Ø©
            signal, confidence = self._determine_signal_with_confidence(df.iloc[i])
            
            if signal in ['BUY', 'SELL']:
                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ø±ÙƒØ© Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
                if signal == 'BUY':
                    max_favorable = future_data['high'].max() - current_price
                    max_adverse = current_price - future_data['low'].min()
                else:
                    max_favorable = current_price - future_data['low'].min()
                    max_adverse = future_data['high'].max() - current_price
                
                # Ø­Ø³Ø§Ø¨ SL Ø§Ù„Ø£Ù…Ø«Ù„
                base_sl = max(max_adverse * 0.7, type_config['min_sl'] * pip_value)
                volatility_adjusted_sl = base_sl * (1 + volatility * 2)
                optimal_sl = min(volatility_adjusted_sl * type_config['sl_multiplier'], 
                               config['max_sl_pips'] * pip_value)
                
                # Ø­Ø³Ø§Ø¨ TP Ø§Ù„Ø£Ù…Ø«Ù„
                base_tp = max_favorable * 0.7  # Ø§Ø³ØªÙ‡Ø¯Ø§Ù 70% Ù…Ù† Ø§Ù„Ø­Ø±ÙƒØ© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
                
                # ØªØ¹Ø¯ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‚ÙˆØ© Ø§Ù„ØªØ±Ù†Ø¯
                if trend_strength > 0.7:
                    base_tp *= 1.3  # Ø£Ù‡Ø¯Ø§Ù Ø£ÙƒØ¨Ø± ÙÙŠ ØªØ±Ù†Ø¯ Ù‚ÙˆÙŠ
                elif trend_strength < 0.3:
                    base_tp *= 0.8  # Ø£Ù‡Ø¯Ø§Ù Ø£ØµØºØ± ÙÙŠ Ø³ÙˆÙ‚ Ø¬Ø§Ù†Ø¨ÙŠ
                
                optimal_tp = min(base_tp * type_config['tp_multiplier'], 
                               config['max_tp_pips'] * pip_value)
                
                # Ø¶Ù…Ø§Ù† Ù†Ø³Ø¨Ø© Ù…Ø®Ø§Ø·Ø±Ø©/Ø¹Ø§Ø¦Ø¯ Ù…Ù†Ø§Ø³Ø¨Ø©
                rr_ratio = optimal_tp / optimal_sl if optimal_sl > 0 else 1
                
                if rr_ratio < config['risk_reward_min']:
                    # ØªØ¹Ø¯ÙŠÙ„ TP Ù„ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù…Ù† RR
                    optimal_tp = optimal_sl * config['risk_reward_min']
                elif rr_ratio > 5:
                    # ØªÙ‚Ù„ÙŠÙ„ TP Ø¥Ø°Ø§ ÙƒØ§Ù† ØºÙŠØ± ÙˆØ§Ù‚Ø¹ÙŠ
                    optimal_tp = optimal_sl * 4
                
                # ØªØ¹Ø¯ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø«Ù‚Ø©
                if confidence < 0.6:
                    optimal_sl *= 0.8  # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©
                    optimal_tp *= 0.9
                elif confidence > 0.8:
                    optimal_tp *= 1.1  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù‡Ø¯Ù Ù‚Ù„ÙŠÙ„Ø§Ù‹
                
                # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Ù‚Ø§Ø·
                df.loc[i, 'optimal_sl_pips'] = optimal_sl / pip_value
                df.loc[i, 'optimal_tp_pips'] = optimal_tp / pip_value
                df.loc[i, 'confidence_level'] = confidence
                
                # ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙÙ‚Ø©
                if rr_ratio >= 2 and confidence >= 0.7:
                    df.loc[i, 'trade_quality'] = 'high'
                elif rr_ratio >= 1.5 or confidence >= 0.6:
                    df.loc[i, 'trade_quality'] = 'normal'
                else:
                    df.loc[i, 'trade_quality'] = 'low'
            else:
                # Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù€ NO_TRADE
                df.loc[i, 'optimal_sl_pips'] = type_config['typical_sl']
                df.loc[i, 'optimal_tp_pips'] = type_config['typical_tp']
                df.loc[i, 'confidence_level'] = 0.3
                
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        trades = df[df['trade_quality'] != 'normal']
        if len(trades) > 0:
            logger.info(f"   Trade quality distribution: {df['trade_quality'].value_counts().to_dict()}")
            logger.info(f"   Avg SL: {df['optimal_sl_pips'].mean():.1f} pips")
            logger.info(f"   Avg TP: {df['optimal_tp_pips'].mean():.1f} pips")
            logger.info(f"   Avg R:R: {(df['optimal_tp_pips'] / df['optimal_sl_pips']).mean():.2f}")
            
        return df
        
    def _determine_signal_with_confidence(self, row):
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù…Ø¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©"""
        indicators = {}
        signal_scores = {'BUY': 0, 'SELL': 0}
        
        # Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
        if 'RSI' in row and not pd.isna(row['RSI']):
            if row['RSI'] < 30:
                signal_scores['BUY'] += 2
                indicators['RSI'] = 'oversold'
            elif row['RSI'] > 70:
                signal_scores['SELL'] += 2
                indicators['RSI'] = 'overbought'
                
        if 'MACD' in row and 'MACD_signal' in row:
            if row['MACD'] > row['MACD_signal']:
                signal_scores['BUY'] += 1.5
                indicators['MACD'] = 'bullish'
            else:
                signal_scores['SELL'] += 1.5
                indicators['MACD'] = 'bearish'
                
        if 'BB_upper' in row and 'BB_lower' in row:
            bb_position = (row['close'] - row['BB_lower']) / (row['BB_upper'] - row['BB_lower'])
            if bb_position < 0.2:
                signal_scores['BUY'] += 1.5
                indicators['BB'] = 'lower'
            elif bb_position > 0.8:
                signal_scores['SELL'] += 1.5
                indicators['BB'] = 'upper'
                
        if 'distance_to_support_pct' in row and 'distance_to_resistance_pct' in row:
            if row['distance_to_support_pct'] < 1.0:
                signal_scores['BUY'] += 2
                indicators['SR'] = 'near_support'
            elif row['distance_to_resistance_pct'] < 1.0:
                signal_scores['SELL'] += 2
                indicators['SR'] = 'near_resistance'
                
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ÙˆØ§Ù„Ø«Ù‚Ø©
        total_score = signal_scores['BUY'] + signal_scores['SELL']
        
        if total_score == 0:
            return 'NO_TRADE', 0.0
            
        if signal_scores['BUY'] > signal_scores['SELL'] * 1.5:
            confidence = signal_scores['BUY'] / (total_score + 2)  # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø«Ù‚Ø©
            return 'BUY', min(confidence, 0.95)
        elif signal_scores['SELL'] > signal_scores['BUY'] * 1.5:
            confidence = signal_scores['SELL'] / (total_score + 2)
            return 'SELL', min(confidence, 0.95)
        else:
            return 'NO_TRADE', 0.3
            
    def _calculate_trend_strength(self, df):
        """Ø­Ø³Ø§Ø¨ Ù‚ÙˆØ© Ø§Ù„ØªØ±Ù†Ø¯"""
        if len(df) < 20:
            return 0.5
            
        # Ø­Ø³Ø§Ø¨ Ù…ÙŠÙ„ Ø®Ø· Ø§Ù„Ø§ØªØ¬Ø§Ù‡
        prices = df['close'].values
        x = np.arange(len(prices))
        
        # Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ
        slope = np.polyfit(x, prices, 1)[0]
        
        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù‚ÙˆØ©
        price_range = prices.max() - prices.min()
        if price_range > 0:
            normalized_slope = abs(slope) / price_range * len(prices)
            return min(normalized_slope, 1.0)
        
        return 0.5
        
    def evaluate_model(self, symbol, timeframe, test_data):
        """ØªÙ‚ÙŠÙŠÙ… Ø´Ø§Ù…Ù„ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬"""
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            filename = f"{symbol}_{timeframe}_unified.pkl"
            filepath = self.models_dir / filename
            
            if not filepath.exists():
                return {
                    'accuracy': 0,
                    'sl_mae': 0,
                    'tp_mae': 0,
                    'sharpe_ratio': 0,
                    'max_drawdown': 0,
                    'win_rate': 0,
                    'avg_rr': 0
                }
                
            model_data = joblib.load(filepath)
            
            # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
            trades = []
            
            for i in range(100, len(test_data) - 1):
                # Ø§Ù„ØªÙ†Ø¨Ø¤
                features = test_data.iloc[i:i+1]
                prediction = self.advanced_learner.predict_with_sltp(
                    features, symbol, timeframe
                )
                
                if prediction and prediction['signal'] != 'NO_TRADE':
                    # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ØµÙÙ‚Ø©
                    entry_price = test_data['close'].iloc[i]
                    sl_pips = prediction['sl_pips']
                    tp_pips = prediction['tp_pips']
                    
                    # ØªØªØ¨Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                    future_prices = test_data.iloc[i+1:i+50]
                    
                    trade_result = self._simulate_trade(
                        prediction['signal'], entry_price, 
                        sl_pips, tp_pips, future_prices
                    )
                    
                    trades.append(trade_result)
                    
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            if trades:
                df_trades = pd.DataFrame(trades)
                
                wins = df_trades['result'] == 'win'
                win_rate = wins.sum() / len(df_trades)
                
                returns = df_trades['pnl_pips'].values
                sharpe_ratio = np.mean(returns) / (np.std(returns) + 1e-10) * np.sqrt(252)
                
                cumulative_pnl = df_trades['pnl_pips'].cumsum()
                max_drawdown = (cumulative_pnl.cummax() - cumulative_pnl).max()
                
                avg_rr = df_trades['actual_rr'].mean()
                
                return {
                    'accuracy': model_data['metrics']['signal_accuracy'],
                    'sl_mae': model_data['metrics']['sl_mae'],
                    'tp_mae': model_data['metrics']['tp_mae'],
                    'sharpe_ratio': sharpe_ratio,
                    'max_drawdown': max_drawdown,
                    'win_rate': win_rate,
                    'avg_rr': avg_rr
                }
            else:
                return {
                    'accuracy': model_data['metrics']['signal_accuracy'],
                    'sl_mae': model_data['metrics']['sl_mae'],
                    'tp_mae': model_data['metrics']['tp_mae'],
                    'sharpe_ratio': 0,
                    'max_drawdown': 0,
                    'win_rate': 0,
                    'avg_rr': 0
                }
                
        except Exception as e:
            logger.error(f"Error evaluating model: {str(e)}")
            return {
                'accuracy': 0,
                'sl_mae': 0,
                'tp_mae': 0,
                'sharpe_ratio': 0,
                'max_drawdown': 0,
                'win_rate': 0,
                'avg_rr': 0
            }
            
    def _simulate_trade(self, signal, entry_price, sl_pips, tp_pips, future_prices):
        """Ù…Ø­Ø§ÙƒØ§Ø© ØµÙÙ‚Ø© ÙˆØ§Ø­Ø¯Ø©"""
        pip_value = 0.0001  # Ø§ÙØªØ±Ø§Ø¶ÙŠ
        
        if signal == 'BUY':
            sl_price = entry_price - (sl_pips * pip_value)
            tp_price = entry_price + (tp_pips * pip_value)
            
            for idx, row in future_prices.iterrows():
                if row['low'] <= sl_price:
                    return {
                        'result': 'loss',
                        'pnl_pips': -sl_pips,
                        'actual_rr': 0
                    }
                elif row['high'] >= tp_price:
                    return {
                        'result': 'win',
                        'pnl_pips': tp_pips,
                        'actual_rr': tp_pips / sl_pips
                    }
                    
        else:  # SELL
            sl_price = entry_price + (sl_pips * pip_value)
            tp_price = entry_price - (tp_pips * pip_value)
            
            for idx, row in future_prices.iterrows():
                if row['high'] >= sl_price:
                    return {
                        'result': 'loss',
                        'pnl_pips': -sl_pips,
                        'actual_rr': 0
                    }
                elif row['low'] <= tp_price:
                    return {
                        'result': 'win',
                        'pnl_pips': tp_pips,
                        'actual_rr': tp_pips / sl_pips
                    }
                    
        # Ù„Ù… ÙŠØµÙ„ Ù„Ø£ÙŠ Ù‡Ø¯Ù
        return {
            'result': 'open',
            'pnl_pips': 0,
            'actual_rr': 0
        }
        
    def needs_training(self, symbol, timeframe):
        """ÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ­ØªØ§Ø¬ ØªØ¯Ø±ÙŠØ¨"""
        filename = f"{symbol}_{timeframe}_unified.pkl"
        filepath = self.models_dir / filename
        
        if not filepath.exists():
            return True
            
        try:
            model_data = joblib.load(filepath)
            training_date = datetime.fromisoformat(model_data['training_date'])
            
            # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¥Ø°Ø§ Ù…Ø± Ø£ÙƒØ«Ø± Ù…Ù† 7 Ø£ÙŠØ§Ù…
            if (datetime.now() - training_date).days > 7:
                return True
                
            # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¶Ø¹ÙŠÙØ§Ù‹
            if model_data['metrics']['signal_accuracy'] < 0.55:
                return True
                
        except:
            return True
            
        return False
        
    def load_training_data(self, symbol, timeframe):
        """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        try:
            conn = sqlite3.connect("trading_data.db")
            
            query = f"""
            SELECT * FROM ohlcv_data 
            WHERE symbol = ? AND timeframe = ?
            ORDER BY timestamp DESC
            LIMIT 10000
            """
            
            df = pd.read_sql_query(query, conn, params=(symbol, timeframe))
            conn.close()
            
            if len(df) > 0:
                df = df.sort_values('timestamp').reset_index(drop=True)
                return df
                
        except Exception as e:
            logger.error(f"Error loading data: {str(e)}")
            
        return None
        
    def get_important_pairs(self, instruments):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ù…Ù‡Ù…Ø© Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±"""
        important = []
        
        # Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        major_pairs = ['EURUSD', 'GBPUSD', 'USDJPY', 'USDCHF', 'AUDUSD', 'NZDUSD', 'USDCAD']
        
        # Ø§Ù„Ù…Ø¹Ø§Ø¯Ù† Ø§Ù„Ù…Ù‡Ù…Ø©
        metals = ['XAUUSD', 'XAGUSD']
        
        # Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        indices = ['US30', 'NAS100', 'SP500']
        
        all_important = major_pairs + metals + indices
        
        for instrument in instruments:
            if instrument['symbol'] in all_important:
                important.append(instrument['symbol'])
                
        return important[:10]  # Ø£Ø¹Ù„Ù‰ 10 Ø£Ø²ÙˆØ§Ø¬
        
    def start_continuous_learning(self, pairs):
        """Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø± Ù„Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ù…Ù‡Ù…Ø©"""
        if pairs:
            logger.info(f"ğŸ”„ Starting continuous learning for {len(pairs)} important pairs...")
            self.continuous_learner.start_continuous_learning(
                pairs, 
                ['H1', 'H4']  # Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ø§Ù‹
            )
            
    def summarize_results(self, results):
        """ØªÙ„Ø®ÙŠØµ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        successful = [r for r in results if r.get('success', False)]
        failed = [r for r in results if not r.get('success', False)]
        
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š TRAINING SUMMARY")
        logger.info("="*60)
        
        logger.info(f"âœ… Successful: {len(successful)}")
        logger.info(f"âŒ Failed: {len(failed)}")
        
        if successful:
            avg_accuracy = np.mean([r['accuracy'] for r in successful])
            avg_sl_mae = np.mean([r['sl_mae'] for r in successful])
            avg_tp_mae = np.mean([r['tp_mae'] for r in successful])
            avg_sharpe = np.mean([r.get('sharpe_ratio', 0) for r in successful])
            avg_win_rate = np.mean([r.get('win_rate', 0) for r in successful])
            
            logger.info(f"\nğŸ“ˆ Average Metrics:")
            logger.info(f"   Accuracy: {avg_accuracy:.2%}")
            logger.info(f"   SL MAE: {avg_sl_mae:.1f} pips")
            logger.info(f"   TP MAE: {avg_tp_mae:.1f} pips")
            logger.info(f"   Sharpe Ratio: {avg_sharpe:.2f}")
            logger.info(f"   Win Rate: {avg_win_rate:.2%}")
            
        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        report = {
            'timestamp': datetime.now().isoformat(),
            'total_tasks': len(results),
            'successful': len(successful),
            'failed': len(failed),
            'results': results
        }
        
        report_path = self.models_dir / f"training_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
            
        logger.info(f"\nğŸ“„ Report saved to: {report_path}")
        logger.info("="*60)
        
    def _get_pip_value(self, pair):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚ÙŠÙ…Ø© Ø§Ù„Ù†Ù‚Ø·Ø©"""
        if 'JPY' in pair:
            return 0.01
        elif 'XAU' in pair or 'GOLD' in pair:
            return 0.1
        elif 'BTC' in pair or any(idx in pair for idx in ['US30', 'NAS', 'DAX']):
            return 1.0
        else:
            return 0.0001


if __name__ == "__main__":
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…
    system = IntegratedTrainingSystemSLTP()
    
    # ØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¯ÙˆØ§Øª
    results = system.train_all_instruments(
        instrument_types=['forex_major', 'metals', 'indices'],
        force_retrain=False
    )
    
    logger.info("\nâœ… Integrated training system completed!")
    logger.info("ğŸ“Š Models are now optimized for SL/TP prediction")
    logger.info("ğŸ”„ Continuous learning is running in the background")