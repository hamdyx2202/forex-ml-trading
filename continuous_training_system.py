#!/usr/bin/env python3
"""
Continuous Training System - Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³ØªÙ…Ø± ÙˆØ§Ù„Ù…ØªÙƒØ§Ù…Ù„
Ù†Ø¸Ø§Ù… Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³ØªÙ…Ø± Ù…Ø¹ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
"""

import time
import warnings
warnings.filterwarnings('ignore')

from datetime import datetime, timedelta
import sqlite3
import pandas as pd
from pathlib import Path
import json
import numpy as np
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import threading
import signal
import sys
import pickle
import os
import schedule
from train_advanced_complete import AdvancedCompleteTrainer
import logging
from typing import Dict, List, Tuple, Optional
import hashlib

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø¬Ù„Ø§Øª
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    handlers=[
        logging.FileHandler('logs/continuous_training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ContinuousTrainingSystem:
    """Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³ØªÙ…Ø± Ù…Ø¹ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ"""
    
    def __init__(self):
        self.trainer = AdvancedCompleteTrainer()
        self.state_file = Path("state/continuous_training_state.pkl")
        self.models_registry = Path("models/registry.json")
        self.performance_db = Path("data/performance_tracking.db")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        self.config = {
            'retrain_interval_hours': 24,  # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙƒÙ„ 24 Ø³Ø§Ø¹Ø©
            'min_accuracy_threshold': 0.80,  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…Ù‚Ø¨ÙˆÙ„Ø©
            'performance_check_interval': 3600,  # ÙØ­Øµ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙƒÙ„ Ø³Ø§Ø¹Ø©
            'max_concurrent_training': 2,  # Ø¹Ø¯Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨Ø§Øª Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
            'auto_update_models': True,  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
            'alert_on_degradation': True,  # ØªÙ†Ø¨ÙŠÙ‡ Ø¹Ù†Ø¯ Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„Ø£Ø¯Ø§Ø¡
            'min_data_points': 10000,  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            'max_training_time_minutes': 30,  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„ÙˆÙ‚Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        }
        
        # Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
        self.state = {
            'active_models': {},
            'training_queue': [],
            'performance_history': {},
            'last_full_scan': None,
            'training_in_progress': {},
            'failed_attempts': {},
        }
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        self.load_state()
        
        # Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªØ­ÙƒÙ…
        self._running = False
        self._stop_event = threading.Event()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        self._create_directories()
        
    def _create_directories(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"""
        directories = [
            'state', 'models', 'logs', 'results/continuous',
            'alerts', 'backups', 'performance_reports'
        ]
        for dir_path in directories:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    def load_state(self):
        """ØªØ­Ù…ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
        if self.state_file.exists():
            try:
                with open(self.state_file, 'rb') as f:
                    saved_state = pickle.load(f)
                    self.state.update(saved_state)
                logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {len(self.state['active_models'])} Ù†Ù…ÙˆØ°Ø¬ Ù†Ø´Ø·")
            except Exception as e:
                logger.error(f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø©: {e}")
    
    def save_state(self):
        """Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
        try:
            self.state_file.parent.mkdir(exist_ok=True)
            with open(self.state_file, 'wb') as f:
                pickle.dump(self.state, f)
            logger.debug("ØªÙ… Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…")
        except Exception as e:
            logger.error(f"ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ø­Ø§Ù„Ø©: {e}")
    
    def get_available_pairs(self) -> List[Tuple[str, str, int]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
        try:
            conn = sqlite3.connect("data/forex_ml.db")
            query = f"""
                SELECT symbol, timeframe, COUNT(*) as count
                FROM price_data
                GROUP BY symbol, timeframe
                HAVING count >= {self.config['min_data_points']}
                ORDER BY count DESC
            """
            df = pd.read_sql_query(query, conn)
            conn.close()
            
            pairs = [(row['symbol'], row['timeframe'], row['count']) 
                    for _, row in df.iterrows()]
            
            return pairs
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø£Ø²ÙˆØ§Ø¬: {e}")
            return []
    
    def check_data_updates(self, symbol: str, timeframe: str) -> bool:
        """ÙØ­Øµ ÙˆØ¬ÙˆØ¯ ØªØ­Ø¯ÙŠØ«Ø§Øª ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            conn = sqlite3.connect("data/forex_ml.db")
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¢Ø®Ø± timestamp ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            query = """
                SELECT MAX(timestamp) as last_update, COUNT(*) as count
                FROM price_data
                WHERE symbol = ? AND timeframe = ?
            """
            result = pd.read_sql_query(query, conn, params=(symbol, timeframe))
            conn.close()
            
            if result.empty or result['count'].iloc[0] < self.config['min_data_points']:
                return False
            
            last_update = pd.to_datetime(result['last_update'].iloc[0])
            
            # ÙØ­Øµ Ø¢Ø®Ø± ØªØ¯Ø±ÙŠØ¨
            model_key = f"{symbol}_{timeframe}"
            if model_key in self.state['active_models']:
                last_train = pd.to_datetime(self.state['active_models'][model_key]['last_training'])
                
                # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
                return last_update > last_train
            
            return True  # ØªØ¯Ø±ÙŠØ¨ Ø¬Ø¯ÙŠØ¯
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ù„Ù€ {symbol} {timeframe}: {e}")
            return False
    
    def evaluate_model_performance(self, symbol: str, timeframe: str) -> Dict:
        """ØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ø§Ù„ÙŠ"""
        try:
            model_key = f"{symbol}_{timeframe}"
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø­Ø¯Ø« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªÙ‚ÙŠÙŠÙ…
            conn = sqlite3.connect("data/forex_ml.db")
            query = """
                SELECT * FROM price_data
                WHERE symbol = ? AND timeframe = ?
                ORDER BY timestamp DESC
                LIMIT 1000
            """
            df = pd.read_sql_query(query, conn, params=(symbol, timeframe))
            conn.close()
            
            if df.empty:
                return {'accuracy': 0, 'status': 'no_data'}
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªÙ‚ÙŠÙŠÙ…Ù‡
            model_info = self.state['active_models'].get(model_key)
            if not model_info:
                return {'accuracy': 0, 'status': 'no_model'}
            
            # Ù‡Ù†Ø§ ÙŠØªÙ… ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
            # (ØªØ­ØªØ§Ø¬ Ù„ØªÙ†ÙÙŠØ° Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙØ¹Ù„ÙŠØ©)
            
            performance = {
                'accuracy': model_info.get('accuracy', 0),
                'last_check': datetime.now().isoformat(),
                'data_points': len(df),
                'status': 'evaluated'
            }
            
            return performance
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ‚ÙŠÙŠÙ… {symbol} {timeframe}: {e}")
            return {'accuracy': 0, 'status': 'error', 'error': str(e)}
    
    def train_model_async(self, symbol: str, timeframe: str, count: int):
        """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†"""
        model_key = f"{symbol}_{timeframe}"
        
        try:
            logger.info(f"ğŸ”„ Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ {symbol} {timeframe}")
            
            # ÙˆØ¶Ø¹ Ø¹Ù„Ø§Ù…Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù‚ÙŠØ¯ Ø§Ù„ØªÙ†ÙÙŠØ°
            self.state['training_in_progress'][model_key] = {
                'start_time': datetime.now().isoformat(),
                'status': 'training'
            }
            
            # Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙØ¹Ù„ÙŠ
            start_time = time.time()
            results = self.trainer.train_symbol_advanced(symbol, timeframe)
            training_time = time.time() - start_time
            
            if results and results.get('best_accuracy', 0) >= self.config['min_accuracy_threshold']:
                # ØªØ­Ø¯ÙŠØ« Ø³Ø¬Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                self.state['active_models'][model_key] = {
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'accuracy': results['best_accuracy'],
                    'strategy': results['best_strategy'],
                    'ensemble_accuracy': results.get('ensemble_accuracy', 0),
                    'confidence_threshold': results.get('confidence_threshold', 0.7),
                    'expected_win_rate': results.get('expected_win_rate', 0),
                    'last_training': datetime.now().isoformat(),
                    'training_time': training_time,
                    'data_points': count,
                    'model_version': self._generate_model_version(symbol, timeframe),
                    'status': 'active'
                }
                
                logger.info(f"âœ… {symbol} {timeframe}: Ø¯Ù‚Ø© {results['best_accuracy']:.4f} "
                          f"({training_time/60:.1f} Ø¯Ù‚ÙŠÙ‚Ø©)")
                
                # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                self._save_model_info(model_key, results)
                
            else:
                logger.warning(f"âŒ {symbol} {timeframe}: Ø¯Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø© Ø£Ùˆ ÙØ´Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨")
                self.state['failed_attempts'][model_key] = {
                    'timestamp': datetime.now().isoformat(),
                    'reason': 'low_accuracy' if results else 'training_failed'
                }
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ {symbol} {timeframe}: {e}")
            self.state['failed_attempts'][model_key] = {
                'timestamp': datetime.now().isoformat(),
                'reason': 'exception',
                'error': str(e)
            }
        
        finally:
            # Ø¥Ø²Ø§Ù„Ø© Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¬Ø§Ø±ÙŠ
            if model_key in self.state['training_in_progress']:
                del self.state['training_in_progress'][model_key]
            
            # Ø­ÙØ¸ Ø§Ù„Ø­Ø§Ù„Ø©
            self.save_state()
    
    def _generate_model_version(self, symbol: str, timeframe: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø±Ù‚Ù… Ø¥ØµØ¯Ø§Ø± ÙØ±ÙŠØ¯ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬"""
        timestamp = datetime.now().isoformat()
        version_string = f"{symbol}_{timeframe}_{timestamp}"
        return hashlib.md5(version_string.encode()).hexdigest()[:8]
    
    def _save_model_info(self, model_key: str, results: Dict):
        """Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        try:
            # ØªØ­Ø¯ÙŠØ« Ø³Ø¬Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            registry = {}
            if self.models_registry.exists():
                with open(self.models_registry, 'r') as f:
                    registry = json.load(f)
            
            registry[model_key] = {
                'info': self.state['active_models'][model_key],
                'results': results,
                'updated': datetime.now().isoformat()
            }
            
            with open(self.models_registry, 'w') as f:
                json.dump(registry, f, indent=2)
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
    
    def scheduled_full_scan(self):
        """Ù…Ø³Ø­ Ø´Ø§Ù…Ù„ Ù…Ø¬Ø¯ÙˆÙ„ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬"""
        logger.info("ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø³Ø­ Ø§Ù„Ø´Ø§Ù…Ù„ Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„")
        
        pairs = self.get_available_pairs()
        updates_needed = []
        
        for symbol, timeframe, count in pairs:
            if self.check_data_updates(symbol, timeframe):
                updates_needed.append((symbol, timeframe, count))
        
        logger.info(f"ğŸ“Š ØªØ­ØªØ§Ø¬ {len(updates_needed)} Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªØ­Ø¯ÙŠØ«")
        
        # Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±
        for item in updates_needed:
            if item not in self.state['training_queue']:
                self.state['training_queue'].append(item)
        
        self.state['last_full_scan'] = datetime.now().isoformat()
        self.save_state()
    
    def performance_monitoring(self):
        """Ù…Ø±Ø§Ù‚Ø¨Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù†Ø´Ø·Ø©"""
        logger.info("ğŸ“ˆ ÙØ­Øµ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù†Ø´Ø·Ø©")
        
        degraded_models = []
        
        for model_key, model_info in self.state['active_models'].items():
            if model_info['status'] != 'active':
                continue
                
            symbol = model_info['symbol']
            timeframe = model_info['timeframe']
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ø§Ù„ÙŠ
            performance = self.evaluate_model_performance(symbol, timeframe)
            
            # Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø§Ø¨Ù‚
            original_accuracy = model_info['accuracy']
            current_accuracy = performance.get('accuracy', 0)
            
            if current_accuracy < original_accuracy * 0.95:  # Ø§Ù†Ø®ÙØ§Ø¶ 5% Ø£Ùˆ Ø£ÙƒØ«Ø±
                degraded_models.append({
                    'model': model_key,
                    'original': original_accuracy,
                    'current': current_accuracy,
                    'drop': original_accuracy - current_accuracy
                })
                
                # Ø¥Ø¶Ø§ÙØ© Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
                self.state['training_queue'].append(
                    (symbol, timeframe, model_info['data_points'])
                )
        
        if degraded_models and self.config['alert_on_degradation']:
            self._send_performance_alert(degraded_models)
        
        # Ø­ÙØ¸ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø£Ø¯Ø§Ø¡
        timestamp = datetime.now().isoformat()
        for model in degraded_models:
            if model['model'] not in self.state['performance_history']:
                self.state['performance_history'][model['model']] = []
            
            self.state['performance_history'][model['model']].append({
                'timestamp': timestamp,
                'accuracy': model['current']
            })
        
        self.save_state()
    
    def _send_performance_alert(self, degraded_models: List[Dict]):
        """Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        alert_file = Path(f"alerts/performance_alert_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        
        alert_data = {
            'timestamp': datetime.now().isoformat(),
            'type': 'performance_degradation',
            'models': degraded_models,
            'action': 'scheduled_for_retraining'
        }
        
        with open(alert_file, 'w') as f:
            json.dump(alert_data, f, indent=2)
        
        logger.warning(f"âš ï¸ ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø§Ù†Ø®ÙØ§Ø¶ ÙÙŠ Ø£Ø¯Ø§Ø¡ {len(degraded_models)} Ù†Ù…ÙˆØ°Ø¬")
    
    def process_training_queue(self):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        if not self.state['training_queue']:
            return
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨Ø§Øª Ø§Ù„Ø¬Ø§Ø±ÙŠØ©
        active_training = len(self.state['training_in_progress'])
        
        if active_training >= self.config['max_concurrent_training']:
            return
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ù†Ø§ØµØ± ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
        with ThreadPoolExecutor(max_workers=self.config['max_concurrent_training']) as executor:
            while self.state['training_queue'] and active_training < self.config['max_concurrent_training']:
                symbol, timeframe, count = self.state['training_queue'].pop(0)
                model_key = f"{symbol}_{timeframe}"
                
                # ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙƒØ±Ø±
                if model_key in self.state['training_in_progress']:
                    continue
                
                # Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
                executor.submit(self.train_model_async, symbol, timeframe, count)
                active_training += 1
    
    def generate_performance_report(self):
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø´Ø§Ù…Ù„"""
        try:
            report_data = {
                'timestamp': datetime.now().isoformat(),
                'active_models': len(self.state['active_models']),
                'models_in_training': len(self.state['training_in_progress']),
                'queued_for_training': len(self.state['training_queue']),
                'failed_attempts': len(self.state['failed_attempts']),
                'models_summary': []
            }
            
            # ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù†Ø´Ø·Ø©
            for model_key, model_info in self.state['active_models'].items():
                report_data['models_summary'].append({
                    'model': model_key,
                    'accuracy': model_info['accuracy'],
                    'strategy': model_info['strategy'],
                    'last_training': model_info['last_training'],
                    'status': model_info['status']
                })
            
            # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            report_file = Path(f"performance_reports/report_{datetime.now().strftime('%Y%m%d')}.json")
            with open(report_file, 'w') as f:
                json.dump(report_data, f, indent=2)
            
            logger.info(f"ğŸ“Š ØªÙ… ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡: {report_file}")
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {e}")
    
    def run_continuous(self):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±"""
        logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³ØªÙ…Ø±")
        self._running = True
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„Ø©
        schedule.every(self.config['retrain_interval_hours']).hours.do(self.scheduled_full_scan)
        schedule.every(self.config['performance_check_interval']).seconds.do(self.performance_monitoring)
        schedule.every(5).minutes.do(self.process_training_queue)
        schedule.every(1).hours.do(self.generate_performance_report)
        schedule.every(30).minutes.do(self.save_state)
        
        # Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª
        signal.signal(signal.SIGINT, self._signal_handler)
        
        # Ø§Ù„Ù…Ø³Ø­ Ø§Ù„Ø£ÙˆÙ„ÙŠ
        self.scheduled_full_scan()
        
        # Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        while self._running and not self._stop_event.is_set():
            try:
                # ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„Ø©
                schedule.run_pending()
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
                self.process_training_queue()
                
                # Ø§Ù†ØªØ¸Ø§Ø± Ù‚ØµÙŠØ±
                time.sleep(10)
                
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {e}")
                time.sleep(60)  # Ø§Ù†ØªØ¸Ø§Ø± Ø¯Ù‚ÙŠÙ‚Ø© Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰
        
        logger.info("â¹ï¸ ØªÙˆÙ‚Ù Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³ØªÙ…Ø±")
    
    def _signal_handler(self, signum, frame):
        """Ù…Ø¹Ø§Ù„Ø¬ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù"""
        logger.info("\nâš ï¸ ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù...")
        self._running = False
        self._stop_event.set()
        
        # Ø­ÙØ¸ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        self.save_state()
        self.generate_performance_report()
        
        logger.info("âœ… ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù†")
        sys.exit(0)
    
    def stop(self):
        """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù†Ø¸Ø§Ù…"""
        self._running = False
        self._stop_event.set()

def main():
    """Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print("ğŸš€ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³ØªÙ…Ø± ÙˆØ§Ù„Ù…ØªÙƒØ§Ù…Ù„")
    print("="*60)
    print("\nâœ¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª:")
    print("   â€¢ ØªØ¯Ø±ÙŠØ¨ Ù…Ø³ØªÙ…Ø± Ø¹Ù„Ù‰ Ù…Ø¯Ø§Ø± Ø§Ù„Ø³Ø§Ø¹Ø©")
    print("   â€¢ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬")
    print("   â€¢ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù†Ø¯ Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„Ø£Ø¯Ø§Ø¡")
    print("   â€¢ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ù†Ø¯ ØªÙˆÙØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©")
    print("   â€¢ ØªÙ‚Ø§Ø±ÙŠØ± Ø£Ø¯Ø§Ø¡ Ø¯ÙˆØ±ÙŠØ©")
    print("   â€¢ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¢Ù…Ù†Ø© Ù„Ù„Ø¥ÙŠÙ‚Ø§Ù")
    
    print("\nâš ï¸ Ø³ÙŠØ¹Ù…Ù„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø´ÙƒÙ„ Ù…Ø³ØªÙ…Ø±. Ø§Ø¶ØºØ· Ctrl+C Ù„Ù„Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¢Ù…Ù†")
    
    confirm = input("\nÙ‡Ù„ ØªØ±ÙŠØ¯ Ø¨Ø¯Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…ØŸ (y/n): ").strip().lower()
    
    if confirm != 'y':
        print("âŒ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„")
        return
    
    # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…
    system = ContinuousTrainingSystem()
    
    try:
        system.run_continuous()
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…: {e}")
        system.save_state()
        print("\nâŒ ØªÙˆÙ‚Ù Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø³Ø¨Ø¨ Ø®Ø·Ø£")

if __name__ == "__main__":
    main()