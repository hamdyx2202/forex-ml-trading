#!/usr/bin/env python3
"""
ğŸš€ Optimized Forex ML Server
ğŸ“Š ÙŠØ¹Ù…Ù„ Ù…Ø¹ Ø¬Ø¯ÙˆÙ„ price_data Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
ğŸ¤– ØªØ¯Ø±ÙŠØ¨ ÙˆØªÙ†Ø¨Ø¤ Ù…Ø­Ø³Ù†
"""

import os
import sys
import json
import sqlite3
import logging
import threading
from datetime import datetime
from flask import Flask, request, jsonify
from flask_cors import CORS
import pandas as pd
import numpy as np
import joblib

# Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±ÙŠØ©
try:
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
    from sklearn.preprocessing import RobustScaler
    from sklearn.model_selection import train_test_split
    ML_AVAILABLE = True
except:
    ML_AVAILABLE = False

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('optimized_forex_server.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Flask app
app = Flask(__name__)
CORS(app)

class OptimizedForexSystem:
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.db_path = './data/forex_ml.db'
        self.models_dir = './trained_models'
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
        os.makedirs(self.models_dir, exist_ok=True)
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
        self.load_existing_models()
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©
        self.available_pairs = self.get_available_pairs()
        
        logger.info(f"âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… - {len(self.models)} Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù…Ù„")
        logger.info(f"ğŸ“Š Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©: {len(self.available_pairs)}")
    
    def get_available_pairs(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            conn = sqlite3.connect(self.db_path)
            query = """
            SELECT DISTINCT symbol, COUNT(*) as count 
            FROM price_data 
            WHERE symbol NOT LIKE '%BRL%' 
            AND symbol NOT LIKE '%RUB%'
            GROUP BY symbol 
            HAVING count > 1000
            """
            pairs = pd.read_sql_query(query, conn)
            conn.close()
            
            return pairs['symbol'].tolist()
        except:
            return []
    
    def load_existing_models(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©"""
        if not os.path.exists(self.models_dir):
            return
        
        for file in os.listdir(self.models_dir):
            if file.endswith('_model.pkl'):
                try:
                    parts = file.replace('_model.pkl', '').split('_')
                    if len(parts) >= 2:
                        symbol = parts[0]
                        timeframe = parts[1] if len(parts) > 1 else 'M15'
                        
                        model = joblib.load(os.path.join(self.models_dir, file))
                        key = f"{symbol}_{timeframe}"
                        self.models[key] = model
                        
                        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù‚ÙŠØ§Ø³
                        scaler_file = file.replace('_model.pkl', '_scaler.pkl')
                        scaler_path = os.path.join(self.models_dir, scaler_file)
                        if os.path.exists(scaler_path):
                            self.scalers[key] = joblib.load(scaler_path)
                            
                except Exception as e:
                    logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ {file}: {str(e)}")
    
    def calculate_features(self, df):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¨Ø³ÙŠØ·Ø© ÙˆØ§Ù„ÙØ¹Ø§Ù„Ø©"""
        features = pd.DataFrame(index=df.index)
        
        # Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        features['open'] = df['open']
        features['high'] = df['high']
        features['low'] = df['low']
        features['close'] = df['close']
        
        # Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ù…ØªØ­Ø±ÙƒØ©
        features['sma_10'] = df['close'].rolling(10).mean()
        features['sma_20'] = df['close'].rolling(20).mean()
        features['sma_50'] = df['close'].rolling(50).mean()
        
        # RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        features['rsi'] = 100 - (100 / (1 + rs))
        
        # MACD
        exp1 = df['close'].ewm(span=12, adjust=False).mean()
        exp2 = df['close'].ewm(span=26, adjust=False).mean()
        features['macd'] = exp1 - exp2
        features['macd_signal'] = features['macd'].ewm(span=9, adjust=False).mean()
        
        # Bollinger Bands
        sma = df['close'].rolling(window=20).mean()
        std = df['close'].rolling(window=20).std()
        features['bb_upper'] = sma + (std * 2)
        features['bb_lower'] = sma - (std * 2)
        features['bb_width'] = features['bb_upper'] - features['bb_lower']
        
        # Ø§Ù„Ù†Ø³Ø¨
        features['high_low_ratio'] = df['high'] / df['low']
        features['close_open_ratio'] = df['close'] / df['open']
        
        # ATR
        high_low = df['high'] - df['low']
        high_close = np.abs(df['high'] - df['close'].shift())
        low_close = np.abs(df['low'] - df['close'].shift())
        ranges = pd.concat([high_low, high_close, low_close], axis=1)
        true_range = np.max(ranges, axis=1)
        features['atr'] = true_range.rolling(14).mean()
        
        # Ø¥Ø²Ø§Ù„Ø© NaN
        features = features.dropna()
        
        return features
    
    def train_model(self, symbol, timeframe='M15'):
        """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ù„Ø²ÙˆØ¬ Ù…Ø­Ø¯Ø¯"""
        try:
            logger.info(f"ğŸ¤– ØªØ¯Ø±ÙŠØ¨ {symbol} {timeframe}...")
            
            # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            conn = sqlite3.connect(self.db_path)
            query = f"""
            SELECT * FROM price_data 
            WHERE symbol = '{symbol}'
            ORDER BY time DESC
            LIMIT 5000
            """
            
            df = pd.read_sql_query(query, conn)
            conn.close()
            
            if len(df) < 1000:
                logger.warning(f"âš ï¸ Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ù€ {symbol}")
                return False
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            df['time'] = pd.to_datetime(df['time'])
            df.set_index('time', inplace=True)
            
            # ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ø£Ø±Ù‚Ø§Ù…
            for col in ['open', 'high', 'low', 'close']:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            df = df.dropna()
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª
            features = self.calculate_features(df)
            
            if len(features) < 100:
                return False
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨
            X = features.values
            y = (df['close'].shift(-1) > df['close']).astype(int)
            y = y[features.index].values[:-1]
            X = X[:-1]
            
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
            
            # ØªØ·Ø¨ÙŠØ¹
            scaler = RobustScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # ØªØ¯Ø±ÙŠØ¨
            model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42
            )
            model.fit(X_train_scaled, y_train)
            
            # ØªÙ‚ÙŠÙŠÙ…
            accuracy = model.score(X_test_scaled, y_test)
            logger.info(f"   âœ… Ø§Ù„Ø¯Ù‚Ø©: {accuracy:.2%}")
            
            # Ø­ÙØ¸
            key = f"{symbol}_{timeframe}"
            self.models[key] = model
            self.scalers[key] = scaler
            
            # Ø­ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø±Øµ
            model_path = os.path.join(self.models_dir, f"{symbol}_{timeframe}_model.pkl")
            scaler_path = os.path.join(self.models_dir, f"{symbol}_{timeframe}_scaler.pkl")
            
            joblib.dump(model, model_path)
            joblib.dump(scaler, scaler_path)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {str(e)}")
            return False
    
    def predict(self, symbol, timeframe, df):
        """Ø§Ù„ØªÙ†Ø¨Ø¤"""
        try:
            key = f"{symbol}_{timeframe}"
            
            # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ Ù†Ù…ÙˆØ°Ø¬ØŒ Ø­Ø§ÙˆÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            if key not in self.models:
                logger.info(f"ğŸ“š Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {key}, Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨...")
                if not self.train_model(symbol, timeframe):
                    return self.simple_prediction(df)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª
            features = self.calculate_features(df)
            
            if features.empty:
                return self.simple_prediction(df)
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤
            X = features.values[-1:] 
            
            if key in self.scalers:
                X = self.scalers[key].transform(X)
            
            model = self.models[key]
            prediction = model.predict(X)[0]
            
            # Ø§Ù„Ø«Ù‚Ø©
            if hasattr(model, 'predict_proba'):
                proba = model.predict_proba(X)[0]
                confidence = max(proba)
            else:
                confidence = 0.65
            
            return prediction, confidence
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤: {str(e)}")
            return self.simple_prediction(df)
    
    def simple_prediction(self, df):
        """ØªÙ†Ø¨Ø¤ Ø¨Ø³ÙŠØ· Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª"""
        try:
            latest = df.iloc[-1]
            sma20 = df['close'].rolling(20).mean().iloc[-1]
            sma50 = df['close'].rolling(50).mean().iloc[-1]
            
            if latest['close'] > sma20 > sma50:
                return 0, 0.65  # Buy
            elif latest['close'] < sma20 < sma50:
                return 1, 0.65  # Sell
            else:
                return 2, 0.5   # Hold
        except:
            return 2, 0.5

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…
system = OptimizedForexSystem()

@app.route('/status', methods=['GET'])
def status():
    """Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙŠØ±ÙØ±"""
    return jsonify({
        'status': 'running',
        'version': '5.0-optimized',
        'models_loaded': len(system.models),
        'available_pairs': len(system.available_pairs),
        'ml_available': ML_AVAILABLE,
        'pairs_sample': system.available_pairs[:10]
    })

@app.route('/predict', methods=['POST'])
def predict():
    """Ø§Ù„ØªÙ†Ø¨Ø¤"""
    try:
        # Ù…Ø¹Ø§Ù„Ø¬Ø© JSON
        raw_data = request.get_data(as_text=True)
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ØµÙ„Ø§Ø­ JSON
        try:
            data = json.loads(raw_data)
        except json.JSONDecodeError as e:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¥ØµÙ„Ø§Ø­
            if e.pos > 0 and e.pos < len(raw_data):
                try:
                    # Ù‚Ø·Ø¹ Ø¹Ù†Ø¯ Ù…ÙˆØ¶Ø¹ Ø§Ù„Ø®Ø·Ø£ ÙˆØ¥ØºÙ„Ø§Ù‚ JSON
                    fixed = raw_data[:e.pos]
                    open_brackets = fixed.count('[') - fixed.count(']')
                    open_braces = fixed.count('{') - fixed.count('}')
                    fixed += ']' * open_brackets + '}' * open_braces
                    data = json.loads(fixed)
                    logger.info("âœ… ØªÙ… Ø¥ØµÙ„Ø§Ø­ JSON")
                except:
                    return jsonify({'error': 'Invalid JSON', 'action': 'NONE', 'confidence': 0})
            else:
                return jsonify({'error': 'Invalid JSON', 'action': 'NONE', 'confidence': 0})
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        symbol = data.get('symbol', 'UNKNOWN')
        timeframe = data.get('timeframe', 'M15')
        candles = data.get('candles', [])
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„Ø±Ù…Ø²
        clean_symbol = symbol.replace('m', '').replace('.ecn', '').replace('_pro', '')
        
        logger.info(f"ğŸ“Š Ø·Ù„Ø¨: {symbol} ({clean_symbol}) {timeframe} - {len(candles)} Ø´Ù…Ø¹Ø©")
        
        if len(candles) < 50:
            return jsonify({
                'symbol': symbol,
                'action': 'NONE',
                'confidence': 0,
                'error': 'Not enough candles'
            })
        
        # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ DataFrame
        df = pd.DataFrame(candles)
        for col in ['open', 'high', 'low', 'close']:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        if 'time' in df.columns:
            df['time'] = pd.to_datetime(df['time'])
            df.set_index('time', inplace=True)
        
        df = df.dropna()
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤
        prediction, confidence = system.predict(clean_symbol, timeframe, df)
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
        current_price = float(df['close'].iloc[-1])
        pip_value = 0.01 if 'JPY' in symbol else 0.0001
        
        if prediction == 0 and confidence >= 0.65:
            action = 'BUY'
        elif prediction == 1 and confidence >= 0.65:
            action = 'SELL'
        else:
            action = 'NONE'
        
        # Ø­Ø³Ø§Ø¨ SL/TP
        atr = df['high'].rolling(14).max().iloc[-1] - df['low'].rolling(14).min().iloc[-1]
        sl_distance = max(min(atr * 1.5, 100 * pip_value), 30 * pip_value)
        
        if action == 'BUY':
            sl_price = current_price - sl_distance
            tp1_price = current_price + (sl_distance * 2)
            tp2_price = current_price + (sl_distance * 3)
        elif action == 'SELL':
            sl_price = current_price + sl_distance
            tp1_price = current_price - (sl_distance * 2)
            tp2_price = current_price - (sl_distance * 3)
        else:
            sl_price = tp1_price = tp2_price = current_price
        
        response = {
            'symbol': symbol,
            'timeframe': timeframe,
            'action': action,
            'confidence': float(confidence),
            'current_price': current_price,
            'sl_price': float(sl_price),
            'tp1_price': float(tp1_price),
            'tp2_price': float(tp2_price),
            'sl_pips': float(sl_distance / pip_value),
            'tp1_pips': float(sl_distance / pip_value * 2),
            'tp2_pips': float(sl_distance / pip_value * 3),
            'model_exists': f"{clean_symbol}_{timeframe}" in system.models
        }
        
        logger.info(f"   âœ… {action} Ø¨Ø«Ù‚Ø© {confidence:.1%}")
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£: {str(e)}")
        return jsonify({
            'error': str(e),
            'action': 'NONE',
            'confidence': 0
        })

@app.route('/train', methods=['POST'])
def train():
    """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬"""
    try:
        data = request.json
        symbol = data.get('symbol', '').replace('m', '').replace('.ecn', '')
        timeframe = data.get('timeframe', 'M15')
        
        success = system.train_model(symbol, timeframe)
        
        return jsonify({
            'success': success,
            'message': f'Trained {symbol} {timeframe}' if success else 'Training failed'
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/models', methods=['GET'])
def models():
    """Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
    return jsonify({
        'total': len(system.models),
        'models': list(system.models.keys()),
        'available_pairs': system.available_pairs
    })

@app.route('/train_all', methods=['POST'])
def train_all():
    """ØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬"""
    def train_task():
        for symbol in system.available_pairs[:20]:  # Ø£ÙˆÙ„ 20 Ø²ÙˆØ¬
            try:
                system.train_model(symbol)
            except:
                pass
    
    thread = threading.Thread(target=train_task)
    thread.start()
    
    return jsonify({
        'message': 'Training started in background',
        'pairs': len(system.available_pairs)
    })

if __name__ == '__main__':
    logger.info("\n" + "="*60)
    logger.info("ğŸš€ OPTIMIZED FOREX ML SERVER")
    logger.info("ğŸ“Š Working with real price_data table")
    logger.info("ğŸŒ Server: http://0.0.0.0:5000")
    logger.info("="*60 + "\n")
    
    # ØªØ¯Ø±ÙŠØ¨ Ø¨Ø¹Ø¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ù†Ø¯ Ø§Ù„Ø¨Ø¯Ø¡
    logger.info("ğŸ¤– ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©...")
    for symbol in ['EURUSD', 'GBPUSD', 'USDJPY', 'USDCHF', 'AUDUSD']:
        if symbol in system.available_pairs:
            system.train_model(symbol)
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ±
    app.run(host='0.0.0.0', port=5000, debug=False)