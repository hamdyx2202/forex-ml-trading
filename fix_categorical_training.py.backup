#!/usr/bin/env python3
"""
Fix Categorical Columns Error in Training
Ø¥ØµÙ„Ø§Ø­ Ø®Ø·Ø£ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
"""

import os
import fileinput
import sys

print("ğŸ”§ Fixing categorical columns error...")
print("="*60)

# Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø°ÙŠ ÙŠØ­ØªØ§Ø¬ Ø¥ØµÙ„Ø§Ø­
training_file = "train_advanced_95_percent.py"

if not os.path.exists(training_file):
    print(f"âŒ {training_file} not found!")
    print("\nğŸ” Searching for training files...")
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    for root, dirs, files in os.walk('.'):
        for file in files:
            if 'train' in file and file.endswith('.py'):
                print(f"Found: {os.path.join(root, file)}")
    sys.exit(1)

# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
with open(training_file, 'r', encoding='utf-8') as f:
    content = f.read()

# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø´ÙƒÙ„Ø©
if 'volatility_regime' in content or 'volume_regime' in content:
    print("âœ… Found categorical columns in code")
    
    # Ø¥Ø¶Ø§ÙØ© ÙƒÙˆØ¯ Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ©
    fix_code = '''
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ© Ø¥Ù„Ù‰ Ø±Ù‚Ù…ÙŠØ©
        categorical_columns = ['volatility_regime', 'volume_regime']
        for col in categorical_columns:
            if col in df_features.columns:
                # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù‚Ù…ÙŠ
                if df_features[col].dtype == 'category':
                    df_features[col] = df_features[col].cat.codes
                elif df_features[col].dtype == 'object':
                    # Ø¥Ù†Ø´Ø§Ø¡ ØªØµÙ†ÙŠÙ Ø±Ù‚Ù…ÙŠ
                    df_features[col] = pd.Categorical(df_features[col]).codes
'''
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙƒÙˆØ¯
    # Ø¨Ø¹Ø¯ Ø¥Ù†Ø´Ø§Ø¡ df_features ÙˆÙ‚Ø¨Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    insertion_points = [
        "df_features = engineer.create_features",
        "# Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø¨Ø¯ÙˆÙ† Ù‡Ø¯Ù",
        "# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‡Ø¯Ù Ù„Ø«Ù†Ø§Ø¦ÙŠ",
        "X = df_features[feature_cols]"
    ]
    
    inserted = False
    for point in insertion_points:
        if point in content:
            # Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„ÙƒÙˆØ¯ Ø¨Ø¹Ø¯ Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù‚Ø·Ø©
            lines = content.split('\n')
            new_lines = []
            
            for i, line in enumerate(lines):
                new_lines.append(line)
                if point in line and not inserted:
                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙƒÙˆØ¯ ÙÙŠ Ø§Ù„Ø³Ø·Ø± Ø§Ù„ØªØ§Ù„ÙŠ
                    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¨Ø§Ø¯Ø¦Ø©
                    indent = len(line) - len(line.lstrip())
                    if i + 1 < len(lines):
                        next_indent = len(lines[i+1]) - len(lines[i+1].lstrip())
                        indent = next_indent
                    
                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙƒÙˆØ¯ Ù…Ø¹ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¨Ø§Ø¯Ø¦Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©
                    for fix_line in fix_code.strip().split('\n'):
                        new_lines.append(' ' * indent + fix_line)
                    inserted = True
            
            content = '\n'.join(new_lines)
            break
    
    if inserted:
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙØµÙ„Ø­
        with open(training_file, 'w', encoding='utf-8') as f:
            f.write(content)
        print("âœ… Fixed categorical columns handling")
    else:
        print("âš ï¸ Could not find insertion point")

# Ø­Ù„ Ø¨Ø¯ÙŠÙ„ - Ø¥Ù†Ø´Ø§Ø¡ wrapper Ù„Ù„ØªØ¯Ø±ÙŠØ¨
print("\nğŸ“ Creating alternative fix...")

wrapper_code = '''#!/usr/bin/env python3
"""
Training Wrapper with Categorical Fix
ØºÙ„Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ø¹ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„ÙØ¦Ø§Øª
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys

# Import the original training file
sys.path.append('.')

# ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø£ØµÙ„ÙŠ
print("Loading original training module...")
import train_advanced_95_percent as original_train

# ØªØ¹Ø¯ÙŠÙ„ Ø¯Ø§Ù„Ø© prepare_data
original_prepare_data = original_train.prepare_data

def fixed_prepare_data(symbol, timeframe):
    """Ù†Ø³Ø®Ø© Ù…ÙØµÙ„Ø­Ø© Ù…Ù† prepare_data"""
    # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
    result = original_prepare_data(symbol, timeframe)
    
    if result[0] is None:
        return result
    
    X, y, feature_cols = result
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ©
    if isinstance(X, pd.DataFrame):
        categorical_columns = ['volatility_regime', 'volume_regime']
        for col in categorical_columns:
            if col in X.columns:
                if X[col].dtype == 'category':
                    X[col] = X[col].cat.codes
                elif X[col].dtype == 'object':
                    X[col] = pd.Categorical(X[col]).codes
                print(f"  âœ… Converted {col} to numeric")
    
    return X, y, feature_cols

# Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø¯Ø§Ù„Ø©
original_train.prepare_data = fixed_prepare_data

# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
if __name__ == "__main__":
    print("ğŸš€ Starting training with categorical fix...")
    
    # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    if hasattr(original_train, 'main'):
        original_train.main()
    else:
        # ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ø¨Ø§Ø´Ø±Ø©
        trainer = original_train.AdvancedTrainer()
        trainer.train_all_models()
'''

with open('train_with_fix.py', 'w') as f:
    f.write(wrapper_code)

print("âœ… Created train_with_fix.py")

# Ø­Ù„ Ø¢Ø®Ø± - ØªØ¹Ø¯ÙŠÙ„ feature_engineer
print("\nğŸ”§ Checking feature_engineer...")

feature_files = [
    'feature_engineer_fixed_v2.py',
    'feature_engineer_fixed_v3.py',
    'feature_engineer_fixed_v4.py',
    'feature_engineer_fixed_v5.py',
    'feature_engineer_fixed.py'
]

for fe_file in feature_files:
    if os.path.exists(fe_file):
        print(f"\nChecking {fe_file}...")
        
        with open(fe_file, 'r') as f:
            fe_content = f.read()
            
        if 'volatility_regime' in fe_content or 'volume_regime' in fe_content:
            print(f"âœ… Found categorical columns in {fe_file}")
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ø°ÙŠ ÙŠØªÙ… ÙÙŠÙ‡ Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            if "df['volatility_regime']" in fe_content:
                # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø¨ÙƒÙˆØ¯ ÙŠÙÙ†Ø´Ø¦ Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ©
                fe_content = fe_content.replace(
                    "df['volatility_regime'] = pd.cut",
                    "# ØªØ­ÙˆÙŠÙ„ Ù…Ø¨Ø§Ø´Ø± Ù„Ø±Ù‚Ù…ÙŠ\n        df['volatility_regime'] = pd.cut"
                )
                fe_content = fe_content.replace(
                    "df['volume_regime'] = pd.cut",
                    "# ØªØ­ÙˆÙŠÙ„ Ù…Ø¨Ø§Ø´Ø± Ù„Ø±Ù‚Ù…ÙŠ\n        df['volume_regime'] = pd.cut"
                )
                
                # Ø¥Ø¶Ø§ÙØ© .cat.codes ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø³Ø·Ø±
                lines = fe_content.split('\n')
                new_lines = []
                
                for line in lines:
                    if 'volatility_regime' in line and 'pd.cut' in line and not '.cat.codes' in line:
                        line = line.rstrip() + '.cat.codes'
                    elif 'volume_regime' in line and 'pd.cut' in line and not '.cat.codes' in line:
                        line = line.rstrip() + '.cat.codes'
                    new_lines.append(line)
                
                fe_content = '\n'.join(new_lines)
                
                # Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…ÙØµÙ„Ø­Ø©
                fixed_name = fe_file.replace('.py', '_fixed_cat.py')
                with open(fixed_name, 'w') as f:
                    f.write(fe_content)
                print(f"âœ… Created {fixed_name}")

print("\n" + "="*60)
print("âœ… Fixes applied!")
print("\nğŸš€ Try running one of these:")
print("1. python train_with_fix.py")
print("2. python train_advanced_95_percent.py (if fixed)")
print("3. Update feature_engineer imports to use *_fixed_cat.py versions")

# Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª ØªØ¯Ø±ÙŠØ¨ Ù…Ø¨Ø³Ø·
print("\nğŸ“ Creating simplified training script...")

simple_training = '''#!/usr/bin/env python3
"""
Simplified Training without Categorical Columns
ØªØ¯Ø±ÙŠØ¨ Ù…Ø¨Ø³Ø· Ø¨Ø¯ÙˆÙ† Ø£Ø¹Ù…Ø¯Ø© ÙØ¦ÙˆÙŠØ©
"""

import pandas as pd
import numpy as np
import joblib
import sqlite3
from datetime import datetime
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split
import lightgbm as lgb
import xgboost as xgb
from pathlib import Path
import os

print("ğŸš€ Starting simplified training...")

# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
db_path = None
for path in ['forex_data.db', 'data/forex_data.db', '../forex_data.db']:
    if os.path.exists(path):
        db_path = path
        break

if not db_path:
    print("âŒ No database found!")
    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
    for root, dirs, files in os.walk('.'):
        for file in files:
            if file.endswith('.db'):
                db_path = os.path.join(root, file)
                print(f"Found: {db_path}")
                break
        if db_path:
            break

if db_path:
    print(f"âœ… Using database: {db_path}")
    
    # Ø§Ù„Ø±Ù…ÙˆØ² ÙˆØ§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©
    symbols = ['EURUSDm', 'GBPUSDm', 'USDJPYm', 'XAUUSDm']
    timeframes = ['PERIOD_M5', 'PERIOD_H4']  # ÙÙ‚Ø· 2 Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    
    os.makedirs('models/advanced', exist_ok=True)
    
    conn = sqlite3.connect(db_path)
    
    for symbol in symbols:
        for timeframe in timeframes:
            print(f"\\nTraining {symbol} {timeframe}...")
            
            try:
                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                query = "SELECT * FROM forex_data WHERE symbol = ? AND timeframe = ? ORDER BY time"
                df = pd.read_sql_query(query, conn, params=(symbol, timeframe))
                
                if len(df) < 100:
                    print(f"  âš ï¸ Not enough data: {len(df)} rows")
                    continue
                
                # Ù…ÙŠØ²Ø§Øª Ø¨Ø³ÙŠØ·Ø©
                df['returns'] = df['close'].pct_change()
                df['hl_ratio'] = df['high'] / df['low']
                df['co_ratio'] = df['close'] / df['open']
                df['volatility'] = df['returns'].rolling(20).std()
                df['sma_20'] = df['close'].rolling(20).mean()
                df['rsi'] = 50  # Ù…Ø¨Ø³Ø·
                
                # Ø¥Ø²Ø§Ù„Ø© NaN
                df = df.dropna()
                
                # Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØ§Ù„Ù‡Ø¯Ù
                feature_cols = ['returns', 'hl_ratio', 'co_ratio', 'volatility', 'rsi']
                X = df[feature_cols].values
                y = (df['close'].shift(-5) > df['close']).astype(int).values[:-5]
                X = X[:-5]
                
                if len(X) < 50:
                    print(f"  âš ï¸ Not enough samples: {len(X)}")
                    continue
                
                # ØªÙ‚Ø³ÙŠÙ… ÙˆØªØ¯Ø±ÙŠØ¨
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                
                scaler = RobustScaler()
                X_train = scaler.fit_transform(X_train)
                X_test = scaler.transform(X_test)
                
                # Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø³ÙŠØ·
                model = RandomForestClassifier(n_estimators=50, random_state=42)
                model.fit(X_train, y_train)
                
                accuracy = model.score(X_test, y_test)
                print(f"  âœ… Accuracy: {accuracy:.2%}")
                
                # Ø­ÙØ¸
                model_data = {
                    'model': model,
                    'scaler': scaler,
                    'metrics': {'accuracy': accuracy}
                }
                
                filename = f'models/advanced/{symbol}_{timeframe}_ensemble_{datetime.now().strftime("%Y%m%d_%H%M%S")}.pkl'
                joblib.dump(model_data, filename)
                print(f"  âœ… Saved: {filename}")
                
            except Exception as e:
                print(f"  âŒ Error: {e}")
    
    conn.close()
    print("\\nâœ… Training completed!")
else:
    print("âŒ No database found for training!")
'''

with open('train_simple.py', 'w') as f:
    f.write(simple_training)

print("âœ… Created train_simple.py")
print("\nFor quick results, try: python train_simple.py")