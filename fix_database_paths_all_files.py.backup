#!/usr/bin/env python3
"""
Ø¥ØµÙ„Ø§Ø­ Ù…Ø³Ø§Ø±Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
"""

import os
import glob

def fix_database_paths():
    """ØªØ­Ø¯ÙŠØ« Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ù…Ù† forex_data.db Ø¥Ù„Ù‰ forex_ml.db"""
    
    # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ø¯ÙŠØ«Ù‡Ø§
    files_to_update = [
        'train_advanced_complete.py',
        'train_advanced_complete_enhanced.py',
        'train_full_advanced.py',
        'continuous_learner_advanced_v2.py',
        'train_models_simple.py',
        'train_full_simple.py',
        'train_quick_test.py'
    ]
    
    # Ø¥Ø¶Ø§ÙØ© Ø£ÙŠ Ù…Ù„ÙØ§Øª python Ø£Ø®Ø±Ù‰ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    all_python_files = glob.glob("*.py") + glob.glob("src/*.py")
    
    updated_files = []
    
    for file_path in set(files_to_update + all_python_files):
        if not os.path.exists(file_path):
            continue
            
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            
            # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
            replacements = [
                ('data/forex_data.db', 'data/forex_ml.db'),
                ('"data/forex_data.db"', '"data/forex_ml.db"'),
                ("'data/forex_data.db'", "'data/forex_ml.db'"),
                ('Path("data/forex_data.db")', 'Path("data/forex_ml.db")'),
                ('forex_data.db', 'forex_ml.db'),  # Ø£ÙŠ Ø¥Ø´Ø§Ø±Ø© Ø£Ø®Ø±Ù‰
            ]
            
            for old, new in replacements:
                content = content.replace(old, new)
            
            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø¥Ø°Ø§ ØªÙ… Ø§Ù„ØªØ¹Ø¯ÙŠÙ„
            if content != original_content:
                # Ø­ÙØ¸ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
                backup_path = f"{file_path}.backup"
                with open(backup_path, 'w', encoding='utf-8') as f:
                    f.write(original_content)
                
                # Ø­ÙØ¸ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø­Ø¯Ø«
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                updated_files.append(file_path)
                print(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ«: {file_path}")
        
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ {file_path}: {e}")
    
    print(f"\nğŸ“Š ØªÙ… ØªØ­Ø¯ÙŠØ« {len(updated_files)} Ù…Ù„Ù")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    create_data_check_script()

def create_data_check_script():
    """Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©"""
    
    script_content = '''#!/usr/bin/env python3
"""
Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©
"""

import sqlite3
import pandas as pd
from pathlib import Path

def check_database():
    db_path = Path("data/forex_ml.db")
    
    if not db_path.exists():
        print(f"âŒ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {db_path}")
        return
    
    print(f"âœ… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ¬ÙˆØ¯Ø©: {db_path}")
    print(f"ğŸ“Š Ø§Ù„Ø­Ø¬Ù…: {db_path.stat().st_size / 1024 / 1024:.2f} MB")
    
    try:
        conn = sqlite3.connect(db_path)
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM price_data")
        total_records = cursor.fetchone()[0]
        print(f"\\nğŸ“ˆ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: {total_records:,}")
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ø±Ù…Ø² ÙˆØ§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ
        query = """
            SELECT symbol, timeframe, COUNT(*) as count
            FROM price_data
            GROUP BY symbol, timeframe
            HAVING count >= 10000
            ORDER BY count DESC
        """
        
        df = pd.read_sql_query(query, conn)
        
        print(f"\\nğŸ¯ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© (10,000+ Ø³Ø¬Ù„):")
        print("-" * 60)
        print(f"{'Symbol':<15} {'Timeframe':<10} {'Records':<15}")
        print("-" * 60)
        
        for _, row in df.iterrows():
            print(f"{row['symbol']:<15} {row['timeframe']:<10} {row['count']:<15,}")
        
        # Ù…Ù„Ø®Øµ
        unique_symbols = df['symbol'].nunique()
        unique_timeframes = df['timeframe'].nunique()
        
        print(f"\\nğŸ“Š Ø§Ù„Ù…Ù„Ø®Øµ:")
        print(f"   â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„ÙØ±ÙŠØ¯Ø©: {unique_symbols}")
        print(f"   â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©: {unique_timeframes}")
        print(f"   â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª: {len(df)}")
        
        conn.close()
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")

if __name__ == "__main__":
    check_database()
'''
    
    with open("check_training_data.py", "w", encoding='utf-8') as f:
        f.write(script_content)
    
    print("\nâœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡: check_training_data.py")
    print("ğŸš€ Ù„ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: python check_training_data.py")

def main():
    print("ğŸ”§ Ø¥ØµÙ„Ø§Ø­ Ù…Ø³Ø§Ø±Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    print("=" * 60)
    
    fix_database_paths()
    
    print("\nâœ… ØªÙ… Ø¥ØµÙ„Ø§Ø­ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª!")
    print("\nğŸ’¡ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:")
    print("1. ØªØ´ØºÙŠÙ„: python check_training_data.py")
    print("2. Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: python train_full_advanced.py")

if __name__ == "__main__":
    main()