#!/usr/bin/env python3
"""
MT5 Prediction Server - Ø®Ø§Ø¯Ù… Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
ÙŠØ³ØªÙ‚Ø¨Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† MT5 ÙˆÙŠØ±Ø³Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ù…Ø¹ SL/TP
"""

from flask import Flask, request, jsonify
import json
import numpy as np
import pandas as pd
from datetime import datetime
import sqlite3
from pathlib import Path
import joblib
import logging
from logging.handlers import RotatingFileHandler

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
from train_advanced_complete import AdvancedCompleteTrainer
from continuous_learner_advanced_v2 import AdvancedContinuousLearnerV2

app = Flask(__name__)

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
def setup_logging():
    if not app.debug:
        file_handler = RotatingFileHandler('logs/mt5_server.log', maxBytes=10240000, backupCount=10)
        file_handler.setFormatter(logging.Formatter(
            '%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]'
        ))
        file_handler.setLevel(logging.INFO)
        app.logger.addHandler(file_handler)
        app.logger.setLevel(logging.INFO)
        app.logger.info('MT5 Prediction Server startup')

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
trainer = AdvancedCompleteTrainer()
continuous_learner = AdvancedContinuousLearnerV2()

# Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„Ù†Ù…Ø§Ø°Ø¬
models_cache = {}

@app.route('/api/predict_advanced', methods=['POST'])
def predict_advanced():
    """Ù†Ù‚Ø·Ø© Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
    try:
        data = request.get_json()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        symbol = data.get('symbol')
        timeframe = data.get('timeframe')
        candles = data.get('candles', [])
        requested_strategies = data.get('strategies', ['scalping', 'short_term'])
        
        app.logger.info(f"ðŸ“Š Ø·Ù„Ø¨ ØªÙ†Ø¨Ø¤: {symbol} {timeframe}")
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if not symbol or not timeframe or len(candles) < 100:
            return jsonify({
                'error': 'Invalid data',
                'message': 'Symbol, timeframe and at least 100 candles required'
            }), 400
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø´Ù…ÙˆØ¹ Ø¥Ù„Ù‰ DataFrame
        df = pd.DataFrame(candles)
        df['time'] = pd.to_datetime(df['time'], unit='s')
        df = df.set_index('time')
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        required_columns = ['open', 'high', 'low', 'close', 'volume']
        for col in required_columns:
            if col not in df.columns:
                return jsonify({
                    'error': 'Missing columns',
                    'message': f'Column {col} is required'
                }), 400
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        features_df = trainer.create_ultra_advanced_features(df, symbol)
        
        if features_df.empty:
            return jsonify({
                'error': 'Feature creation failed',
                'message': 'Could not create features from data'
            }), 500
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¢Ø®Ø± ØµÙ Ù…Ù† Ø§Ù„Ù…ÙŠØ²Ø§Øª
        latest_features = features_df.values[-1]
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
        predictions = {}
        
        for strategy in requested_strategies:
            if strategy not in trainer.training_strategies:
                continue
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ø£Ùˆ ØªØ­Ù…ÙŠÙ„Ù‡
            model_key = f"{symbol}_{timeframe}_{strategy}"
            
            if model_key not in models_cache:
                model_path = Path(f"models/{symbol}_{timeframe}/{strategy}/latest_models.pkl")
                
                if not model_path.exists():
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø¹Ø§Ù…
                    general_model_path = Path(f"models/EURUSD_H1/{strategy}/latest_models.pkl")
                    if general_model_path.exists():
                        model_path = general_model_path
                        app.logger.warning(f"Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø¹Ø§Ù… Ù„Ù€ {symbol} {timeframe} {strategy}")
                    else:
                        app.logger.warning(f"Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {strategy}")
                        continue
                
                try:
                    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                    model_data = joblib.load(model_path)
                    models_cache[model_key] = model_data
                except Exception as e:
                    app.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
                    continue
            
            model_data = models_cache[model_key]
            
            try:
                # Ø§Ù„ØªÙ†Ø¨Ø¤
                prediction = predict_with_model(
                    model_data, 
                    latest_features, 
                    df, 
                    symbol, 
                    strategy
                )
                
                if prediction:
                    predictions[strategy] = prediction
                    
            except Exception as e:
                app.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ Ù„Ù€ {strategy}: {e}")
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø³ÙˆÙ‚
        current_price = float(df['close'].iloc[-1])
        
        response = {
            'symbol': symbol,
            'timeframe': timeframe,
            'current_price': current_price,
            'timestamp': datetime.now().isoformat(),
            'predictions': predictions
        }
        
        # Ø­ÙØ¸ Ø§Ù„ØªÙ†Ø¨Ø¤ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¹Ù„Ù…
        save_prediction_to_db(symbol, timeframe, predictions)
        
        app.logger.info(f"âœ… ØªÙ… Ø¥Ø±Ø³Ø§Ù„ {len(predictions)} ØªÙ†Ø¨Ø¤ Ù„Ù€ {symbol} {timeframe}")
        
        return jsonify(response)
        
    except Exception as e:
        app.logger.error(f"Ø®Ø·Ø£ Ø¹Ø§Ù…: {str(e)}")
        return jsonify({
            'error': 'Server error',
            'message': str(e)
        }), 500

def predict_with_model(model_data, features, df, symbol, strategy):
    """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ø¯Ø¯"""
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
    models = model_data.get('signal_models', {})
    sl_models = model_data.get('sl_models', {})
    tp_models = model_data.get('tp_models', {})
    scaler = model_data.get('scaler')
    
    if not models:
        return None
    
    # Ù…Ø¹Ø§ÙŠØ±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if scaler:
        features_scaled = scaler.transform(features.reshape(1, -1))
    else:
        features_scaled = features.reshape(1, -1)
    
    # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
    signal_predictions = []
    signal_probabilities = []
    
    for model_name, model in models.items():
        try:
            pred = model.predict(features_scaled)[0]
            signal_predictions.append(pred)
            
            if hasattr(model, 'predict_proba'):
                proba = model.predict_proba(features_scaled)[0]
                signal_probabilities.append(proba)
        except:
            continue
    
    if not signal_predictions:
        return None
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    final_signal = int(np.median(signal_predictions))
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø©
    if signal_probabilities:
        avg_proba = np.mean(signal_probabilities, axis=0)
        confidence = float(np.max(avg_proba))
    else:
        signal_counts = np.bincount(signal_predictions)
        confidence = float(signal_counts[final_signal] / len(signal_predictions))
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù…Ø­Ø§ÙŠØ¯Ø©ØŒ Ù„Ø§ Ù†Ø±Ø³Ù„ ØªÙ†Ø¨Ø¤
    if final_signal == 1:
        return None
    
    current_price = float(df['close'].iloc[-1])
    
    # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù€ Stop Loss
    sl_predictions = []
    for model_name, model in sl_models.items():
        try:
            sl_pred = model.predict(features_scaled)[0]
            sl_predictions.append(sl_pred)
        except:
            continue
    
    if sl_predictions:
        final_sl = float(np.median(sl_predictions))
    else:
        # Ø­Ø³Ø§Ø¨ SL Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ATR
        atr = calculate_atr(df)
        sl_distance = atr * trainer.sl_tp_settings[strategy]['stop_loss_atr']
        final_sl = current_price - sl_distance if final_signal == 2 else current_price + sl_distance
    
    # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù€ Take Profit
    tp_levels = {}
    for tp_level in ['tp1', 'tp2', 'tp3']:
        tp_predictions = []
        
        if tp_level in tp_models:
            for model_name, model in tp_models[tp_level].items():
                try:
                    tp_pred = model.predict(features_scaled)[0]
                    tp_predictions.append(tp_pred)
                except:
                    continue
        
        if tp_predictions:
            tp_levels[tp_level] = float(np.median(tp_predictions))
        else:
            # Ø­Ø³Ø§Ø¨ TP Ø§ÙØªØ±Ø§Ø¶ÙŠ
            ratios = trainer.sl_tp_settings[strategy]['take_profit_ratios']
            ratio_idx = int(tp_level[-1]) - 1
            
            if ratio_idx < len(ratios):
                tp_distance = abs(current_price - final_sl) * ratios[ratio_idx]
                tp_levels[tp_level] = current_price + tp_distance if final_signal == 2 else current_price - tp_distance
    
    return {
        'signal': final_signal,
        'confidence': confidence,
        'stop_loss': final_sl,
        'take_profit_1': tp_levels.get('tp1', current_price),
        'take_profit_2': tp_levels.get('tp2', current_price),
        'take_profit_3': tp_levels.get('tp3', current_price),
        'strategy_settings': trainer.training_strategies[strategy],
        'sl_tp_settings': trainer.sl_tp_settings[strategy]
    }

def calculate_atr(df, period=14):
    """Ø­Ø³Ø§Ø¨ ATR"""
    high_low = df['high'] - df['low']
    high_close = abs(df['high'] - df['close'].shift())
    low_close = abs(df['low'] - df['close'].shift())
    
    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    atr = true_range.rolling(period).mean().iloc[-1]
    
    return atr

def save_prediction_to_db(symbol, timeframe, predictions):
    """Ø­ÙØ¸ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¹Ù„Ù…"""
    try:
        conn = sqlite3.connect("data/forex_ml.db")
        cursor = conn.cursor()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                symbol TEXT,
                timeframe TEXT,
                strategy TEXT,
                signal INTEGER,
                confidence REAL,
                stop_loss REAL,
                take_profit_1 REAL,
                take_profit_2 REAL,
                take_profit_3 REAL
            )
        """)
        
        # Ø­ÙØ¸ ÙƒÙ„ ØªÙ†Ø¨Ø¤
        for strategy, pred in predictions.items():
            cursor.execute("""
                INSERT INTO predictions 
                (symbol, timeframe, strategy, signal, confidence, 
                 stop_loss, take_profit_1, take_profit_2, take_profit_3)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                symbol, timeframe, strategy,
                pred['signal'], pred['confidence'],
                pred['stop_loss'], pred['take_profit_1'],
                pred['take_profit_2'], pred['take_profit_3']
            ))
        
        conn.commit()
        conn.close()
        
    except Exception as e:
        app.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")

@app.route('/api/update_trade_result', methods=['POST'])
def update_trade_result():
    """ØªØ­Ø¯ÙŠØ« Ù†ØªÙŠØ¬Ø© Ø§Ù„ØµÙÙ‚Ø© Ù„Ù„ØªØ¹Ù„Ù…"""
    try:
        data = request.get_json()
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        save_trade_result(data)
        
        return jsonify({'status': 'success'})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def save_trade_result(data):
    """Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØµÙÙ‚Ø©"""
    try:
        conn = sqlite3.connect("data/forex_ml.db")
        cursor = conn.cursor()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS trade_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                ticket INTEGER,
                symbol TEXT,
                timeframe TEXT,
                strategy TEXT,
                entry_price REAL,
                exit_price REAL,
                stop_loss REAL,
                take_profit REAL,
                profit REAL,
                profit_pips REAL,
                duration_minutes INTEGER,
                result TEXT
            )
        """)
        
        cursor.execute("""
            INSERT INTO trade_results 
            (ticket, symbol, timeframe, strategy, entry_price, exit_price, 
             stop_loss, take_profit, profit, profit_pips, duration_minutes, result)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            data.get('ticket'),
            data.get('symbol'),
            data.get('timeframe'),
            data.get('strategy'),
            data.get('entry_price'),
            data.get('exit_price'),
            data.get('stop_loss'),
            data.get('take_profit'),
            data.get('profit'),
            data.get('profit_pips'),
            data.get('duration_minutes'),
            data.get('result')
        ))
        
        conn.commit()
        conn.close()
        
        app.logger.info(f"âœ… ØªÙ… Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØµÙÙ‚Ø© #{data.get('ticket')}")
        
    except Exception as e:
        app.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØµÙÙ‚Ø©: {e}")

@app.route('/api/health', methods=['GET'])
def health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ø®Ø§Ø¯Ù…"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'models_loaded': len(models_cache),
        'version': '2.0'
    })

@app.route('/api/get_performance', methods=['GET'])
def get_performance():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…"""
    try:
        conn = sqlite3.connect("data/forex_ml.db")
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
        query = """
            SELECT 
                COUNT(*) as total_trades,
                SUM(CASE WHEN profit > 0 THEN 1 ELSE 0 END) as winning_trades,
                SUM(profit) as total_profit,
                AVG(profit_pips) as avg_pips,
                MAX(profit) as best_trade,
                MIN(profit) as worst_trade
            FROM trade_results
            WHERE timestamp > datetime('now', '-30 days')
        """
        
        cursor = conn.cursor()
        cursor.execute(query)
        stats = cursor.fetchone()
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©
        query2 = """
            SELECT 
                strategy,
                COUNT(*) as trades,
                SUM(CASE WHEN profit > 0 THEN 1 ELSE 0 END) as wins,
                SUM(profit) as profit
            FROM trade_results
            WHERE timestamp > datetime('now', '-30 days')
            GROUP BY strategy
        """
        
        strategy_stats = pd.read_sql_query(query2, conn)
        
        conn.close()
        
        return jsonify({
            'overall': {
                'total_trades': stats[0] or 0,
                'winning_trades': stats[1] or 0,
                'win_rate': (stats[1] / stats[0] * 100) if stats[0] else 0,
                'total_profit': stats[2] or 0,
                'avg_pips': stats[3] or 0,
                'best_trade': stats[4] or 0,
                'worst_trade': stats[5] or 0
            },
            'by_strategy': strategy_stats.to_dict('records')
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    setup_logging()
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
    Path("logs").mkdir(exist_ok=True)
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù…
    app.run(host='0.0.0.0', port=5000, debug=False)