#!/usr/bin/env python3
"""
ğŸ“¦ Smart Backup Manager - Ù…Ø¯ÙŠØ± Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø§Ù„Ø°ÙƒÙŠ
ğŸ—„ï¸ ÙŠØ­ØªÙØ¸ Ø¨Ù†Ø³Ø® Ø°ÙƒÙŠØ© Ø¯ÙˆÙ† Ø¥Ù‡Ø¯Ø§Ø± Ø§Ù„Ù…Ø³Ø§Ø­Ø©
"""

import os
import shutil
import sqlite3
import hashlib
from datetime import datetime, timedelta
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)

class SmartBackupManager:
    """Ù…Ø¯ÙŠØ± Ø°ÙƒÙŠ Ù„Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
    
    def __init__(self):
        self.backup_dir = './backups'
        self.archive_dir = './backups/archive'
        
        # Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ù†Ø³Ø®
        self.retention_policy = {
            'daily': 7,      # Ø§Ø­ØªÙØ¸ Ø¨Ù€ 7 Ù†Ø³Ø® ÙŠÙˆÙ…ÙŠØ©
            'weekly': 4,     # Ø§Ø­ØªÙØ¸ Ø¨Ù€ 4 Ù†Ø³Ø® Ø£Ø³Ø¨ÙˆØ¹ÙŠØ©
            'monthly': 3     # Ø§Ø­ØªÙØ¸ Ø¨Ù€ 3 Ù†Ø³Ø® Ø´Ù‡Ø±ÙŠØ©
        }
        
        os.makedirs(self.backup_dir, exist_ok=True)
        os.makedirs(self.archive_dir, exist_ok=True)
    
    def smart_backup(self, db_path):
        """Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø°ÙƒÙŠ"""
        if not os.path.exists(db_path):
            logger.error(f"Database not found: {db_path}")
            return None
        
        db_name = os.path.basename(db_path).replace('.db', '')
        
        # 1. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
        if not self._has_changes(db_path):
            logger.info("ğŸ“Š No changes detected, skipping backup")
            return None
        
        # 2. Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_name = f"{db_name}_backup_{timestamp}.db"
        backup_path = os.path.join(self.backup_dir, backup_name)
        
        logger.info(f"ğŸ“¦ Creating backup: {backup_name}")
        shutil.copy2(db_path, backup_path)
        
        # 3. Ø¶ØºØ· Ø§Ù„Ù†Ø³Ø®Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ÙƒØ¨ÙŠØ±Ø©
        size_mb = os.path.getsize(backup_path) / (1024 * 1024)
        if size_mb > 100:  # Ø£ÙƒØ¨Ø± Ù…Ù† 100 Ù…ÙŠØ¬Ø§
            self._compress_backup(backup_path)
        
        # 4. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø¨Ø°ÙƒØ§Ø¡
        self._smart_cleanup(db_name)
        
        return backup_path
    
    def _has_changes(self, db_path):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ØªØºÙŠÙŠØ±Ø§Øª Ù…Ù†Ø° Ø¢Ø®Ø± Ù†Ø³Ø®Ø©"""
        try:
            # Ø­Ø³Ø§Ø¨ checksum Ù„Ù„Ù…Ù„Ù Ø§Ù„Ø­Ø§Ù„ÙŠ
            current_hash = self._calculate_checksum(db_path)
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¢Ø®Ø± Ù†Ø³Ø®Ø©
            db_name = os.path.basename(db_path).replace('.db', '')
            last_backup = self._get_last_backup(db_name)
            
            if not last_backup:
                return True  # Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†Ø³Ø® Ø³Ø§Ø¨Ù‚Ø©
            
            # Ù…Ù‚Ø§Ø±Ù†Ø© checksum
            last_hash = self._calculate_checksum(last_backup)
            return current_hash != last_hash
            
        except Exception as e:
            logger.error(f"Error checking changes: {e}")
            return True  # Ø§ÙØªØ±Ø¶ ÙˆØ¬ÙˆØ¯ ØªØºÙŠÙŠØ±Ø§Øª
    
    def _calculate_checksum(self, file_path):
        """Ø­Ø³Ø§Ø¨ checksum Ù„Ù„Ù…Ù„Ù"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            # Ù‚Ø±Ø§Ø¡Ø© Ø£ÙˆÙ„ 10 Ù…ÙŠØ¬Ø§ ÙÙ‚Ø· Ù„Ù„Ø³Ø±Ø¹Ø©
            for chunk in iter(lambda: f.read(10 * 1024 * 1024), b""):
                hash_md5.update(chunk)
                break  # ÙÙ‚Ø· Ø£ÙˆÙ„ chunk
        return hash_md5.hexdigest()
    
    def _get_last_backup(self, db_name):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¢Ø®Ø± Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        backups = []
        for file in os.listdir(self.backup_dir):
            if file.startswith(f"{db_name}_backup_") and (file.endswith('.db') or file.endswith('.db.gz')):
                file_path = os.path.join(self.backup_dir, file)
                backups.append((file_path, os.path.getmtime(file_path)))
        
        if backups:
            backups.sort(key=lambda x: x[1], reverse=True)
            return backups[0][0]
        return None
    
    def _compress_backup(self, backup_path):
        """Ø¶ØºØ· Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        try:
            import gzip
            compressed_path = backup_path + '.gz'
            
            with open(backup_path, 'rb') as f_in:
                with gzip.open(compressed_path, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
            
            # Ø­Ø°Ù Ø§Ù„Ù†Ø³Ø®Ø© ØºÙŠØ± Ø§Ù„Ù…Ø¶ØºÙˆØ·Ø©
            os.remove(backup_path)
            
            original_size = os.path.getsize(backup_path) / (1024 * 1024)
            compressed_size = os.path.getsize(compressed_path) / (1024 * 1024)
            logger.info(f"   ğŸ—œï¸ Compressed: {original_size:.1f} MB â†’ {compressed_size:.1f} MB")
            
        except Exception as e:
            logger.error(f"Compression failed: {e}")
    
    def _smart_cleanup(self, db_name):
        """ØªÙ†Ø¸ÙŠÙ Ø°ÙƒÙŠ Ù„Ù„Ù†Ø³Ø® Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        logger.info("   ğŸ§¹ Smart cleanup of old backups...")
        
        # Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ù†Ø³Ø®
        all_backups = []
        for file in os.listdir(self.backup_dir):
            if file.startswith(f"{db_name}_backup_"):
                file_path = os.path.join(self.backup_dir, file)
                file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                all_backups.append({
                    'path': file_path,
                    'time': file_time,
                    'age_days': (datetime.now() - file_time).days
                })
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ø§Ù‹)
        all_backups.sort(key=lambda x: x['time'], reverse=True)
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ø§Ø­ØªÙØ§Ø¸
        to_keep = set()
        
        # 1. Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ù†Ø³Ø® Ø§Ù„ÙŠÙˆÙ…ÙŠØ© (Ø¢Ø®Ø± 7 Ø£ÙŠØ§Ù…)
        daily_count = 0
        for backup in all_backups:
            if backup['age_days'] <= 7 and daily_count < self.retention_policy['daily']:
                to_keep.add(backup['path'])
                daily_count += 1
        
        # 2. Ø§Ø­ØªÙØ¸ Ø¨Ù†Ø³Ø®Ø© Ø£Ø³Ø¨ÙˆØ¹ÙŠØ© (Ø¢Ø®Ø± 4 Ø£Ø³Ø§Ø¨ÙŠØ¹)
        weekly_count = 0
        for week in range(4):
            week_start = datetime.now() - timedelta(weeks=week+1)
            week_end = week_start + timedelta(days=7)
            
            for backup in all_backups:
                if week_start <= backup['time'] < week_end and weekly_count < self.retention_policy['weekly']:
                    to_keep.add(backup['path'])
                    weekly_count += 1
                    break
        
        # 3. Ø§Ø­ØªÙØ¸ Ø¨Ù†Ø³Ø®Ø© Ø´Ù‡Ø±ÙŠØ© (Ø¢Ø®Ø± 3 Ø´Ù‡ÙˆØ±)
        monthly_count = 0
        for month in range(3):
            month_start = datetime.now() - timedelta(days=30*(month+1))
            month_end = month_start + timedelta(days=30)
            
            for backup in all_backups:
                if month_start <= backup['time'] < month_end and monthly_count < self.retention_policy['monthly']:
                    to_keep.add(backup['path'])
                    monthly_count += 1
                    break
        
        # 4. Ø§Ø­Ø°Ù Ø§Ù„Ø¨Ø§Ù‚ÙŠ
        deleted_count = 0
        saved_space = 0
        
        for backup in all_backups:
            if backup['path'] not in to_keep:
                try:
                    size_mb = os.path.getsize(backup['path']) / (1024 * 1024)
                    os.remove(backup['path'])
                    deleted_count += 1
                    saved_space += size_mb
                    logger.info(f"      âŒ Deleted: {os.path.basename(backup['path'])} ({backup['age_days']} days old)")
                except Exception as e:
                    logger.error(f"      Failed to delete {backup['path']}: {e}")
        
        if deleted_count > 0:
            logger.info(f"   âœ… Deleted {deleted_count} old backups, saved {saved_space:.1f} MB")
        else:
            logger.info(f"   âœ… No old backups to delete")
        
        # Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù…Ø­ØªÙØ¸ Ø¨Ù‡Ø§
        logger.info(f"   ğŸ“¦ Keeping {len(to_keep)} backups:")
        logger.info(f"      - Daily: {daily_count}")
        logger.info(f"      - Weekly: {weekly_count}")
        logger.info(f"      - Monthly: {monthly_count}")
    
    def restore_backup(self, backup_path, target_path):
        """Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        try:
            if backup_path.endswith('.gz'):
                import gzip
                with gzip.open(backup_path, 'rb') as f_in:
                    with open(target_path, 'wb') as f_out:
                        shutil.copyfileobj(f_in, f_out)
            else:
                shutil.copy2(backup_path, target_path)
            
            logger.info(f"âœ… Restored backup to: {target_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Restore failed: {e}")
            return False
    
    def list_backups(self, db_name=None):
        """Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        backups = []
        
        for file in os.listdir(self.backup_dir):
            if file.endswith('.db') or file.endswith('.db.gz'):
                if db_name and not file.startswith(f"{db_name}_backup_"):
                    continue
                    
                file_path = os.path.join(self.backup_dir, file)
                size_mb = os.path.getsize(file_path) / (1024 * 1024)
                mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                age_days = (datetime.now() - mod_time).days
                
                backups.append({
                    'name': file,
                    'path': file_path,
                    'size_mb': size_mb,
                    'date': mod_time,
                    'age_days': age_days,
                    'compressed': file.endswith('.gz')
                })
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ®
        backups.sort(key=lambda x: x['date'], reverse=True)
        
        return backups

def main():
    """Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"""
    manager = SmartBackupManager()
    
    import sys
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == 'backup':
            # Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø°ÙƒÙŠ
            db_path = sys.argv[2] if len(sys.argv) > 2 else './data/forex_ml.db'
            manager.smart_backup(db_path)
            
        elif command == 'list':
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†Ø³Ø®
            backups = manager.list_backups()
            print(f"\nğŸ“¦ Total backups: {len(backups)}")
            for b in backups[:10]:  # Ø£ÙˆÙ„ 10 ÙÙ‚Ø·
                print(f"   - {b['name']} ({b['size_mb']:.1f} MB, {b['age_days']} days old)")
            
        elif command == 'restore':
            # Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù†Ø³Ø®Ø©
            if len(sys.argv) > 3:
                manager.restore_backup(sys.argv[2], sys.argv[3])
            else:
                print("Usage: python3 smart_backup_manager.py restore <backup_path> <target_path>")
    else:
        print("Smart Backup Manager")
        print("Usage:")
        print("  python3 smart_backup_manager.py backup [db_path]")
        print("  python3 smart_backup_manager.py list")
        print("  python3 smart_backup_manager.py restore <backup_path> <target_path>")

if __name__ == "__main__":
    main()